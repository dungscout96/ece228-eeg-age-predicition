{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "2c0_0uImBwm5"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as T\n",
    "import numpy as np\n",
    "import h5py\n",
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "import csv\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "import logging\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# For visualize input\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import io\n",
    "import torchvision\n",
    "from torchvision import transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image\n",
    "\n",
    "class EEGDataset(Dataset):\n",
    "    '''\n",
    "    Custom Dataset object for PyTorch to load the dataset\n",
    "    '''\n",
    "    def __init__(self, x, y, train, val):\n",
    "        super(EEGDataset).__init__()\n",
    "        assert x.shape[0] == y.size\n",
    "        self.x = x\n",
    "        self.y = [y[i][0] for i in range(y.size)]\n",
    "        self.train = train\n",
    "        self.val = val\n",
    "\n",
    "    def __getitem__(self,key):\n",
    "        return (self.x[key], self.y[key])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "class Logger():\n",
    "    '''\n",
    "    Object controlling how information will be logged\n",
    "    A logger created globally will be used to log all information\n",
    "    Create a Logger(mode='debug') to have everything print to the console\n",
    "    '''\n",
    "    def __init__(self, mode='log'):\n",
    "        self.mode = mode\n",
    "        \n",
    "    def set_model_save_location(self, model_dir):\n",
    "        self.model_dir = f\"saved-model/{model_dir}\"\n",
    "        if not os.path.isdir(self.model_dir):\n",
    "            os.mkdir(self.model_dir)\n",
    "        \n",
    "    def set_experiment(self, experiment_name):\n",
    "        self.experiment_name = experiment_name\n",
    "        log_format = '%(asctime)s %(message)s'\n",
    "        logging.basicConfig(stream=sys.stdout, level=logging.INFO,\n",
    "                            format=log_format, datefmt='%m/%d %I:%M:%S %p')\n",
    "        fh = logging.FileHandler(os.path.join('training-logs', f'log-{experiment_name}-{datetime.datetime.today()}.txt'))\n",
    "        fh.setFormatter(logging.Formatter(log_format))\n",
    "        logging.getLogger().addHandler(fh)\n",
    "        self.writer = SummaryWriter(f\"runs/{experiment_name}\")\n",
    "            \n",
    "    def log(self, message=\"\"):\n",
    "        if self.mode == 'log':\n",
    "            logging.info(message)\n",
    "        elif self.mode == 'debug':\n",
    "            print(message)\n",
    "\n",
    "    def save_model(self, model, info):\n",
    "        torch.save(model.state_dict(), f\"{self.model_dir}/model-{logger.experiment_name}-{info}\")\n",
    "        \n",
    "def load_data(path, role, winLength, numChan, srate, feature, one_channel=False, version=\"\"):\n",
    "    \"\"\"\n",
    "    Load dataset\n",
    "    :param  \n",
    "        path: Filepath to the dataset\n",
    "        role: Role of the dataset. Can be \"train\", \"val\", or \"test\"\n",
    "        winLength: Length of time window. Can be 2 or 15\n",
    "        numChan: Number of channels. Can be 24 or 128\n",
    "        srate: Sampling rate. Supporting 126Hz\n",
    "        feature: Input feature. Can be \"raw\", \"spectral\", or \"topo\"\n",
    "        one_channel: Whether input has 1 or 3 channel in depth dimension. Matters when load topo data as number of input channels \n",
    "                are different from original's\n",
    "        version: Any additional information of the datafile. Will be appended to the file name at the end\n",
    "    \"\"\"\n",
    "    transform = T.Compose([\n",
    "        T.ToTensor()\n",
    "    ])\n",
    "    if version:\n",
    "        f = h5py.File(path + f\"child_mind_x_{role}_{winLength}s_{numChan}chan_{feature}_{version}.mat\", 'r')\n",
    "    else:\n",
    "        f = h5py.File(path + f\"child_mind_x_{role}_{winLength}s_{numChan}chan_{feature}.mat\", 'r')\n",
    "    x = f[f'X_{role}']\n",
    "    if feature == 'raw':\n",
    "        x = np.transpose(x,(0,2,1))\n",
    "        x = np.reshape(x,(-1,numChan,winLength*srate))\n",
    "    elif feature == 'topo':\n",
    "        if one_channel:\n",
    "            samples = []\n",
    "            for i in range(x.shape[0]):\n",
    "                image = x[i]\n",
    "                b, g, r = image[0,:, :], image[1,:, :], image[2,:, :]\n",
    "                concat = np.concatenate((b,g,r), axis=1)\n",
    "                samples.append(concat)\n",
    "            x = np.stack(samples)\n",
    "            x = np.reshape(x,(-1,1,x.shape[1],x.shape[2]))\n",
    "    \n",
    "    if version:\n",
    "        f = h5py.File(path + f\"child_mind_yclass1_ages_{role}_{winLength}s_{numChan}chan_{feature}_{version}.mat\", 'r')\n",
    "    else:\n",
    "        f = h5py.File(path + f\"child_mind_yclass1_ages_{role}_{winLength}s_{numChan}chan_{feature}.mat\", 'r')\n",
    "    y = np.subtract(f[f'Y_cls_{role}'], 1)\n",
    "   \n",
    "    return x,y\n",
    "\n",
    "\n",
    "\n",
    "def plot_to_image_tensor(figure):\n",
    "    # Save the plot to a PNG in memory.\n",
    "    figure.savefig('batch.png')\n",
    "    # Closing the figure prevents it from being displayed directly inside\n",
    "    # the notebook.\n",
    "    plt.close(figure)\n",
    "    img = Image.open('batch.png')\n",
    "    trans = transforms.ToPILImage()\n",
    "    trans1 = transforms.ToTensor()\n",
    "    image_tensor = trans1(img)\n",
    "    return image_tensor\n",
    "\n",
    "def plot_EEG(data, feature, numChan, one_channel=True):\n",
    "    '''\n",
    "    Plot EEG sample\n",
    "    :param\n",
    "        data: An EEGDataset object\n",
    "        feature: String - 'raw' or 'topo'\n",
    "        numChan: Int - number of EEG channels\n",
    "        one_channel: Bool - Whether input has 1 or 3 channel in depth dimension. Matters when load topo data as number of input channels \n",
    "                are different from original's\n",
    "    '''\n",
    "    x_data = data[:][0]\n",
    "    if feature == 'raw':        \n",
    "        fig = plt.figure(figsize=(80, 80))\n",
    "        outer = gridspec.GridSpec(8, 8)\n",
    "        for i in range(64):\n",
    "            inner = gridspec.GridSpecFromSubplotSpec(numChan, 1,\n",
    "                            subplot_spec=outer[i])\n",
    "#             npimg = img[i,:,:,:].numpy()\n",
    "            npimg = x_data[i,:,:,:]\n",
    "            npimg = np.reshape(npimg,(24,256))\n",
    "            yax = None\n",
    "            for j in range(24):\n",
    "                ax = plt.Subplot(fig, inner[j])\n",
    "                ax.plot(range(256),npimg[j,:],'k')\n",
    "                ax.set_xticks([])\n",
    "                ax.set_yticks([])\n",
    "                fig.add_subplot(ax)\n",
    "\n",
    "        return fig\n",
    "    else:\n",
    "        sample = 2\n",
    "        if one_channel:\n",
    "            image = np.reshape(x_data[sample], (x_data[sample].shape[1],x_data[sample].shape[2]))\n",
    "            plt.imshow(image.astype('int32'))\n",
    "        else:\n",
    "            plt.imshow(np.transpose(x_data[sample].astype('int32'), (1, 2, 0)))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load EEG data\n",
    "path = './data/'\n",
    "winLength = 2\n",
    "numChan = 24\n",
    "srate = 128\n",
    "feature = 'raw'\n",
    "one_channel = False\n",
    "\n",
    "role = 'train'\n",
    "train_data_x, train_data_labels = load_data(path, role, winLength, numChan, srate, feature, one_channel)\n",
    "# print(f'X_train shape: {len(train_data)}, {train_data[0][0].shape}')\n",
    "# print(f'Y_train shape: {len(train_data)}, {train_data[0][1].shape}')\n",
    "\n",
    "role = 'val'\n",
    "val_data_x, val_data_labels = load_data(path, role, winLength, numChan, srate, feature, one_channel)\n",
    "# print(f'X_val shape: {len(val_data)}, {val_data[0][0].shape}')\n",
    "# print(f'Y_val shape: {len(val_data)}, {val_data[0][1].shape}')\n",
    "# EEGDataset(x, y, role=='train', role=='val')\n",
    "# plot_EEG(train_data, feature, numChan, one_channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_y = train_data_labels.copy()\n",
    "train_data_y[np.logical_and(train_data_labels <= 2,train_data_labels >= 0)] = 0\n",
    "train_data_y[train_data_labels > 2] = 1\n",
    "val_data_y = val_data_labels.copy()\n",
    "val_data_y[np.logical_and(val_data_labels <= 2,val_data_labels >= 0)] = 0\n",
    "val_data_y[val_data_labels > 2] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([43597.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0., 27784.]),\n",
       " array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(train_data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.610764769336378"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "43597/(43597+27784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([24980.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0., 14888.]),\n",
       " array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(val_data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6265676733219625"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "24980/(24980+14888)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = EEGDataset(train_data_x, train_data_y, True, False)\n",
    "val_data = EEGDataset(val_data_x, val_data_y, False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Initialize device information for PyTorch\n",
    "USE_GPU = True\n",
    "\n",
    "dtype = torch.float32 # we will be using float throughout this tutorial\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# Constant to control how frequently we print train loss\n",
    "print_every = 100\n",
    "\n",
    "print('using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(loader, model):\n",
    "    '''\n",
    "    Check accuracy of the model \n",
    "    param:\n",
    "        loader: An EEGDataset object\n",
    "        model: A PyTorch Module to test\n",
    "    '''\n",
    "    if loader.dataset.train:\n",
    "        logger.log('Checking accuracy on training set')\n",
    "    elif loader.dataset.val:\n",
    "        logger.log('Checking accuracy on validation set')\n",
    "    else:\n",
    "        logger.log('Checking accuracy on test set')   \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    lossTotal = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            x=x.squeeze(1)\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            scores = model(x)\n",
    "            loss = F.cross_entropy(scores, y, weight=torch.tensor([class_0_weight,class_1_weight], dtype=dtype,device=device))\n",
    "            lossTotal += loss.item()\n",
    "#             print(f\"label {y}, prediction {scores}\")\n",
    "            _, preds = scores.max(1)\n",
    "            num_correct += (preds == y).sum()\n",
    "            num_samples += preds.size(0)\n",
    "        acc = float(num_correct) / num_samples\n",
    "        lossTotal = lossTotal / len(loader)\n",
    "        logger.log('Loss (%f)' % (loss))\n",
    "        logger.log('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
    "\n",
    "        return acc,lossTotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_0_weight = 43597/(43597+27784)\n",
    "class_1_weight = 1-class_0_weight\n",
    "def train(model, loader_train, loader_val, optimizer, epochs=1):\n",
    "    \"\"\"\n",
    "    Train a model using the PyTorch Module API.\n",
    "    \n",
    "    params:\n",
    "        model: A PyTorch Module giving the model to train.\n",
    "        loader_train: A PyTorch DataLoader object containing training data loaded in batch\n",
    "        loader_val: A PyTorch DataLoader object containing validation data loaded in batch        \n",
    "        optimizer: An Optimizer object we will use to train the model\n",
    "        epochs: (Optional) A Python integer giving the number of epochs to train for\n",
    "    \n",
    "    Returns: Nothing, but prints model accuracies during training.\n",
    "    \"\"\"\n",
    "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
    "#     mseLoss = nn.MSELoss()\n",
    "    for e in range(epochs):\n",
    "        for t, (x, y) in enumerate(loader_train):\n",
    "            model.train()  # put model to training mode\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            x = x.squeeze(1)\n",
    "#             y = y.to(device=device, dtype=dtype).unsqueeze(1)\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "\n",
    "            scores = model(x)\n",
    "#             loss = mseLoss(scores, y)\n",
    "            loss = F.cross_entropy(scores, y, weight=torch.tensor([class_0_weight,class_1_weight], dtype=dtype,device=device))\n",
    "#             loss = F.binary_cross_entropy(torch.sigmoid(scores), y)\n",
    "\n",
    "            # Zero out all of the gradients for the variables which the optimizer\n",
    "            # will update.\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # This is the backwards pass: compute the gradient of the loss with\n",
    "            # respect to each  parameter of the model.\n",
    "            loss.backward()\n",
    "\n",
    "            # Actually update the parameters of the model using the gradients\n",
    "            # computed by the backwards pass.\n",
    "            optimizer.step()\n",
    "\n",
    "            if t % print_every == 0:\n",
    "                logger.log('Epoch %d, Iteration %d, loss = %.4f' % (e, t, loss.item()))\n",
    "        train_acc, train_loss = check_accuracy(loader_train, model)\n",
    "        logger.writer.add_scalar(\"Loss/train\", train_loss, e)\n",
    "        logger.writer.add_scalar(\"Acc/train\", train_acc, e)        \n",
    "        val_acc, val_loss = check_accuracy(loader_val, model)\n",
    "        logger.writer.add_scalar(\"Acc/val\", val_acc, e)        \n",
    "        logger.writer.add_scalar(\"Loss/val\", val_loss, e)\n",
    "        logger.log()\n",
    "        \n",
    "        # Save model every 20 epochs\n",
    "        if e > 0 and e % 10 == 0:\n",
    "            logger.save_model(model,f\"epoch{e}\")\n",
    "        elif val_acc >= 0.7:\n",
    "            logger.save_model(model,f\"valacc{round(val_acc*100,2)}-epoch{e}\")\n",
    "    # save final model\n",
    "    logger.save_model(model,f\"epoch{e}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    '''\n",
    "    Create the CNN following configuration in https://arxiv.org/pdf/1611.08024.pdf\n",
    "    '''\n",
    "    model = nn.Sequential(\n",
    "            nn.Conv1d(24,64,3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(64,64,3),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.MaxPool1d(2, 2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(8064,100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100,2)\n",
    "        )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------\n",
      "      Layer (type)        Output Shape         Param #     Tr. Param #\n",
      "=======================================================================\n",
      "          Conv1d-1        [1, 64, 254]           4,672           4,672\n",
      "            ReLU-2        [1, 64, 254]               0               0\n",
      "          Conv1d-3        [1, 64, 252]          12,352          12,352\n",
      "            ReLU-4        [1, 64, 252]               0               0\n",
      "         Dropout-5        [1, 64, 252]               0               0\n",
      "       MaxPool1d-6        [1, 64, 126]               0               0\n",
      "         Flatten-7           [1, 8064]               0               0\n",
      "          Linear-8            [1, 100]         806,500         806,500\n",
      "            ReLU-9            [1, 100]               0               0\n",
      "         Linear-10              [1, 2]             202             202\n",
      "=======================================================================\n",
      "Total params: 823,726\n",
      "Trainable params: 823,726\n",
      "Non-trainable params: 0\n",
      "-----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Create and show model summary\n",
    "model = create_model()\n",
    "from pytorch_model_summary import summary\n",
    "print(summary(model, torch.zeros((1, 24, 256)), show_input=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_data, subj_csv):\n",
    "    '''\n",
    "    Test model using two different metrics. First is per sample accuracy.\n",
    "    Second is to use 40 samples per subject and perform voting:\n",
    "        If mean prediction > 0.5, classify as female (1)\n",
    "        Otherwise, classify as male (0)\n",
    "    param:\n",
    "        model: A trained PyTorch Module\n",
    "        test_data: test dataset\n",
    "        subj_csv: spreadsheet containing subject IDs for the test dataset\n",
    "    '''\n",
    "    # one-segment test\n",
    "    logger.log('Testing model accuracy using 1-segment metric')\n",
    "    loader_test = DataLoader(test_data, batch_size=70)\n",
    "    per_sample_acc = check_accuracy(loader_test, model)\n",
    "\n",
    "    # 40-segment test\n",
    "    logger.log('Testing model accuracy using 40-segment per subject metric')\n",
    "    with open(subj_csv, newline='') as csvfile:\n",
    "        spamreader = csv.reader(csvfile, delimiter=' ', quotechar='|')\n",
    "        subjIDs = [row[0] for row in spamreader]\n",
    "    unique_subjs,indices = np.unique(subjIDs,return_index=True)\n",
    "\n",
    "    iterable_test_data = list(iter(DataLoader(test_data, batch_size=1)))\n",
    "    num_correct = []\n",
    "    for subj,idx in zip(unique_subjs,indices):\n",
    "    #     print(f'Subj {subj} - gender {iterable_test_data[idx][1]}')\n",
    "        data = iterable_test_data[idx:idx+40]\n",
    "        #print(np.sum([y for _,y in data]))\n",
    "        assert 40 == np.sum([y for _,y in data]) or 0 == np.sum([y for _,y in data])\n",
    "        preds = []\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for x,y in data:\n",
    "                x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "                correct = y\n",
    "                scores = model(x)\n",
    "                _, pred = scores.max(1)\n",
    "                preds.append(pred)\n",
    "        final_pred = (torch.mean(torch.FloatTensor(preds)) > 0.5).sum()\n",
    "        num_correct.append((final_pred == correct).sum())\n",
    "    #print(len(num_correct))\n",
    "    acc = float(np.sum(num_correct)) / len(unique_subjs)\n",
    "    logger.log('Got %d / %d correct (%.2f)' % (np.sum(num_correct), len(unique_subjs), 100 * acc))\n",
    "    return per_sample_acc, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(seed, model_name, feature, loader_train, loader_val, num_epoch):\n",
    "    '''\n",
    "    Train a model for num_epoch given a random seed. \n",
    "    During training, logs and intemediary models will be saved in files accordingly to model_name\n",
    "    param:\n",
    "        seed: Int - Random seed number\n",
    "        model_name: String - Name of the model to be saved. Used for logging\n",
    "        feature: String - Whether 'raw' or 'topo'\n",
    "        loader_train: DataLoader with training set\n",
    "        loader_val: DataLoader with validation set\n",
    "        num_epoch: Int - number of epoch to train the model\n",
    "    '''\n",
    "    model = create_model()\n",
    "    logger.set_model_save_location(f'{model_name}-{feature}')\n",
    "    experiment = f'{model_name}-{feature}-seed{seed}'\n",
    "    logger.set_experiment(experiment)\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    # toggle between learning rate and batch size values \n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    model = train(model, loader_train, loader_val, optimizer, epochs=num_epoch)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "ZSqENpKfB2UE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/02 03:12:02 PM Epoch 0, Iteration 0, loss = 3.6760\n",
      "06/02 03:12:04 PM Epoch 0, Iteration 100, loss = 0.6712\n",
      "06/02 03:12:05 PM Epoch 0, Iteration 200, loss = 0.6404\n",
      "06/02 03:12:05 PM Checking accuracy on training set\n",
      "06/02 03:12:07 PM Loss (0.623404)\n",
      "06/02 03:12:07 PM Got 43648 / 71381 correct (61.15)\n",
      "06/02 03:12:07 PM Checking accuracy on validation set\n",
      "06/02 03:12:07 PM Loss (0.511939)\n",
      "06/02 03:12:07 PM Got 24985 / 39868 correct (62.67)\n",
      "06/02 03:12:07 PM \n",
      "06/02 03:12:07 PM Epoch 1, Iteration 0, loss = 0.6282\n",
      "06/02 03:12:08 PM Epoch 1, Iteration 100, loss = 0.5869\n",
      "06/02 03:12:09 PM Epoch 1, Iteration 200, loss = 0.5723\n",
      "06/02 03:12:10 PM Checking accuracy on training set\n",
      "06/02 03:12:11 PM Loss (0.603270)\n",
      "06/02 03:12:11 PM Got 43665 / 71381 correct (61.17)\n",
      "06/02 03:12:11 PM Checking accuracy on validation set\n",
      "06/02 03:12:12 PM Loss (0.331841)\n",
      "06/02 03:12:12 PM Got 24985 / 39868 correct (62.67)\n",
      "06/02 03:12:12 PM \n",
      "06/02 03:12:12 PM Epoch 2, Iteration 0, loss = 0.5861\n",
      "06/02 03:12:13 PM Epoch 2, Iteration 100, loss = 0.5724\n",
      "06/02 03:12:14 PM Epoch 2, Iteration 200, loss = 0.5582\n",
      "06/02 03:12:15 PM Checking accuracy on training set\n",
      "06/02 03:12:16 PM Loss (0.590087)\n",
      "06/02 03:12:16 PM Got 43690 / 71381 correct (61.21)\n",
      "06/02 03:12:16 PM Checking accuracy on validation set\n",
      "06/02 03:12:17 PM Loss (0.296442)\n",
      "06/02 03:12:17 PM Got 24984 / 39868 correct (62.67)\n",
      "06/02 03:12:17 PM \n",
      "06/02 03:12:17 PM Epoch 3, Iteration 0, loss = 0.5478\n",
      "06/02 03:12:18 PM Epoch 3, Iteration 100, loss = 0.5540\n",
      "06/02 03:12:19 PM Epoch 3, Iteration 200, loss = 0.5650\n",
      "06/02 03:12:20 PM Checking accuracy on training set\n",
      "06/02 03:12:21 PM Loss (0.575031)\n",
      "06/02 03:12:21 PM Got 43724 / 71381 correct (61.25)\n",
      "06/02 03:12:21 PM Checking accuracy on validation set\n",
      "06/02 03:12:22 PM Loss (0.293402)\n",
      "06/02 03:12:22 PM Got 24956 / 39868 correct (62.60)\n",
      "06/02 03:12:22 PM \n",
      "06/02 03:12:22 PM Epoch 4, Iteration 0, loss = 0.6166\n",
      "06/02 03:12:23 PM Epoch 4, Iteration 100, loss = 0.5943\n",
      "06/02 03:12:24 PM Epoch 4, Iteration 200, loss = 0.5777\n",
      "06/02 03:12:24 PM Checking accuracy on training set\n",
      "06/02 03:12:26 PM Loss (0.523434)\n",
      "06/02 03:12:26 PM Got 43893 / 71381 correct (61.49)\n",
      "06/02 03:12:26 PM Checking accuracy on validation set\n",
      "06/02 03:12:26 PM Loss (0.267831)\n",
      "06/02 03:12:26 PM Got 24884 / 39868 correct (62.42)\n",
      "06/02 03:12:26 PM \n",
      "06/02 03:12:26 PM Epoch 5, Iteration 0, loss = 0.5514\n",
      "06/02 03:12:27 PM Epoch 5, Iteration 100, loss = 0.5074\n",
      "06/02 03:12:28 PM Epoch 5, Iteration 200, loss = 0.5264\n",
      "06/02 03:12:29 PM Checking accuracy on training set\n",
      "06/02 03:12:30 PM Loss (0.517900)\n",
      "06/02 03:12:30 PM Got 50245 / 71381 correct (70.39)\n",
      "06/02 03:12:30 PM Checking accuracy on validation set\n",
      "06/02 03:12:31 PM Loss (0.236656)\n",
      "06/02 03:12:31 PM Got 27743 / 39868 correct (69.59)\n",
      "06/02 03:12:31 PM \n",
      "06/02 03:12:31 PM Epoch 6, Iteration 0, loss = 0.5479\n",
      "06/02 03:12:32 PM Epoch 6, Iteration 100, loss = 0.4601\n",
      "06/02 03:12:33 PM Epoch 6, Iteration 200, loss = 0.4920\n",
      "06/02 03:12:34 PM Checking accuracy on training set\n",
      "06/02 03:12:35 PM Loss (0.482553)\n",
      "06/02 03:12:35 PM Got 49860 / 71381 correct (69.85)\n",
      "06/02 03:12:35 PM Checking accuracy on validation set\n",
      "06/02 03:12:36 PM Loss (0.213027)\n",
      "06/02 03:12:36 PM Got 27840 / 39868 correct (69.83)\n",
      "06/02 03:12:36 PM \n",
      "06/02 03:12:36 PM Epoch 7, Iteration 0, loss = 0.5128\n",
      "06/02 03:12:37 PM Epoch 7, Iteration 100, loss = 0.5555\n",
      "06/02 03:12:38 PM Epoch 7, Iteration 200, loss = 0.4968\n",
      "06/02 03:12:39 PM Checking accuracy on training set\n",
      "06/02 03:12:40 PM Loss (0.476114)\n",
      "06/02 03:12:40 PM Got 50543 / 71381 correct (70.81)\n",
      "06/02 03:12:40 PM Checking accuracy on validation set\n",
      "06/02 03:12:41 PM Loss (0.203566)\n",
      "06/02 03:12:41 PM Got 27735 / 39868 correct (69.57)\n",
      "06/02 03:12:41 PM \n",
      "06/02 03:12:41 PM Epoch 8, Iteration 0, loss = 0.4385\n",
      "06/02 03:12:42 PM Epoch 8, Iteration 100, loss = 0.5169\n",
      "06/02 03:12:43 PM Epoch 8, Iteration 200, loss = 0.4866\n",
      "06/02 03:12:43 PM Checking accuracy on training set\n",
      "06/02 03:12:45 PM Loss (0.522441)\n",
      "06/02 03:12:45 PM Got 53396 / 71381 correct (74.80)\n",
      "06/02 03:12:45 PM Checking accuracy on validation set\n",
      "06/02 03:12:45 PM Loss (0.254915)\n",
      "06/02 03:12:45 PM Got 28693 / 39868 correct (71.97)\n",
      "06/02 03:12:45 PM \n",
      "06/02 03:12:45 PM Epoch 9, Iteration 0, loss = 0.4587\n",
      "06/02 03:12:46 PM Epoch 9, Iteration 100, loss = 0.5123\n",
      "06/02 03:12:47 PM Epoch 9, Iteration 200, loss = 0.4578\n",
      "06/02 03:12:48 PM Checking accuracy on training set\n",
      "06/02 03:12:49 PM Loss (0.454306)\n",
      "06/02 03:12:49 PM Got 53721 / 71381 correct (75.26)\n",
      "06/02 03:12:49 PM Checking accuracy on validation set\n",
      "06/02 03:12:50 PM Loss (0.226312)\n",
      "06/02 03:12:50 PM Got 28865 / 39868 correct (72.40)\n",
      "06/02 03:12:50 PM \n",
      "06/02 03:12:50 PM Epoch 10, Iteration 0, loss = 0.4877\n",
      "06/02 03:12:51 PM Epoch 10, Iteration 100, loss = 0.4877\n",
      "06/02 03:12:52 PM Epoch 10, Iteration 200, loss = 0.4699\n",
      "06/02 03:12:53 PM Checking accuracy on training set\n",
      "06/02 03:12:54 PM Loss (0.536058)\n",
      "06/02 03:12:54 PM Got 51871 / 71381 correct (72.67)\n",
      "06/02 03:12:54 PM Checking accuracy on validation set\n",
      "06/02 03:12:55 PM Loss (0.295173)\n",
      "06/02 03:12:55 PM Got 28418 / 39868 correct (71.28)\n",
      "06/02 03:12:55 PM \n",
      "06/02 03:12:55 PM Epoch 11, Iteration 0, loss = 0.4860\n",
      "06/02 03:12:56 PM Epoch 11, Iteration 100, loss = 0.5225\n",
      "06/02 03:12:57 PM Epoch 11, Iteration 200, loss = 0.4551\n",
      "06/02 03:12:58 PM Checking accuracy on training set\n",
      "06/02 03:12:59 PM Loss (0.453795)\n",
      "06/02 03:12:59 PM Got 53787 / 71381 correct (75.35)\n",
      "06/02 03:12:59 PM Checking accuracy on validation set\n",
      "06/02 03:13:00 PM Loss (0.240493)\n",
      "06/02 03:13:00 PM Got 29022 / 39868 correct (72.80)\n",
      "06/02 03:13:00 PM \n",
      "06/02 03:13:00 PM Epoch 12, Iteration 0, loss = 0.4145\n",
      "06/02 03:13:01 PM Epoch 12, Iteration 100, loss = 0.4820\n",
      "06/02 03:13:02 PM Epoch 12, Iteration 200, loss = 0.5538\n",
      "06/02 03:13:03 PM Checking accuracy on training set\n",
      "06/02 03:13:04 PM Loss (0.435561)\n",
      "06/02 03:13:04 PM Got 54013 / 71381 correct (75.67)\n",
      "06/02 03:13:04 PM Checking accuracy on validation set\n",
      "06/02 03:13:04 PM Loss (0.195619)\n",
      "06/02 03:13:04 PM Got 29136 / 39868 correct (73.08)\n",
      "06/02 03:13:04 PM \n",
      "06/02 03:13:05 PM Epoch 13, Iteration 0, loss = 0.4131\n",
      "06/02 03:13:06 PM Epoch 13, Iteration 100, loss = 0.3806\n",
      "06/02 03:13:07 PM Epoch 13, Iteration 200, loss = 0.4545\n",
      "06/02 03:13:07 PM Checking accuracy on training set\n",
      "06/02 03:13:09 PM Loss (0.434185)\n",
      "06/02 03:13:09 PM Got 54474 / 71381 correct (76.31)\n",
      "06/02 03:13:09 PM Checking accuracy on validation set\n",
      "06/02 03:13:09 PM Loss (0.207613)\n",
      "06/02 03:13:09 PM Got 29117 / 39868 correct (73.03)\n",
      "06/02 03:13:09 PM \n",
      "06/02 03:13:09 PM Epoch 14, Iteration 0, loss = 0.4135\n",
      "06/02 03:13:10 PM Epoch 14, Iteration 100, loss = 0.4412\n",
      "06/02 03:13:11 PM Epoch 14, Iteration 200, loss = 0.4574\n",
      "06/02 03:13:12 PM Checking accuracy on training set\n",
      "06/02 03:13:13 PM Loss (0.504290)\n",
      "06/02 03:13:13 PM Got 54157 / 71381 correct (75.87)\n",
      "06/02 03:13:13 PM Checking accuracy on validation set\n",
      "06/02 03:13:14 PM Loss (0.206219)\n",
      "06/02 03:13:14 PM Got 29110 / 39868 correct (73.02)\n",
      "06/02 03:13:14 PM \n",
      "06/02 03:13:14 PM Epoch 15, Iteration 0, loss = 0.4554\n",
      "06/02 03:13:15 PM Epoch 15, Iteration 100, loss = 0.4885\n",
      "06/02 03:13:16 PM Epoch 15, Iteration 200, loss = 0.4841\n",
      "06/02 03:13:17 PM Checking accuracy on training set\n",
      "06/02 03:13:18 PM Loss (0.441755)\n",
      "06/02 03:13:18 PM Got 53687 / 71381 correct (75.21)\n",
      "06/02 03:13:18 PM Checking accuracy on validation set\n",
      "06/02 03:13:19 PM Loss (0.175747)\n",
      "06/02 03:13:19 PM Got 28899 / 39868 correct (72.49)\n",
      "06/02 03:13:19 PM \n",
      "06/02 03:13:19 PM Epoch 16, Iteration 0, loss = 0.4084\n",
      "06/02 03:13:20 PM Epoch 16, Iteration 100, loss = 0.4570\n",
      "06/02 03:13:21 PM Epoch 16, Iteration 200, loss = 0.4373\n",
      "06/02 03:13:22 PM Checking accuracy on training set\n",
      "06/02 03:13:23 PM Loss (0.416083)\n",
      "06/02 03:13:23 PM Got 54482 / 71381 correct (76.33)\n",
      "06/02 03:13:23 PM Checking accuracy on validation set\n",
      "06/02 03:13:24 PM Loss (0.194052)\n",
      "06/02 03:13:24 PM Got 29139 / 39868 correct (73.09)\n",
      "06/02 03:13:24 PM \n",
      "06/02 03:13:24 PM Epoch 17, Iteration 0, loss = 0.4297\n",
      "06/02 03:13:25 PM Epoch 17, Iteration 100, loss = 0.4799\n",
      "06/02 03:13:26 PM Epoch 17, Iteration 200, loss = 0.4736\n",
      "06/02 03:13:27 PM Checking accuracy on training set\n",
      "06/02 03:13:28 PM Loss (0.421755)\n",
      "06/02 03:13:28 PM Got 54913 / 71381 correct (76.93)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/02 03:13:28 PM Checking accuracy on validation set\n",
      "06/02 03:13:29 PM Loss (0.230521)\n",
      "06/02 03:13:29 PM Got 29199 / 39868 correct (73.24)\n",
      "06/02 03:13:29 PM \n",
      "06/02 03:13:29 PM Epoch 18, Iteration 0, loss = 0.4470\n",
      "06/02 03:13:30 PM Epoch 18, Iteration 100, loss = 0.4248\n",
      "06/02 03:13:31 PM Epoch 18, Iteration 200, loss = 0.3990\n",
      "06/02 03:13:31 PM Checking accuracy on training set\n",
      "06/02 03:13:33 PM Loss (0.447157)\n",
      "06/02 03:13:33 PM Got 55176 / 71381 correct (77.30)\n",
      "06/02 03:13:33 PM Checking accuracy on validation set\n",
      "06/02 03:13:33 PM Loss (0.205809)\n",
      "06/02 03:13:33 PM Got 29198 / 39868 correct (73.24)\n",
      "06/02 03:13:33 PM \n",
      "06/02 03:13:33 PM Epoch 19, Iteration 0, loss = 0.3963\n",
      "06/02 03:13:34 PM Epoch 19, Iteration 100, loss = 0.4277\n",
      "06/02 03:13:35 PM Epoch 19, Iteration 200, loss = 0.4089\n",
      "06/02 03:13:36 PM Checking accuracy on training set\n",
      "06/02 03:13:37 PM Loss (0.409553)\n",
      "06/02 03:13:37 PM Got 54869 / 71381 correct (76.87)\n",
      "06/02 03:13:37 PM Checking accuracy on validation set\n",
      "06/02 03:13:38 PM Loss (0.178660)\n",
      "06/02 03:13:38 PM Got 29129 / 39868 correct (73.06)\n",
      "06/02 03:13:38 PM \n",
      "06/02 03:13:38 PM Epoch 20, Iteration 0, loss = 0.4211\n",
      "06/02 03:13:39 PM Epoch 20, Iteration 100, loss = 0.4822\n",
      "06/02 03:13:40 PM Epoch 20, Iteration 200, loss = 0.4858\n",
      "06/02 03:13:41 PM Checking accuracy on training set\n",
      "06/02 03:13:42 PM Loss (0.441907)\n",
      "06/02 03:13:42 PM Got 55091 / 71381 correct (77.18)\n",
      "06/02 03:13:42 PM Checking accuracy on validation set\n",
      "06/02 03:13:43 PM Loss (0.180333)\n",
      "06/02 03:13:43 PM Got 29044 / 39868 correct (72.85)\n",
      "06/02 03:13:43 PM \n",
      "06/02 03:13:43 PM Epoch 21, Iteration 0, loss = 0.4182\n",
      "06/02 03:13:44 PM Epoch 21, Iteration 100, loss = 0.3889\n",
      "06/02 03:13:45 PM Epoch 21, Iteration 200, loss = 0.4564\n",
      "06/02 03:13:46 PM Checking accuracy on training set\n",
      "06/02 03:13:47 PM Loss (0.419633)\n",
      "06/02 03:13:47 PM Got 56374 / 71381 correct (78.98)\n",
      "06/02 03:13:47 PM Checking accuracy on validation set\n",
      "06/02 03:13:48 PM Loss (0.165624)\n",
      "06/02 03:13:48 PM Got 29378 / 39868 correct (73.69)\n",
      "06/02 03:13:48 PM \n",
      "06/02 03:13:48 PM Epoch 22, Iteration 0, loss = 0.4534\n",
      "06/02 03:13:49 PM Epoch 22, Iteration 100, loss = 0.5724\n",
      "06/02 03:13:50 PM Epoch 22, Iteration 200, loss = 0.4211\n",
      "06/02 03:13:51 PM Checking accuracy on training set\n",
      "06/02 03:13:52 PM Loss (0.477431)\n",
      "06/02 03:13:52 PM Got 56795 / 71381 correct (79.57)\n",
      "06/02 03:13:52 PM Checking accuracy on validation set\n",
      "06/02 03:13:53 PM Loss (0.210225)\n",
      "06/02 03:13:53 PM Got 29587 / 39868 correct (74.21)\n",
      "06/02 03:13:53 PM \n",
      "06/02 03:13:53 PM Epoch 23, Iteration 0, loss = 0.4211\n",
      "06/02 03:13:54 PM Epoch 23, Iteration 100, loss = 0.4015\n",
      "06/02 03:13:55 PM Epoch 23, Iteration 200, loss = 0.4177\n",
      "06/02 03:13:55 PM Checking accuracy on training set\n",
      "06/02 03:13:57 PM Loss (0.354179)\n",
      "06/02 03:13:57 PM Got 56152 / 71381 correct (78.67)\n",
      "06/02 03:13:57 PM Checking accuracy on validation set\n",
      "06/02 03:13:57 PM Loss (0.181221)\n",
      "06/02 03:13:57 PM Got 29266 / 39868 correct (73.41)\n",
      "06/02 03:13:57 PM \n",
      "06/02 03:13:57 PM Epoch 24, Iteration 0, loss = 0.3931\n",
      "06/02 03:13:58 PM Epoch 24, Iteration 100, loss = 0.3635\n",
      "06/02 03:13:59 PM Epoch 24, Iteration 200, loss = 0.5003\n",
      "06/02 03:14:00 PM Checking accuracy on training set\n",
      "06/02 03:14:02 PM Loss (0.401343)\n",
      "06/02 03:14:02 PM Got 56173 / 71381 correct (78.69)\n",
      "06/02 03:14:02 PM Checking accuracy on validation set\n",
      "06/02 03:14:02 PM Loss (0.171922)\n",
      "06/02 03:14:02 PM Got 29304 / 39868 correct (73.50)\n",
      "06/02 03:14:02 PM \n",
      "06/02 03:14:02 PM Epoch 25, Iteration 0, loss = 0.4543\n",
      "06/02 03:14:03 PM Epoch 25, Iteration 100, loss = 0.3816\n",
      "06/02 03:14:04 PM Epoch 25, Iteration 200, loss = 0.4489\n",
      "06/02 03:14:05 PM Checking accuracy on training set\n",
      "06/02 03:14:06 PM Loss (0.356937)\n",
      "06/02 03:14:06 PM Got 57370 / 71381 correct (80.37)\n",
      "06/02 03:14:06 PM Checking accuracy on validation set\n",
      "06/02 03:14:07 PM Loss (0.193239)\n",
      "06/02 03:14:07 PM Got 29452 / 39868 correct (73.87)\n",
      "06/02 03:14:07 PM \n",
      "06/02 03:14:07 PM Epoch 26, Iteration 0, loss = 0.3872\n",
      "06/02 03:14:08 PM Epoch 26, Iteration 100, loss = 0.3799\n",
      "06/02 03:14:09 PM Epoch 26, Iteration 200, loss = 0.4806\n",
      "06/02 03:14:10 PM Checking accuracy on training set\n",
      "06/02 03:14:11 PM Loss (0.432031)\n",
      "06/02 03:14:11 PM Got 54341 / 71381 correct (76.13)\n",
      "06/02 03:14:11 PM Checking accuracy on validation set\n",
      "06/02 03:14:12 PM Loss (0.211695)\n",
      "06/02 03:14:12 PM Got 29050 / 39868 correct (72.87)\n",
      "06/02 03:14:12 PM \n",
      "06/02 03:14:12 PM Epoch 27, Iteration 0, loss = 0.5801\n",
      "06/02 03:14:13 PM Epoch 27, Iteration 100, loss = 0.4193\n",
      "06/02 03:14:14 PM Epoch 27, Iteration 200, loss = 0.4433\n",
      "06/02 03:14:15 PM Checking accuracy on training set\n",
      "06/02 03:14:16 PM Loss (0.412120)\n",
      "06/02 03:14:16 PM Got 57148 / 71381 correct (80.06)\n",
      "06/02 03:14:16 PM Checking accuracy on validation set\n",
      "06/02 03:14:17 PM Loss (0.193712)\n",
      "06/02 03:14:17 PM Got 29494 / 39868 correct (73.98)\n",
      "06/02 03:14:17 PM \n",
      "06/02 03:14:17 PM Epoch 28, Iteration 0, loss = 0.3694\n",
      "06/02 03:14:18 PM Epoch 28, Iteration 100, loss = 0.4443\n",
      "06/02 03:14:19 PM Epoch 28, Iteration 200, loss = 0.4408\n",
      "06/02 03:14:19 PM Checking accuracy on training set\n",
      "06/02 03:14:21 PM Loss (0.383353)\n",
      "06/02 03:14:21 PM Got 57351 / 71381 correct (80.34)\n",
      "06/02 03:14:21 PM Checking accuracy on validation set\n",
      "06/02 03:14:21 PM Loss (0.202483)\n",
      "06/02 03:14:21 PM Got 29552 / 39868 correct (74.12)\n",
      "06/02 03:14:21 PM \n",
      "06/02 03:14:21 PM Epoch 29, Iteration 0, loss = 0.3693\n",
      "06/02 03:14:23 PM Epoch 29, Iteration 100, loss = 0.4484\n",
      "06/02 03:14:24 PM Epoch 29, Iteration 200, loss = 0.4661\n",
      "06/02 03:14:24 PM Checking accuracy on training set\n",
      "06/02 03:14:26 PM Loss (0.461134)\n",
      "06/02 03:14:26 PM Got 55767 / 71381 correct (78.13)\n",
      "06/02 03:14:26 PM Checking accuracy on validation set\n",
      "06/02 03:14:26 PM Loss (0.208497)\n",
      "06/02 03:14:26 PM Got 29233 / 39868 correct (73.32)\n",
      "06/02 03:14:26 PM \n",
      "06/02 03:14:26 PM Epoch 30, Iteration 0, loss = 0.4268\n",
      "06/02 03:14:27 PM Epoch 30, Iteration 100, loss = 0.4229\n",
      "06/02 03:14:28 PM Epoch 30, Iteration 200, loss = 0.3889\n",
      "06/02 03:14:29 PM Checking accuracy on training set\n",
      "06/02 03:14:30 PM Loss (0.371846)\n",
      "06/02 03:14:30 PM Got 57505 / 71381 correct (80.56)\n",
      "06/02 03:14:30 PM Checking accuracy on validation set\n",
      "06/02 03:14:31 PM Loss (0.194883)\n",
      "06/02 03:14:31 PM Got 29448 / 39868 correct (73.86)\n",
      "06/02 03:14:31 PM \n",
      "06/02 03:14:31 PM Epoch 31, Iteration 0, loss = 0.3341\n",
      "06/02 03:14:32 PM Epoch 31, Iteration 100, loss = 0.4063\n",
      "06/02 03:14:33 PM Epoch 31, Iteration 200, loss = 0.4137\n",
      "06/02 03:14:34 PM Checking accuracy on training set\n",
      "06/02 03:14:35 PM Loss (0.448370)\n",
      "06/02 03:14:35 PM Got 57444 / 71381 correct (80.48)\n",
      "06/02 03:14:35 PM Checking accuracy on validation set\n",
      "06/02 03:14:36 PM Loss (0.274590)\n",
      "06/02 03:14:36 PM Got 29368 / 39868 correct (73.66)\n",
      "06/02 03:14:36 PM \n",
      "06/02 03:14:36 PM Epoch 32, Iteration 0, loss = 0.3579\n",
      "06/02 03:14:37 PM Epoch 32, Iteration 100, loss = 0.3788\n",
      "06/02 03:14:38 PM Epoch 32, Iteration 200, loss = 0.3242\n",
      "06/02 03:14:39 PM Checking accuracy on training set\n",
      "06/02 03:14:40 PM Loss (0.328033)\n",
      "06/02 03:14:40 PM Got 58107 / 71381 correct (81.40)\n",
      "06/02 03:14:40 PM Checking accuracy on validation set\n",
      "06/02 03:14:41 PM Loss (0.188601)\n",
      "06/02 03:14:41 PM Got 29418 / 39868 correct (73.79)\n",
      "06/02 03:14:41 PM \n",
      "06/02 03:14:41 PM Epoch 33, Iteration 0, loss = 0.3805\n",
      "06/02 03:14:42 PM Epoch 33, Iteration 100, loss = 0.3814\n",
      "06/02 03:14:43 PM Epoch 33, Iteration 200, loss = 0.4114\n",
      "06/02 03:14:43 PM Checking accuracy on training set\n",
      "06/02 03:14:45 PM Loss (0.406398)\n",
      "06/02 03:14:45 PM Got 58992 / 71381 correct (82.64)\n",
      "06/02 03:14:45 PM Checking accuracy on validation set\n",
      "06/02 03:14:45 PM Loss (0.183201)\n",
      "06/02 03:14:45 PM Got 29545 / 39868 correct (74.11)\n",
      "06/02 03:14:45 PM \n",
      "06/02 03:14:45 PM Epoch 34, Iteration 0, loss = 0.3336\n",
      "06/02 03:14:46 PM Epoch 34, Iteration 100, loss = 0.3064\n",
      "06/02 03:14:47 PM Epoch 34, Iteration 200, loss = 0.3468\n",
      "06/02 03:14:48 PM Checking accuracy on training set\n",
      "06/02 03:14:49 PM Loss (0.338204)\n",
      "06/02 03:14:49 PM Got 59258 / 71381 correct (83.02)\n",
      "06/02 03:14:49 PM Checking accuracy on validation set\n",
      "06/02 03:14:50 PM Loss (0.173147)\n",
      "06/02 03:14:50 PM Got 29503 / 39868 correct (74.00)\n",
      "06/02 03:14:50 PM \n",
      "06/02 03:14:50 PM Epoch 35, Iteration 0, loss = 0.3231\n",
      "06/02 03:14:51 PM Epoch 35, Iteration 100, loss = 0.4015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/02 03:14:52 PM Epoch 35, Iteration 200, loss = 0.4177\n",
      "06/02 03:14:53 PM Checking accuracy on training set\n",
      "06/02 03:14:54 PM Loss (0.443213)\n",
      "06/02 03:14:54 PM Got 55505 / 71381 correct (77.76)\n",
      "06/02 03:14:54 PM Checking accuracy on validation set\n",
      "06/02 03:14:55 PM Loss (0.248284)\n",
      "06/02 03:14:55 PM Got 29090 / 39868 correct (72.97)\n",
      "06/02 03:14:55 PM \n",
      "06/02 03:14:55 PM Epoch 36, Iteration 0, loss = 0.5313\n",
      "06/02 03:14:56 PM Epoch 36, Iteration 100, loss = 0.4572\n",
      "06/02 03:14:57 PM Epoch 36, Iteration 200, loss = 0.4268\n",
      "06/02 03:14:58 PM Checking accuracy on training set\n",
      "06/02 03:14:59 PM Loss (0.412718)\n",
      "06/02 03:14:59 PM Got 57414 / 71381 correct (80.43)\n",
      "06/02 03:14:59 PM Checking accuracy on validation set\n",
      "06/02 03:15:00 PM Loss (0.203428)\n",
      "06/02 03:15:00 PM Got 29197 / 39868 correct (73.23)\n",
      "06/02 03:15:00 PM \n",
      "06/02 03:15:00 PM Epoch 37, Iteration 0, loss = 0.3778\n",
      "06/02 03:15:01 PM Epoch 37, Iteration 100, loss = 0.3529\n",
      "06/02 03:15:02 PM Epoch 37, Iteration 200, loss = 0.4029\n",
      "06/02 03:15:03 PM Checking accuracy on training set\n",
      "06/02 03:15:04 PM Loss (0.370065)\n",
      "06/02 03:15:04 PM Got 58278 / 71381 correct (81.64)\n",
      "06/02 03:15:04 PM Checking accuracy on validation set\n",
      "06/02 03:15:04 PM Loss (0.225921)\n",
      "06/02 03:15:04 PM Got 29291 / 39868 correct (73.47)\n",
      "06/02 03:15:04 PM \n",
      "06/02 03:15:05 PM Epoch 38, Iteration 0, loss = 0.3176\n",
      "06/02 03:15:06 PM Epoch 38, Iteration 100, loss = 0.3600\n",
      "06/02 03:15:07 PM Epoch 38, Iteration 200, loss = 0.3239\n",
      "06/02 03:15:07 PM Checking accuracy on training set\n",
      "06/02 03:15:09 PM Loss (0.374413)\n",
      "06/02 03:15:09 PM Got 59001 / 71381 correct (82.66)\n",
      "06/02 03:15:09 PM Checking accuracy on validation set\n",
      "06/02 03:15:09 PM Loss (0.183464)\n",
      "06/02 03:15:09 PM Got 29370 / 39868 correct (73.67)\n",
      "06/02 03:15:09 PM \n",
      "06/02 03:15:09 PM Epoch 39, Iteration 0, loss = 0.3267\n",
      "06/02 03:15:10 PM Epoch 39, Iteration 100, loss = 0.3770\n",
      "06/02 03:15:11 PM Epoch 39, Iteration 200, loss = 0.3543\n",
      "06/02 03:15:12 PM Checking accuracy on training set\n",
      "06/02 03:15:13 PM Loss (0.335889)\n",
      "06/02 03:15:13 PM Got 60024 / 71381 correct (84.09)\n",
      "06/02 03:15:13 PM Checking accuracy on validation set\n",
      "06/02 03:15:14 PM Loss (0.189312)\n",
      "06/02 03:15:14 PM Got 29306 / 39868 correct (73.51)\n",
      "06/02 03:15:14 PM \n",
      "06/02 03:15:14 PM Epoch 0, Iteration 0, loss = 1.3479\n",
      "06/02 03:15:15 PM Epoch 0, Iteration 100, loss = 0.6280\n",
      "06/02 03:15:16 PM Epoch 0, Iteration 200, loss = 0.5377\n",
      "06/02 03:15:17 PM Checking accuracy on training set\n",
      "06/02 03:15:18 PM Loss (0.565437)\n",
      "06/02 03:15:18 PM Got 43757 / 71381 correct (61.30)\n",
      "06/02 03:15:18 PM Checking accuracy on validation set\n",
      "06/02 03:15:19 PM Loss (0.289143)\n",
      "06/02 03:15:19 PM Got 24946 / 39868 correct (62.57)\n",
      "06/02 03:15:19 PM \n",
      "06/02 03:15:19 PM Epoch 1, Iteration 0, loss = 0.6030\n",
      "06/02 03:15:20 PM Epoch 1, Iteration 100, loss = 0.5477\n",
      "06/02 03:15:21 PM Epoch 1, Iteration 200, loss = 0.5209\n",
      "06/02 03:15:22 PM Checking accuracy on training set\n",
      "06/02 03:15:23 PM Loss (0.510728)\n",
      "06/02 03:15:23 PM Got 45842 / 71381 correct (64.22)\n",
      "06/02 03:15:23 PM Checking accuracy on validation set\n",
      "06/02 03:15:24 PM Loss (0.225615)\n",
      "06/02 03:15:24 PM Got 25912 / 39868 correct (64.99)\n",
      "06/02 03:15:24 PM \n",
      "06/02 03:15:24 PM Epoch 2, Iteration 0, loss = 0.5243\n",
      "06/02 03:15:25 PM Epoch 2, Iteration 100, loss = 0.5278\n",
      "06/02 03:15:26 PM Epoch 2, Iteration 200, loss = 0.5112\n",
      "06/02 03:15:26 PM Checking accuracy on training set\n",
      "06/02 03:15:28 PM Loss (0.557155)\n",
      "06/02 03:15:28 PM Got 47666 / 71381 correct (66.78)\n",
      "06/02 03:15:28 PM Checking accuracy on validation set\n",
      "06/02 03:15:28 PM Loss (0.258379)\n",
      "06/02 03:15:28 PM Got 26726 / 39868 correct (67.04)\n",
      "06/02 03:15:28 PM \n",
      "06/02 03:15:28 PM Epoch 3, Iteration 0, loss = 0.5046\n",
      "06/02 03:15:29 PM Epoch 3, Iteration 100, loss = 0.4831\n",
      "06/02 03:15:30 PM Epoch 3, Iteration 200, loss = 0.5806\n",
      "06/02 03:15:31 PM Checking accuracy on training set\n",
      "06/02 03:15:32 PM Loss (0.585077)\n",
      "06/02 03:15:32 PM Got 43769 / 71381 correct (61.32)\n",
      "06/02 03:15:32 PM Checking accuracy on validation set\n",
      "06/02 03:15:33 PM Loss (0.296501)\n",
      "06/02 03:15:33 PM Got 25016 / 39868 correct (62.75)\n",
      "06/02 03:15:33 PM \n",
      "06/02 03:15:33 PM Epoch 4, Iteration 0, loss = 0.5424\n",
      "06/02 03:15:34 PM Epoch 4, Iteration 100, loss = 0.5473\n",
      "06/02 03:15:35 PM Epoch 4, Iteration 200, loss = 0.5636\n",
      "06/02 03:15:36 PM Checking accuracy on training set\n",
      "06/02 03:15:37 PM Loss (0.487939)\n",
      "06/02 03:15:37 PM Got 49487 / 71381 correct (69.33)\n",
      "06/02 03:15:37 PM Checking accuracy on validation set\n",
      "06/02 03:15:38 PM Loss (0.249386)\n",
      "06/02 03:15:38 PM Got 27468 / 39868 correct (68.90)\n",
      "06/02 03:15:38 PM \n",
      "06/02 03:15:38 PM Epoch 5, Iteration 0, loss = 0.4658\n",
      "06/02 03:15:39 PM Epoch 5, Iteration 100, loss = 0.4753\n",
      "06/02 03:15:40 PM Epoch 5, Iteration 200, loss = 0.4757\n",
      "06/02 03:15:41 PM Checking accuracy on training set\n",
      "06/02 03:15:42 PM Loss (0.472001)\n",
      "06/02 03:15:42 PM Got 51581 / 71381 correct (72.26)\n",
      "06/02 03:15:42 PM Checking accuracy on validation set\n",
      "06/02 03:15:43 PM Loss (0.238706)\n",
      "06/02 03:15:43 PM Got 28103 / 39868 correct (70.49)\n",
      "06/02 03:15:43 PM \n",
      "06/02 03:15:43 PM Epoch 6, Iteration 0, loss = 0.4964\n",
      "06/02 03:15:44 PM Epoch 6, Iteration 100, loss = 0.4955\n",
      "06/02 03:15:45 PM Epoch 6, Iteration 200, loss = 0.4659\n",
      "06/02 03:15:45 PM Checking accuracy on training set\n",
      "06/02 03:15:47 PM Loss (0.475320)\n",
      "06/02 03:15:47 PM Got 51893 / 71381 correct (72.70)\n",
      "06/02 03:15:47 PM Checking accuracy on validation set\n",
      "06/02 03:15:47 PM Loss (0.289781)\n",
      "06/02 03:15:47 PM Got 28049 / 39868 correct (70.35)\n",
      "06/02 03:15:47 PM \n",
      "06/02 03:15:47 PM Epoch 7, Iteration 0, loss = 0.4907\n",
      "06/02 03:15:48 PM Epoch 7, Iteration 100, loss = 0.4438\n",
      "06/02 03:15:49 PM Epoch 7, Iteration 200, loss = 0.5370\n",
      "06/02 03:15:50 PM Checking accuracy on training set\n",
      "06/02 03:15:51 PM Loss (0.485058)\n",
      "06/02 03:15:51 PM Got 52786 / 71381 correct (73.95)\n",
      "06/02 03:15:51 PM Checking accuracy on validation set\n",
      "06/02 03:15:52 PM Loss (0.305993)\n",
      "06/02 03:15:52 PM Got 28537 / 39868 correct (71.58)\n",
      "06/02 03:15:52 PM \n",
      "06/02 03:15:52 PM Epoch 8, Iteration 0, loss = 0.4431\n",
      "06/02 03:15:53 PM Epoch 8, Iteration 100, loss = 0.4498\n",
      "06/02 03:15:54 PM Epoch 8, Iteration 200, loss = 0.4786\n",
      "06/02 03:15:55 PM Checking accuracy on training set\n",
      "06/02 03:15:56 PM Loss (0.414877)\n",
      "06/02 03:15:56 PM Got 52385 / 71381 correct (73.39)\n",
      "06/02 03:15:56 PM Checking accuracy on validation set\n",
      "06/02 03:15:57 PM Loss (0.206170)\n",
      "06/02 03:15:57 PM Got 28629 / 39868 correct (71.81)\n",
      "06/02 03:15:57 PM \n",
      "06/02 03:15:57 PM Epoch 9, Iteration 0, loss = 0.4130\n",
      "06/02 03:15:58 PM Epoch 9, Iteration 100, loss = 0.4986\n",
      "06/02 03:15:59 PM Epoch 9, Iteration 200, loss = 0.4317\n",
      "06/02 03:16:00 PM Checking accuracy on training set\n",
      "06/02 03:16:01 PM Loss (0.640118)\n",
      "06/02 03:16:01 PM Got 42829 / 71381 correct (60.00)\n",
      "06/02 03:16:01 PM Checking accuracy on validation set\n",
      "06/02 03:16:02 PM Loss (0.435762)\n",
      "06/02 03:16:02 PM Got 24452 / 39868 correct (61.33)\n",
      "06/02 03:16:02 PM \n",
      "06/02 03:16:02 PM Epoch 10, Iteration 0, loss = 0.5976\n",
      "06/02 03:16:03 PM Epoch 10, Iteration 100, loss = 0.6906\n",
      "06/02 03:16:04 PM Epoch 10, Iteration 200, loss = 0.6127\n",
      "06/02 03:16:04 PM Checking accuracy on training set\n",
      "06/02 03:16:06 PM Loss (0.452671)\n",
      "06/02 03:16:06 PM Got 50903 / 71381 correct (71.31)\n",
      "06/02 03:16:06 PM Checking accuracy on validation set\n",
      "06/02 03:16:06 PM Loss (0.175178)\n",
      "06/02 03:16:06 PM Got 28015 / 39868 correct (70.27)\n",
      "06/02 03:16:06 PM \n",
      "06/02 03:16:06 PM Epoch 11, Iteration 0, loss = 0.5188\n",
      "06/02 03:16:07 PM Epoch 11, Iteration 100, loss = 0.5048\n",
      "06/02 03:16:08 PM Epoch 11, Iteration 200, loss = 0.4541\n",
      "06/02 03:16:09 PM Checking accuracy on training set\n",
      "06/02 03:16:10 PM Loss (0.474544)\n",
      "06/02 03:16:10 PM Got 52801 / 71381 correct (73.97)\n",
      "06/02 03:16:10 PM Checking accuracy on validation set\n",
      "06/02 03:16:11 PM Loss (0.192329)\n",
      "06/02 03:16:11 PM Got 28629 / 39868 correct (71.81)\n",
      "06/02 03:16:11 PM \n",
      "06/02 03:16:11 PM Epoch 12, Iteration 0, loss = 0.4795\n",
      "06/02 03:16:12 PM Epoch 12, Iteration 100, loss = 0.4308\n",
      "06/02 03:16:13 PM Epoch 12, Iteration 200, loss = 0.4187\n",
      "06/02 03:16:14 PM Checking accuracy on training set\n",
      "06/02 03:16:15 PM Loss (0.474203)\n",
      "06/02 03:16:15 PM Got 53137 / 71381 correct (74.44)\n",
      "06/02 03:16:15 PM Checking accuracy on validation set\n",
      "06/02 03:16:16 PM Loss (0.198967)\n",
      "06/02 03:16:16 PM Got 28782 / 39868 correct (72.19)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/02 03:16:16 PM \n",
      "06/02 03:16:16 PM Epoch 13, Iteration 0, loss = 0.4259\n",
      "06/02 03:16:17 PM Epoch 13, Iteration 100, loss = 0.5868\n",
      "06/02 03:16:18 PM Epoch 13, Iteration 200, loss = 0.5732\n",
      "06/02 03:16:19 PM Checking accuracy on training set\n",
      "06/02 03:16:20 PM Loss (0.545378)\n",
      "06/02 03:16:20 PM Got 46064 / 71381 correct (64.53)\n",
      "06/02 03:16:20 PM Checking accuracy on validation set\n",
      "06/02 03:16:21 PM Loss (0.309859)\n",
      "06/02 03:16:21 PM Got 26118 / 39868 correct (65.51)\n",
      "06/02 03:16:21 PM \n",
      "06/02 03:16:21 PM Epoch 14, Iteration 0, loss = 0.5862\n",
      "06/02 03:16:22 PM Epoch 14, Iteration 100, loss = 0.5047\n",
      "06/02 03:16:23 PM Epoch 14, Iteration 200, loss = 0.5243\n",
      "06/02 03:16:24 PM Checking accuracy on training set\n",
      "06/02 03:16:25 PM Loss (0.477283)\n",
      "06/02 03:16:25 PM Got 49927 / 71381 correct (69.94)\n",
      "06/02 03:16:25 PM Checking accuracy on validation set\n",
      "06/02 03:16:25 PM Loss (0.232216)\n",
      "06/02 03:16:25 PM Got 27488 / 39868 correct (68.95)\n",
      "06/02 03:16:25 PM \n",
      "06/02 03:16:25 PM Epoch 15, Iteration 0, loss = 0.5075\n",
      "06/02 03:16:26 PM Epoch 15, Iteration 100, loss = 0.5087\n",
      "06/02 03:16:28 PM Epoch 15, Iteration 200, loss = 0.5028\n",
      "06/02 03:16:28 PM Checking accuracy on training set\n",
      "06/02 03:16:30 PM Loss (0.438387)\n",
      "06/02 03:16:30 PM Got 52900 / 71381 correct (74.11)\n",
      "06/02 03:16:30 PM Checking accuracy on validation set\n",
      "06/02 03:16:30 PM Loss (0.220015)\n",
      "06/02 03:16:30 PM Got 28715 / 39868 correct (72.03)\n",
      "06/02 03:16:30 PM \n",
      "06/02 03:16:30 PM Epoch 16, Iteration 0, loss = 0.5469\n",
      "06/02 03:16:31 PM Epoch 16, Iteration 100, loss = 0.4644\n",
      "06/02 03:16:32 PM Epoch 16, Iteration 200, loss = 0.5545\n",
      "06/02 03:16:33 PM Checking accuracy on training set\n",
      "06/02 03:16:34 PM Loss (0.482647)\n",
      "06/02 03:16:34 PM Got 52790 / 71381 correct (73.96)\n",
      "06/02 03:16:34 PM Checking accuracy on validation set\n",
      "06/02 03:16:35 PM Loss (0.216505)\n",
      "06/02 03:16:35 PM Got 28487 / 39868 correct (71.45)\n",
      "06/02 03:16:35 PM \n",
      "06/02 03:16:35 PM Epoch 17, Iteration 0, loss = 0.4618\n",
      "06/02 03:16:36 PM Epoch 17, Iteration 100, loss = 0.4937\n",
      "06/02 03:16:37 PM Epoch 17, Iteration 200, loss = 0.4490\n",
      "06/02 03:16:38 PM Checking accuracy on training set\n",
      "06/02 03:16:39 PM Loss (0.435574)\n",
      "06/02 03:16:39 PM Got 53630 / 71381 correct (75.13)\n",
      "06/02 03:16:39 PM Checking accuracy on validation set\n",
      "06/02 03:16:40 PM Loss (0.198079)\n",
      "06/02 03:16:40 PM Got 28905 / 39868 correct (72.50)\n",
      "06/02 03:16:40 PM \n",
      "06/02 03:16:40 PM Epoch 18, Iteration 0, loss = 0.4833\n",
      "06/02 03:16:41 PM Epoch 18, Iteration 100, loss = 0.5447\n",
      "06/02 03:16:42 PM Epoch 18, Iteration 200, loss = 0.6413\n",
      "06/02 03:16:43 PM Checking accuracy on training set\n",
      "06/02 03:16:44 PM Loss (0.527206)\n",
      "06/02 03:16:44 PM Got 50201 / 71381 correct (70.33)\n",
      "06/02 03:16:44 PM Checking accuracy on validation set\n",
      "06/02 03:16:45 PM Loss (0.220177)\n",
      "06/02 03:16:45 PM Got 27604 / 39868 correct (69.24)\n",
      "06/02 03:16:45 PM \n",
      "06/02 03:16:45 PM Epoch 19, Iteration 0, loss = 0.4744\n",
      "06/02 03:16:46 PM Epoch 19, Iteration 100, loss = 0.5612\n",
      "06/02 03:16:47 PM Epoch 19, Iteration 200, loss = 0.5179\n",
      "06/02 03:16:47 PM Checking accuracy on training set\n",
      "06/02 03:16:49 PM Loss (0.430758)\n",
      "06/02 03:16:49 PM Got 52811 / 71381 correct (73.98)\n",
      "06/02 03:16:49 PM Checking accuracy on validation set\n",
      "06/02 03:16:49 PM Loss (0.211265)\n",
      "06/02 03:16:49 PM Got 28590 / 39868 correct (71.71)\n",
      "06/02 03:16:49 PM \n",
      "06/02 03:16:49 PM Epoch 20, Iteration 0, loss = 0.4980\n",
      "06/02 03:16:50 PM Epoch 20, Iteration 100, loss = 0.4799\n",
      "06/02 03:16:51 PM Epoch 20, Iteration 200, loss = 0.4248\n",
      "06/02 03:16:52 PM Checking accuracy on training set\n",
      "06/02 03:16:53 PM Loss (0.527816)\n",
      "06/02 03:16:53 PM Got 52432 / 71381 correct (73.45)\n",
      "06/02 03:16:53 PM Checking accuracy on validation set\n",
      "06/02 03:16:54 PM Loss (0.188542)\n",
      "06/02 03:16:54 PM Got 28652 / 39868 correct (71.87)\n",
      "06/02 03:16:54 PM \n",
      "06/02 03:16:54 PM Epoch 21, Iteration 0, loss = 0.4022\n",
      "06/02 03:16:55 PM Epoch 21, Iteration 100, loss = 0.5408\n",
      "06/02 03:16:56 PM Epoch 21, Iteration 200, loss = 0.5818\n",
      "06/02 03:16:57 PM Checking accuracy on training set\n",
      "06/02 03:16:58 PM Loss (0.485836)\n",
      "06/02 03:16:58 PM Got 52129 / 71381 correct (73.03)\n",
      "06/02 03:16:58 PM Checking accuracy on validation set\n",
      "06/02 03:16:59 PM Loss (0.205041)\n",
      "06/02 03:16:59 PM Got 28424 / 39868 correct (71.30)\n",
      "06/02 03:16:59 PM \n",
      "06/02 03:16:59 PM Epoch 22, Iteration 0, loss = 0.5148\n",
      "06/02 03:17:00 PM Epoch 22, Iteration 100, loss = 0.5104\n",
      "06/02 03:17:01 PM Epoch 22, Iteration 200, loss = 0.4337\n",
      "06/02 03:17:02 PM Checking accuracy on training set\n",
      "06/02 03:17:03 PM Loss (0.463015)\n",
      "06/02 03:17:03 PM Got 53344 / 71381 correct (74.73)\n",
      "06/02 03:17:03 PM Checking accuracy on validation set\n",
      "06/02 03:17:04 PM Loss (0.188905)\n",
      "06/02 03:17:04 PM Got 28899 / 39868 correct (72.49)\n",
      "06/02 03:17:04 PM \n",
      "06/02 03:17:04 PM Epoch 23, Iteration 0, loss = 0.4139\n",
      "06/02 03:17:05 PM Epoch 23, Iteration 100, loss = 0.4387\n",
      "06/02 03:17:06 PM Epoch 23, Iteration 200, loss = 0.4277\n",
      "06/02 03:17:07 PM Checking accuracy on training set\n",
      "06/02 03:17:08 PM Loss (0.533913)\n",
      "06/02 03:17:08 PM Got 52571 / 71381 correct (73.65)\n",
      "06/02 03:17:08 PM Checking accuracy on validation set\n",
      "06/02 03:17:08 PM Loss (0.171387)\n",
      "06/02 03:17:08 PM Got 28738 / 39868 correct (72.08)\n",
      "06/02 03:17:08 PM \n",
      "06/02 03:17:09 PM Epoch 24, Iteration 0, loss = 0.4597\n",
      "06/02 03:17:10 PM Epoch 24, Iteration 100, loss = 0.4089\n",
      "06/02 03:17:11 PM Epoch 24, Iteration 200, loss = 0.4586\n",
      "06/02 03:17:11 PM Checking accuracy on training set\n",
      "06/02 03:17:13 PM Loss (0.529528)\n",
      "06/02 03:17:13 PM Got 52827 / 71381 correct (74.01)\n",
      "06/02 03:17:13 PM Checking accuracy on validation set\n",
      "06/02 03:17:13 PM Loss (0.170388)\n",
      "06/02 03:17:13 PM Got 28837 / 39868 correct (72.33)\n",
      "06/02 03:17:13 PM \n",
      "06/02 03:17:13 PM Epoch 25, Iteration 0, loss = 0.4308\n",
      "06/02 03:17:14 PM Epoch 25, Iteration 100, loss = 0.5256\n",
      "06/02 03:17:15 PM Epoch 25, Iteration 200, loss = 0.4730\n",
      "06/02 03:17:16 PM Checking accuracy on training set\n",
      "06/02 03:17:17 PM Loss (0.436076)\n",
      "06/02 03:17:17 PM Got 54783 / 71381 correct (76.75)\n",
      "06/02 03:17:17 PM Checking accuracy on validation set\n",
      "06/02 03:17:18 PM Loss (0.173620)\n",
      "06/02 03:17:18 PM Got 29232 / 39868 correct (73.32)\n",
      "06/02 03:17:18 PM \n",
      "06/02 03:17:18 PM Epoch 26, Iteration 0, loss = 0.4757\n",
      "06/02 03:17:19 PM Epoch 26, Iteration 100, loss = 0.4517\n",
      "06/02 03:17:20 PM Epoch 26, Iteration 200, loss = 0.4510\n",
      "06/02 03:17:21 PM Checking accuracy on training set\n",
      "06/02 03:17:22 PM Loss (0.473931)\n",
      "06/02 03:17:22 PM Got 50937 / 71381 correct (71.36)\n",
      "06/02 03:17:22 PM Checking accuracy on validation set\n",
      "06/02 03:17:23 PM Loss (0.165943)\n",
      "06/02 03:17:23 PM Got 28040 / 39868 correct (70.33)\n",
      "06/02 03:17:23 PM \n",
      "06/02 03:17:23 PM Epoch 27, Iteration 0, loss = 0.5118\n",
      "06/02 03:17:24 PM Epoch 27, Iteration 100, loss = 0.4576\n",
      "06/02 03:17:25 PM Epoch 27, Iteration 200, loss = 0.4811\n",
      "06/02 03:17:26 PM Checking accuracy on training set\n",
      "06/02 03:17:27 PM Loss (0.477847)\n",
      "06/02 03:17:27 PM Got 55080 / 71381 correct (77.16)\n",
      "06/02 03:17:27 PM Checking accuracy on validation set\n",
      "06/02 03:17:28 PM Loss (0.171551)\n",
      "06/02 03:17:28 PM Got 29305 / 39868 correct (73.51)\n",
      "06/02 03:17:28 PM \n",
      "06/02 03:17:28 PM Epoch 28, Iteration 0, loss = 0.5041\n",
      "06/02 03:17:29 PM Epoch 28, Iteration 100, loss = 0.4184\n",
      "06/02 03:17:30 PM Epoch 28, Iteration 200, loss = 0.4417\n",
      "06/02 03:17:30 PM Checking accuracy on training set\n",
      "06/02 03:17:32 PM Loss (0.433961)\n",
      "06/02 03:17:32 PM Got 54473 / 71381 correct (76.31)\n",
      "06/02 03:17:32 PM Checking accuracy on validation set\n",
      "06/02 03:17:32 PM Loss (0.162548)\n",
      "06/02 03:17:32 PM Got 29282 / 39868 correct (73.45)\n",
      "06/02 03:17:32 PM \n",
      "06/02 03:17:32 PM Epoch 29, Iteration 0, loss = 0.4006\n",
      "06/02 03:17:33 PM Epoch 29, Iteration 100, loss = 0.4651\n",
      "06/02 03:17:34 PM Epoch 29, Iteration 200, loss = 0.4174\n",
      "06/02 03:17:35 PM Checking accuracy on training set\n",
      "06/02 03:17:36 PM Loss (0.436731)\n",
      "06/02 03:17:36 PM Got 54190 / 71381 correct (75.92)\n",
      "06/02 03:17:36 PM Checking accuracy on validation set\n",
      "06/02 03:17:37 PM Loss (0.164478)\n",
      "06/02 03:17:37 PM Got 29197 / 39868 correct (73.23)\n",
      "06/02 03:17:37 PM \n",
      "06/02 03:17:37 PM Epoch 30, Iteration 0, loss = 0.4410\n",
      "06/02 03:17:38 PM Epoch 30, Iteration 100, loss = 0.3858\n",
      "06/02 03:17:39 PM Epoch 30, Iteration 200, loss = 0.4516\n",
      "06/02 03:17:40 PM Checking accuracy on training set\n",
      "06/02 03:17:41 PM Loss (0.461343)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/02 03:17:41 PM Got 53830 / 71381 correct (75.41)\n",
      "06/02 03:17:41 PM Checking accuracy on validation set\n",
      "06/02 03:17:42 PM Loss (0.197573)\n",
      "06/02 03:17:42 PM Got 29003 / 39868 correct (72.75)\n",
      "06/02 03:17:42 PM \n",
      "06/02 03:17:42 PM Epoch 31, Iteration 0, loss = 0.4164\n",
      "06/02 03:17:43 PM Epoch 31, Iteration 100, loss = 0.4249\n",
      "06/02 03:17:44 PM Epoch 31, Iteration 200, loss = 0.4795\n",
      "06/02 03:17:45 PM Checking accuracy on training set\n",
      "06/02 03:17:46 PM Loss (0.480147)\n",
      "06/02 03:17:46 PM Got 53162 / 71381 correct (74.48)\n",
      "06/02 03:17:46 PM Checking accuracy on validation set\n",
      "06/02 03:17:47 PM Loss (0.185794)\n",
      "06/02 03:17:47 PM Got 28790 / 39868 correct (72.21)\n",
      "06/02 03:17:47 PM \n",
      "06/02 03:17:47 PM Epoch 32, Iteration 0, loss = 0.4844\n",
      "06/02 03:17:48 PM Epoch 32, Iteration 100, loss = 0.4103\n",
      "06/02 03:17:49 PM Epoch 32, Iteration 200, loss = 0.4600\n",
      "06/02 03:17:50 PM Checking accuracy on training set\n",
      "06/02 03:17:51 PM Loss (0.425331)\n",
      "06/02 03:17:51 PM Got 55707 / 71381 correct (78.04)\n",
      "06/02 03:17:51 PM Checking accuracy on validation set\n",
      "06/02 03:17:52 PM Loss (0.212072)\n",
      "06/02 03:17:52 PM Got 29466 / 39868 correct (73.91)\n",
      "06/02 03:17:52 PM \n",
      "06/02 03:17:52 PM Epoch 33, Iteration 0, loss = 0.4846\n",
      "06/02 03:17:53 PM Epoch 33, Iteration 100, loss = 0.3494\n",
      "06/02 03:17:54 PM Epoch 33, Iteration 200, loss = 0.4715\n",
      "06/02 03:17:54 PM Checking accuracy on training set\n",
      "06/02 03:17:56 PM Loss (0.437808)\n",
      "06/02 03:17:56 PM Got 54642 / 71381 correct (76.55)\n",
      "06/02 03:17:56 PM Checking accuracy on validation set\n",
      "06/02 03:17:56 PM Loss (0.170754)\n",
      "06/02 03:17:56 PM Got 29281 / 39868 correct (73.44)\n",
      "06/02 03:17:56 PM \n",
      "06/02 03:17:56 PM Epoch 34, Iteration 0, loss = 0.4758\n",
      "06/02 03:17:57 PM Epoch 34, Iteration 100, loss = 0.4615\n",
      "06/02 03:17:58 PM Epoch 34, Iteration 200, loss = 0.4075\n",
      "06/02 03:17:59 PM Checking accuracy on training set\n",
      "06/02 03:18:00 PM Loss (0.445475)\n",
      "06/02 03:18:00 PM Got 55672 / 71381 correct (77.99)\n",
      "06/02 03:18:00 PM Checking accuracy on validation set\n",
      "06/02 03:18:01 PM Loss (0.155699)\n",
      "06/02 03:18:01 PM Got 29483 / 39868 correct (73.95)\n",
      "06/02 03:18:01 PM \n",
      "06/02 03:18:01 PM Epoch 35, Iteration 0, loss = 0.3849\n",
      "06/02 03:18:02 PM Epoch 35, Iteration 100, loss = 0.4327\n",
      "06/02 03:18:03 PM Epoch 35, Iteration 200, loss = 0.3824\n",
      "06/02 03:18:04 PM Checking accuracy on training set\n",
      "06/02 03:18:05 PM Loss (0.394026)\n",
      "06/02 03:18:05 PM Got 55692 / 71381 correct (78.02)\n",
      "06/02 03:18:05 PM Checking accuracy on validation set\n",
      "06/02 03:18:06 PM Loss (0.151883)\n",
      "06/02 03:18:06 PM Got 29470 / 39868 correct (73.92)\n",
      "06/02 03:18:06 PM \n",
      "06/02 03:18:06 PM Epoch 36, Iteration 0, loss = 0.4306\n",
      "06/02 03:18:07 PM Epoch 36, Iteration 100, loss = 0.4312\n",
      "06/02 03:18:08 PM Epoch 36, Iteration 200, loss = 0.4398\n",
      "06/02 03:18:09 PM Checking accuracy on training set\n",
      "06/02 03:18:10 PM Loss (0.450910)\n",
      "06/02 03:18:10 PM Got 54608 / 71381 correct (76.50)\n",
      "06/02 03:18:10 PM Checking accuracy on validation set\n",
      "06/02 03:18:11 PM Loss (0.144726)\n",
      "06/02 03:18:11 PM Got 29120 / 39868 correct (73.04)\n",
      "06/02 03:18:11 PM \n",
      "06/02 03:18:11 PM Epoch 37, Iteration 0, loss = 0.4383\n",
      "06/02 03:18:12 PM Epoch 37, Iteration 100, loss = 0.4622\n",
      "06/02 03:18:13 PM Epoch 37, Iteration 200, loss = 0.4426\n",
      "06/02 03:18:14 PM Checking accuracy on training set\n",
      "06/02 03:18:15 PM Loss (0.410297)\n",
      "06/02 03:18:15 PM Got 55632 / 71381 correct (77.94)\n",
      "06/02 03:18:15 PM Checking accuracy on validation set\n",
      "06/02 03:18:16 PM Loss (0.182719)\n",
      "06/02 03:18:16 PM Got 29398 / 39868 correct (73.74)\n",
      "06/02 03:18:16 PM \n",
      "06/02 03:18:16 PM Epoch 38, Iteration 0, loss = 0.4467\n",
      "06/02 03:18:17 PM Epoch 38, Iteration 100, loss = 0.4467\n",
      "06/02 03:18:18 PM Epoch 38, Iteration 200, loss = 0.4103\n",
      "06/02 03:18:18 PM Checking accuracy on training set\n",
      "06/02 03:18:20 PM Loss (0.447332)\n",
      "06/02 03:18:20 PM Got 54154 / 71381 correct (75.87)\n",
      "06/02 03:18:20 PM Checking accuracy on validation set\n",
      "06/02 03:18:20 PM Loss (0.163449)\n",
      "06/02 03:18:20 PM Got 29076 / 39868 correct (72.93)\n",
      "06/02 03:18:20 PM \n",
      "06/02 03:18:20 PM Epoch 39, Iteration 0, loss = 0.4753\n",
      "06/02 03:18:21 PM Epoch 39, Iteration 100, loss = 0.4420\n",
      "06/02 03:18:22 PM Epoch 39, Iteration 200, loss = 0.4393\n",
      "06/02 03:18:23 PM Checking accuracy on training set\n",
      "06/02 03:18:24 PM Loss (0.517282)\n",
      "06/02 03:18:24 PM Got 54612 / 71381 correct (76.51)\n",
      "06/02 03:18:24 PM Checking accuracy on validation set\n",
      "06/02 03:18:25 PM Loss (0.169060)\n",
      "06/02 03:18:25 PM Got 29066 / 39868 correct (72.91)\n",
      "06/02 03:18:25 PM \n",
      "06/02 03:18:25 PM Epoch 0, Iteration 0, loss = 1.1654\n",
      "06/02 03:18:26 PM Epoch 0, Iteration 100, loss = 0.6395\n",
      "06/02 03:18:27 PM Epoch 0, Iteration 200, loss = 0.6365\n",
      "06/02 03:18:28 PM Checking accuracy on training set\n",
      "06/02 03:18:29 PM Loss (0.582106)\n",
      "06/02 03:18:29 PM Got 43593 / 71381 correct (61.07)\n",
      "06/02 03:18:29 PM Checking accuracy on validation set\n",
      "06/02 03:18:30 PM Loss (0.353219)\n",
      "06/02 03:18:30 PM Got 24967 / 39868 correct (62.62)\n",
      "06/02 03:18:30 PM \n",
      "06/02 03:18:30 PM Epoch 1, Iteration 0, loss = 0.5885\n",
      "06/02 03:18:31 PM Epoch 1, Iteration 100, loss = 0.5235\n",
      "06/02 03:18:32 PM Epoch 1, Iteration 200, loss = 0.5829\n",
      "06/02 03:18:33 PM Checking accuracy on training set\n",
      "06/02 03:18:34 PM Loss (0.563869)\n",
      "06/02 03:18:34 PM Got 43601 / 71381 correct (61.08)\n",
      "06/02 03:18:34 PM Checking accuracy on validation set\n",
      "06/02 03:18:35 PM Loss (0.263533)\n",
      "06/02 03:18:35 PM Got 24974 / 39868 correct (62.64)\n",
      "06/02 03:18:35 PM \n",
      "06/02 03:18:35 PM Epoch 2, Iteration 0, loss = 0.5409\n",
      "06/02 03:18:36 PM Epoch 2, Iteration 100, loss = 0.5553\n",
      "06/02 03:18:37 PM Epoch 2, Iteration 200, loss = 0.5583\n",
      "06/02 03:18:37 PM Checking accuracy on training set\n",
      "06/02 03:18:39 PM Loss (0.550915)\n",
      "06/02 03:18:39 PM Got 43600 / 71381 correct (61.08)\n",
      "06/02 03:18:39 PM Checking accuracy on validation set\n",
      "06/02 03:18:39 PM Loss (0.286819)\n",
      "06/02 03:18:39 PM Got 24940 / 39868 correct (62.56)\n",
      "06/02 03:18:39 PM \n",
      "06/02 03:18:39 PM Epoch 3, Iteration 0, loss = 0.5326\n",
      "06/02 03:18:40 PM Epoch 3, Iteration 100, loss = 0.5422\n",
      "06/02 03:18:41 PM Epoch 3, Iteration 200, loss = 0.5690\n",
      "06/02 03:18:42 PM Checking accuracy on training set\n",
      "06/02 03:18:43 PM Loss (0.521677)\n",
      "06/02 03:18:43 PM Got 47551 / 71381 correct (66.62)\n",
      "06/02 03:18:43 PM Checking accuracy on validation set\n",
      "06/02 03:18:44 PM Loss (0.196052)\n",
      "06/02 03:18:44 PM Got 26619 / 39868 correct (66.77)\n",
      "06/02 03:18:44 PM \n",
      "06/02 03:18:44 PM Epoch 4, Iteration 0, loss = 0.7568\n",
      "06/02 03:18:45 PM Epoch 4, Iteration 100, loss = 0.6213\n",
      "06/02 03:18:46 PM Epoch 4, Iteration 200, loss = 0.6580\n",
      "06/02 03:18:47 PM Checking accuracy on training set\n",
      "06/02 03:18:48 PM Loss (0.650177)\n",
      "06/02 03:18:48 PM Got 43597 / 71381 correct (61.08)\n",
      "06/02 03:18:48 PM Checking accuracy on validation set\n",
      "06/02 03:18:49 PM Loss (0.471956)\n",
      "06/02 03:18:49 PM Got 24980 / 39868 correct (62.66)\n",
      "06/02 03:18:49 PM \n",
      "06/02 03:18:49 PM Epoch 5, Iteration 0, loss = 0.6040\n",
      "06/02 03:18:50 PM Epoch 5, Iteration 100, loss = 0.5807\n",
      "06/02 03:18:51 PM Epoch 5, Iteration 200, loss = 0.5940\n",
      "06/02 03:18:52 PM Checking accuracy on training set\n",
      "06/02 03:18:53 PM Loss (0.586886)\n",
      "06/02 03:18:53 PM Got 43597 / 71381 correct (61.08)\n",
      "06/02 03:18:53 PM Checking accuracy on validation set\n",
      "06/02 03:18:53 PM Loss (0.332687)\n",
      "06/02 03:18:53 PM Got 24980 / 39868 correct (62.66)\n",
      "06/02 03:18:53 PM \n",
      "06/02 03:18:54 PM Epoch 6, Iteration 0, loss = 0.5691\n",
      "06/02 03:18:55 PM Epoch 6, Iteration 100, loss = 0.5393\n",
      "06/02 03:18:56 PM Epoch 6, Iteration 200, loss = 0.5293\n",
      "06/02 03:18:56 PM Checking accuracy on training set\n",
      "06/02 03:18:58 PM Loss (0.574845)\n",
      "06/02 03:18:58 PM Got 43597 / 71381 correct (61.08)\n",
      "06/02 03:18:58 PM Checking accuracy on validation set\n",
      "06/02 03:18:58 PM Loss (0.208981)\n",
      "06/02 03:18:58 PM Got 24980 / 39868 correct (62.66)\n",
      "06/02 03:18:58 PM \n",
      "06/02 03:18:58 PM Epoch 7, Iteration 0, loss = 0.5201\n",
      "06/02 03:18:59 PM Epoch 7, Iteration 100, loss = 0.5543\n",
      "06/02 03:19:00 PM Epoch 7, Iteration 200, loss = 0.5668\n",
      "06/02 03:19:01 PM Checking accuracy on training set\n",
      "06/02 03:19:02 PM Loss (0.543029)\n",
      "06/02 03:19:02 PM Got 43597 / 71381 correct (61.08)\n",
      "06/02 03:19:02 PM Checking accuracy on validation set\n",
      "06/02 03:19:03 PM Loss (0.245134)\n",
      "06/02 03:19:03 PM Got 24980 / 39868 correct (62.66)\n",
      "06/02 03:19:03 PM \n",
      "06/02 03:19:03 PM Epoch 8, Iteration 0, loss = 0.5460\n",
      "06/02 03:19:04 PM Epoch 8, Iteration 100, loss = 0.5826\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/02 03:19:05 PM Epoch 8, Iteration 200, loss = 0.5626\n",
      "06/02 03:19:06 PM Checking accuracy on training set\n",
      "06/02 03:19:07 PM Loss (0.508390)\n",
      "06/02 03:19:07 PM Got 43597 / 71381 correct (61.08)\n",
      "06/02 03:19:07 PM Checking accuracy on validation set\n",
      "06/02 03:19:08 PM Loss (0.255425)\n",
      "06/02 03:19:08 PM Got 24980 / 39868 correct (62.66)\n",
      "06/02 03:19:08 PM \n",
      "06/02 03:19:08 PM Epoch 9, Iteration 0, loss = 0.5505\n",
      "06/02 03:19:09 PM Epoch 9, Iteration 100, loss = 0.5386\n",
      "06/02 03:19:10 PM Epoch 9, Iteration 200, loss = 0.5353\n",
      "06/02 03:19:10 PM Checking accuracy on training set\n",
      "06/02 03:19:12 PM Loss (0.557053)\n",
      "06/02 03:19:12 PM Got 43594 / 71381 correct (61.07)\n",
      "06/02 03:19:12 PM Checking accuracy on validation set\n",
      "06/02 03:19:12 PM Loss (0.331671)\n",
      "06/02 03:19:12 PM Got 24979 / 39868 correct (62.65)\n",
      "06/02 03:19:12 PM \n",
      "06/02 03:19:12 PM Epoch 10, Iteration 0, loss = 0.5250\n",
      "06/02 03:19:13 PM Epoch 10, Iteration 100, loss = 0.5686\n",
      "06/02 03:19:14 PM Epoch 10, Iteration 200, loss = 0.5192\n",
      "06/02 03:19:15 PM Checking accuracy on training set\n",
      "06/02 03:19:16 PM Loss (0.582066)\n",
      "06/02 03:19:16 PM Got 49418 / 71381 correct (69.23)\n",
      "06/02 03:19:16 PM Checking accuracy on validation set\n",
      "06/02 03:19:17 PM Loss (0.219282)\n",
      "06/02 03:19:17 PM Got 26437 / 39868 correct (66.31)\n",
      "06/02 03:19:17 PM \n",
      "06/02 03:19:17 PM Epoch 11, Iteration 0, loss = 0.4818\n",
      "06/02 03:19:18 PM Epoch 11, Iteration 100, loss = 0.4611\n",
      "06/02 03:19:19 PM Epoch 11, Iteration 200, loss = 0.4847\n",
      "06/02 03:19:20 PM Checking accuracy on training set\n",
      "06/02 03:19:21 PM Loss (0.561235)\n",
      "06/02 03:19:21 PM Got 52753 / 71381 correct (73.90)\n",
      "06/02 03:19:21 PM Checking accuracy on validation set\n",
      "06/02 03:19:22 PM Loss (0.307692)\n",
      "06/02 03:19:22 PM Got 27463 / 39868 correct (68.88)\n",
      "06/02 03:19:22 PM \n",
      "06/02 03:19:22 PM Epoch 12, Iteration 0, loss = 0.5483\n",
      "06/02 03:19:23 PM Epoch 12, Iteration 100, loss = 0.5039\n",
      "06/02 03:19:24 PM Epoch 12, Iteration 200, loss = 0.4689\n",
      "06/02 03:19:25 PM Checking accuracy on training set\n",
      "06/02 03:19:26 PM Loss (0.499260)\n",
      "06/02 03:19:26 PM Got 53521 / 71381 correct (74.98)\n",
      "06/02 03:19:26 PM Checking accuracy on validation set\n",
      "06/02 03:19:27 PM Loss (0.273632)\n",
      "06/02 03:19:27 PM Got 27913 / 39868 correct (70.01)\n",
      "06/02 03:19:27 PM \n",
      "06/02 03:19:27 PM Epoch 13, Iteration 0, loss = 0.4400\n",
      "06/02 03:19:28 PM Epoch 13, Iteration 100, loss = 0.4775\n",
      "06/02 03:19:29 PM Epoch 13, Iteration 200, loss = 0.4936\n",
      "06/02 03:19:29 PM Checking accuracy on training set\n",
      "06/02 03:19:31 PM Loss (0.539960)\n",
      "06/02 03:19:31 PM Got 54189 / 71381 correct (75.92)\n",
      "06/02 03:19:31 PM Checking accuracy on validation set\n",
      "06/02 03:19:31 PM Loss (0.316467)\n",
      "06/02 03:19:31 PM Got 27629 / 39868 correct (69.30)\n",
      "06/02 03:19:31 PM \n",
      "06/02 03:19:31 PM Epoch 14, Iteration 0, loss = 0.4881\n",
      "06/02 03:19:32 PM Epoch 14, Iteration 100, loss = 0.4897\n",
      "06/02 03:19:33 PM Epoch 14, Iteration 200, loss = 0.4970\n",
      "06/02 03:19:34 PM Checking accuracy on training set\n",
      "06/02 03:19:35 PM Loss (0.483417)\n",
      "06/02 03:19:35 PM Got 53709 / 71381 correct (75.24)\n",
      "06/02 03:19:35 PM Checking accuracy on validation set\n",
      "06/02 03:19:36 PM Loss (0.207939)\n",
      "06/02 03:19:36 PM Got 27959 / 39868 correct (70.13)\n",
      "06/02 03:19:36 PM \n",
      "06/02 03:19:36 PM Epoch 15, Iteration 0, loss = 0.5498\n",
      "06/02 03:19:37 PM Epoch 15, Iteration 100, loss = 0.5124\n",
      "06/02 03:19:38 PM Epoch 15, Iteration 200, loss = 0.4797\n",
      "06/02 03:19:39 PM Checking accuracy on training set\n",
      "06/02 03:19:40 PM Loss (0.461375)\n",
      "06/02 03:19:40 PM Got 55187 / 71381 correct (77.31)\n",
      "06/02 03:19:40 PM Checking accuracy on validation set\n",
      "06/02 03:19:41 PM Loss (0.269186)\n",
      "06/02 03:19:41 PM Got 28236 / 39868 correct (70.82)\n",
      "06/02 03:19:41 PM \n",
      "06/02 03:19:41 PM Epoch 16, Iteration 0, loss = 0.4546\n",
      "06/02 03:19:42 PM Epoch 16, Iteration 100, loss = 0.4776\n",
      "06/02 03:19:43 PM Epoch 16, Iteration 200, loss = 0.4816\n",
      "06/02 03:19:44 PM Checking accuracy on training set\n",
      "06/02 03:19:45 PM Loss (0.461590)\n",
      "06/02 03:19:45 PM Got 53950 / 71381 correct (75.58)\n",
      "06/02 03:19:45 PM Checking accuracy on validation set\n",
      "06/02 03:19:46 PM Loss (0.230281)\n",
      "06/02 03:19:46 PM Got 28230 / 39868 correct (70.81)\n",
      "06/02 03:19:46 PM \n",
      "06/02 03:19:46 PM Epoch 17, Iteration 0, loss = 0.4660\n",
      "06/02 03:19:47 PM Epoch 17, Iteration 100, loss = 0.4763\n",
      "06/02 03:19:48 PM Epoch 17, Iteration 200, loss = 0.4639\n",
      "06/02 03:19:48 PM Checking accuracy on training set\n",
      "06/02 03:19:50 PM Loss (0.450637)\n",
      "06/02 03:19:50 PM Got 55809 / 71381 correct (78.18)\n",
      "06/02 03:19:50 PM Checking accuracy on validation set\n",
      "06/02 03:19:50 PM Loss (0.215885)\n",
      "06/02 03:19:50 PM Got 28403 / 39868 correct (71.24)\n",
      "06/02 03:19:50 PM \n",
      "06/02 03:19:50 PM Epoch 18, Iteration 0, loss = 0.4607\n",
      "06/02 03:19:51 PM Epoch 18, Iteration 100, loss = 0.4204\n",
      "06/02 03:19:52 PM Epoch 18, Iteration 200, loss = 0.4654\n",
      "06/02 03:19:53 PM Checking accuracy on training set\n",
      "06/02 03:19:54 PM Loss (0.516749)\n",
      "06/02 03:19:54 PM Got 55789 / 71381 correct (78.16)\n",
      "06/02 03:19:54 PM Checking accuracy on validation set\n",
      "06/02 03:19:55 PM Loss (0.301908)\n",
      "06/02 03:19:55 PM Got 28514 / 39868 correct (71.52)\n",
      "06/02 03:19:55 PM \n",
      "06/02 03:19:55 PM Epoch 19, Iteration 0, loss = 0.4274\n",
      "06/02 03:19:56 PM Epoch 19, Iteration 100, loss = 0.4176\n",
      "06/02 03:19:57 PM Epoch 19, Iteration 200, loss = 0.4596\n",
      "06/02 03:19:58 PM Checking accuracy on training set\n",
      "06/02 03:19:59 PM Loss (0.468734)\n",
      "06/02 03:19:59 PM Got 55730 / 71381 correct (78.07)\n",
      "06/02 03:19:59 PM Checking accuracy on validation set\n",
      "06/02 03:20:00 PM Loss (0.176401)\n",
      "06/02 03:20:00 PM Got 28690 / 39868 correct (71.96)\n",
      "06/02 03:20:00 PM \n",
      "06/02 03:20:00 PM Epoch 20, Iteration 0, loss = 0.4649\n",
      "06/02 03:20:01 PM Epoch 20, Iteration 100, loss = 0.4445\n",
      "06/02 03:20:02 PM Epoch 20, Iteration 200, loss = 0.4230\n",
      "06/02 03:20:03 PM Checking accuracy on training set\n",
      "06/02 03:20:04 PM Loss (0.459788)\n",
      "06/02 03:20:04 PM Got 54730 / 71381 correct (76.67)\n",
      "06/02 03:20:04 PM Checking accuracy on validation set\n",
      "06/02 03:20:05 PM Loss (0.311996)\n",
      "06/02 03:20:05 PM Got 28063 / 39868 correct (70.39)\n",
      "06/02 03:20:05 PM \n",
      "06/02 03:20:05 PM Epoch 21, Iteration 0, loss = 0.6022\n",
      "06/02 03:20:06 PM Epoch 21, Iteration 100, loss = 0.4660\n",
      "06/02 03:20:07 PM Epoch 21, Iteration 200, loss = 0.3722\n",
      "06/02 03:20:08 PM Checking accuracy on training set\n",
      "06/02 03:20:09 PM Loss (0.491424)\n",
      "06/02 03:20:09 PM Got 56462 / 71381 correct (79.10)\n",
      "06/02 03:20:09 PM Checking accuracy on validation set\n",
      "06/02 03:20:10 PM Loss (0.227548)\n",
      "06/02 03:20:10 PM Got 28648 / 39868 correct (71.86)\n",
      "06/02 03:20:10 PM \n",
      "06/02 03:20:10 PM Epoch 22, Iteration 0, loss = 0.4179\n",
      "06/02 03:20:11 PM Epoch 22, Iteration 100, loss = 0.4796\n",
      "06/02 03:20:12 PM Epoch 22, Iteration 200, loss = 0.4618\n",
      "06/02 03:20:13 PM Checking accuracy on training set\n",
      "06/02 03:20:14 PM Loss (0.446034)\n",
      "06/02 03:20:14 PM Got 56268 / 71381 correct (78.83)\n",
      "06/02 03:20:14 PM Checking accuracy on validation set\n",
      "06/02 03:20:15 PM Loss (0.405027)\n",
      "06/02 03:20:15 PM Got 28119 / 39868 correct (70.53)\n",
      "06/02 03:20:15 PM \n",
      "06/02 03:20:15 PM Epoch 23, Iteration 0, loss = 0.4414\n",
      "06/02 03:20:16 PM Epoch 23, Iteration 100, loss = 0.4586\n",
      "06/02 03:20:17 PM Epoch 23, Iteration 200, loss = 0.4443\n",
      "06/02 03:20:17 PM Checking accuracy on training set\n",
      "06/02 03:20:19 PM Loss (0.452730)\n",
      "06/02 03:20:19 PM Got 54926 / 71381 correct (76.95)\n",
      "06/02 03:20:19 PM Checking accuracy on validation set\n",
      "06/02 03:20:19 PM Loss (0.252139)\n",
      "06/02 03:20:19 PM Got 27796 / 39868 correct (69.72)\n",
      "06/02 03:20:19 PM \n",
      "06/02 03:20:19 PM Epoch 24, Iteration 0, loss = 0.4167\n",
      "06/02 03:20:20 PM Epoch 24, Iteration 100, loss = 0.4388\n",
      "06/02 03:20:21 PM Epoch 24, Iteration 200, loss = 0.4200\n",
      "06/02 03:20:22 PM Checking accuracy on training set\n",
      "06/02 03:20:23 PM Loss (0.439574)\n",
      "06/02 03:20:23 PM Got 56856 / 71381 correct (79.65)\n",
      "06/02 03:20:23 PM Checking accuracy on validation set\n",
      "06/02 03:20:24 PM Loss (0.243815)\n",
      "06/02 03:20:24 PM Got 28583 / 39868 correct (71.69)\n",
      "06/02 03:20:24 PM \n",
      "06/02 03:20:24 PM Epoch 25, Iteration 0, loss = 0.4522\n",
      "06/02 03:20:25 PM Epoch 25, Iteration 100, loss = 0.4288\n",
      "06/02 03:20:26 PM Epoch 25, Iteration 200, loss = 0.4257\n",
      "06/02 03:20:27 PM Checking accuracy on training set\n",
      "06/02 03:20:28 PM Loss (0.467183)\n",
      "06/02 03:20:28 PM Got 56732 / 71381 correct (79.48)\n",
      "06/02 03:20:28 PM Checking accuracy on validation set\n",
      "06/02 03:20:29 PM Loss (0.344933)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/02 03:20:29 PM Got 28142 / 39868 correct (70.59)\n",
      "06/02 03:20:29 PM \n",
      "06/02 03:20:29 PM Epoch 26, Iteration 0, loss = 0.3876\n",
      "06/02 03:20:30 PM Epoch 26, Iteration 100, loss = 0.4335\n",
      "06/02 03:20:31 PM Epoch 26, Iteration 200, loss = 0.3488\n",
      "06/02 03:20:32 PM Checking accuracy on training set\n",
      "06/02 03:20:33 PM Loss (0.412034)\n",
      "06/02 03:20:33 PM Got 57372 / 71381 correct (80.37)\n",
      "06/02 03:20:33 PM Checking accuracy on validation set\n",
      "06/02 03:20:34 PM Loss (0.183632)\n",
      "06/02 03:20:34 PM Got 28707 / 39868 correct (72.01)\n",
      "06/02 03:20:34 PM \n",
      "06/02 03:20:34 PM Epoch 27, Iteration 0, loss = 0.3998\n",
      "06/02 03:20:35 PM Epoch 27, Iteration 100, loss = 0.4109\n",
      "06/02 03:20:36 PM Epoch 27, Iteration 200, loss = 0.4117\n",
      "06/02 03:20:36 PM Checking accuracy on training set\n",
      "06/02 03:20:38 PM Loss (0.419421)\n",
      "06/02 03:20:38 PM Got 57167 / 71381 correct (80.09)\n",
      "06/02 03:20:38 PM Checking accuracy on validation set\n",
      "06/02 03:20:38 PM Loss (0.251698)\n",
      "06/02 03:20:38 PM Got 28548 / 39868 correct (71.61)\n",
      "06/02 03:20:38 PM \n",
      "06/02 03:20:38 PM Epoch 28, Iteration 0, loss = 0.4147\n",
      "06/02 03:20:39 PM Epoch 28, Iteration 100, loss = 0.4336\n",
      "06/02 03:20:40 PM Epoch 28, Iteration 200, loss = 0.5150\n",
      "06/02 03:20:41 PM Checking accuracy on training set\n",
      "06/02 03:20:42 PM Loss (0.428692)\n",
      "06/02 03:20:42 PM Got 57437 / 71381 correct (80.47)\n",
      "06/02 03:20:42 PM Checking accuracy on validation set\n",
      "06/02 03:20:43 PM Loss (0.277479)\n",
      "06/02 03:20:43 PM Got 28583 / 39868 correct (71.69)\n",
      "06/02 03:20:43 PM \n",
      "06/02 03:20:43 PM Epoch 29, Iteration 0, loss = 0.3419\n",
      "06/02 03:20:44 PM Epoch 29, Iteration 100, loss = 0.4075\n",
      "06/02 03:20:45 PM Epoch 29, Iteration 200, loss = 0.4281\n",
      "06/02 03:20:46 PM Checking accuracy on training set\n",
      "06/02 03:20:47 PM Loss (0.480858)\n",
      "06/02 03:20:47 PM Got 56782 / 71381 correct (79.55)\n",
      "06/02 03:20:47 PM Checking accuracy on validation set\n",
      "06/02 03:20:48 PM Loss (0.252462)\n",
      "06/02 03:20:48 PM Got 28559 / 39868 correct (71.63)\n",
      "06/02 03:20:48 PM \n",
      "06/02 03:20:48 PM Epoch 30, Iteration 0, loss = 0.4221\n",
      "06/02 03:20:49 PM Epoch 30, Iteration 100, loss = 0.4331\n",
      "06/02 03:20:50 PM Epoch 30, Iteration 200, loss = 0.3989\n",
      "06/02 03:20:51 PM Checking accuracy on training set\n",
      "06/02 03:20:52 PM Loss (0.387514)\n",
      "06/02 03:20:52 PM Got 58107 / 71381 correct (81.40)\n",
      "06/02 03:20:52 PM Checking accuracy on validation set\n",
      "06/02 03:20:53 PM Loss (0.240988)\n",
      "06/02 03:20:53 PM Got 28885 / 39868 correct (72.45)\n",
      "06/02 03:20:53 PM \n",
      "06/02 03:20:53 PM Epoch 31, Iteration 0, loss = 0.4219\n",
      "06/02 03:20:54 PM Epoch 31, Iteration 100, loss = 0.4093\n",
      "06/02 03:20:55 PM Epoch 31, Iteration 200, loss = 0.4346\n",
      "06/02 03:20:56 PM Checking accuracy on training set\n",
      "06/02 03:20:57 PM Loss (0.378568)\n",
      "06/02 03:20:57 PM Got 57466 / 71381 correct (80.51)\n",
      "06/02 03:20:57 PM Checking accuracy on validation set\n",
      "06/02 03:20:57 PM Loss (0.162566)\n",
      "06/02 03:20:57 PM Got 28632 / 39868 correct (71.82)\n",
      "06/02 03:20:57 PM \n",
      "06/02 03:20:58 PM Epoch 32, Iteration 0, loss = 0.4288\n",
      "06/02 03:20:59 PM Epoch 32, Iteration 100, loss = 0.3759\n",
      "06/02 03:21:00 PM Epoch 32, Iteration 200, loss = 0.4628\n",
      "06/02 03:21:00 PM Checking accuracy on training set\n",
      "06/02 03:21:02 PM Loss (0.480335)\n",
      "06/02 03:21:02 PM Got 57878 / 71381 correct (81.08)\n",
      "06/02 03:21:02 PM Checking accuracy on validation set\n",
      "06/02 03:21:02 PM Loss (0.273115)\n",
      "06/02 03:21:02 PM Got 28683 / 39868 correct (71.94)\n",
      "06/02 03:21:02 PM \n",
      "06/02 03:21:02 PM Epoch 33, Iteration 0, loss = 0.4031\n",
      "06/02 03:21:03 PM Epoch 33, Iteration 100, loss = 0.4082\n",
      "06/02 03:21:04 PM Epoch 33, Iteration 200, loss = 0.4250\n",
      "06/02 03:21:05 PM Checking accuracy on training set\n",
      "06/02 03:21:06 PM Loss (0.435130)\n",
      "06/02 03:21:06 PM Got 57917 / 71381 correct (81.14)\n",
      "06/02 03:21:06 PM Checking accuracy on validation set\n",
      "06/02 03:21:07 PM Loss (0.225849)\n",
      "06/02 03:21:07 PM Got 28741 / 39868 correct (72.09)\n",
      "06/02 03:21:07 PM \n",
      "06/02 03:21:07 PM Epoch 34, Iteration 0, loss = 0.3963\n",
      "06/02 03:21:08 PM Epoch 34, Iteration 100, loss = 0.3902\n",
      "06/02 03:21:09 PM Epoch 34, Iteration 200, loss = 0.4089\n",
      "06/02 03:21:10 PM Checking accuracy on training set\n",
      "06/02 03:21:11 PM Loss (0.425662)\n",
      "06/02 03:21:11 PM Got 57075 / 71381 correct (79.96)\n",
      "06/02 03:21:11 PM Checking accuracy on validation set\n",
      "06/02 03:21:12 PM Loss (0.409324)\n",
      "06/02 03:21:12 PM Got 27645 / 39868 correct (69.34)\n",
      "06/02 03:21:12 PM \n",
      "06/02 03:21:12 PM Epoch 35, Iteration 0, loss = 0.3774\n",
      "06/02 03:21:13 PM Epoch 35, Iteration 100, loss = 0.4164\n",
      "06/02 03:21:14 PM Epoch 35, Iteration 200, loss = 0.3755\n",
      "06/02 03:21:15 PM Checking accuracy on training set\n",
      "06/02 03:21:16 PM Loss (0.372318)\n",
      "06/02 03:21:16 PM Got 58574 / 71381 correct (82.06)\n",
      "06/02 03:21:16 PM Checking accuracy on validation set\n",
      "06/02 03:21:16 PM Loss (0.177906)\n",
      "06/02 03:21:16 PM Got 29117 / 39868 correct (73.03)\n",
      "06/02 03:21:16 PM \n",
      "06/02 03:21:17 PM Epoch 36, Iteration 0, loss = 0.4125\n",
      "06/02 03:21:18 PM Epoch 36, Iteration 100, loss = 0.3801\n",
      "06/02 03:21:19 PM Epoch 36, Iteration 200, loss = 0.4157\n",
      "06/02 03:21:19 PM Checking accuracy on training set\n",
      "06/02 03:21:21 PM Loss (0.389044)\n",
      "06/02 03:21:21 PM Got 58488 / 71381 correct (81.94)\n",
      "06/02 03:21:21 PM Checking accuracy on validation set\n",
      "06/02 03:21:21 PM Loss (0.238124)\n",
      "06/02 03:21:21 PM Got 29148 / 39868 correct (73.11)\n",
      "06/02 03:21:21 PM \n",
      "06/02 03:21:21 PM Epoch 37, Iteration 0, loss = 0.4055\n",
      "06/02 03:21:22 PM Epoch 37, Iteration 100, loss = 0.4300\n",
      "06/02 03:21:23 PM Epoch 37, Iteration 200, loss = 0.3828\n",
      "06/02 03:21:24 PM Checking accuracy on training set\n",
      "06/02 03:21:25 PM Loss (0.457333)\n",
      "06/02 03:21:25 PM Got 58004 / 71381 correct (81.26)\n",
      "06/02 03:21:25 PM Checking accuracy on validation set\n",
      "06/02 03:21:26 PM Loss (0.285339)\n",
      "06/02 03:21:26 PM Got 28210 / 39868 correct (70.76)\n",
      "06/02 03:21:26 PM \n",
      "06/02 03:21:26 PM Epoch 38, Iteration 0, loss = 0.4555\n",
      "06/02 03:21:27 PM Epoch 38, Iteration 100, loss = 0.4088\n",
      "06/02 03:21:28 PM Epoch 38, Iteration 200, loss = 0.3746\n",
      "06/02 03:21:29 PM Checking accuracy on training set\n",
      "06/02 03:21:30 PM Loss (0.415329)\n",
      "06/02 03:21:30 PM Got 58554 / 71381 correct (82.03)\n",
      "06/02 03:21:30 PM Checking accuracy on validation set\n",
      "06/02 03:21:31 PM Loss (0.243237)\n",
      "06/02 03:21:31 PM Got 28929 / 39868 correct (72.56)\n",
      "06/02 03:21:31 PM \n",
      "06/02 03:21:31 PM Epoch 39, Iteration 0, loss = 0.4068\n",
      "06/02 03:21:32 PM Epoch 39, Iteration 100, loss = 0.3707\n",
      "06/02 03:21:33 PM Epoch 39, Iteration 200, loss = 0.4101\n",
      "06/02 03:21:34 PM Checking accuracy on training set\n",
      "06/02 03:21:35 PM Loss (0.382209)\n",
      "06/02 03:21:35 PM Got 59009 / 71381 correct (82.67)\n",
      "06/02 03:21:35 PM Checking accuracy on validation set\n",
      "06/02 03:21:36 PM Loss (0.351153)\n",
      "06/02 03:21:36 PM Got 28876 / 39868 correct (72.43)\n",
      "06/02 03:21:36 PM \n",
      "06/02 03:21:36 PM Epoch 0, Iteration 0, loss = 1.4620\n",
      "06/02 03:21:37 PM Epoch 0, Iteration 100, loss = 1.1354\n",
      "06/02 03:21:38 PM Epoch 0, Iteration 200, loss = 0.5693\n",
      "06/02 03:21:39 PM Checking accuracy on training set\n",
      "06/02 03:21:40 PM Loss (0.570398)\n",
      "06/02 03:21:40 PM Got 43762 / 71381 correct (61.31)\n",
      "06/02 03:21:40 PM Checking accuracy on validation set\n",
      "06/02 03:21:40 PM Loss (0.339921)\n",
      "06/02 03:21:41 PM Got 24806 / 39868 correct (62.22)\n",
      "06/02 03:21:41 PM \n",
      "06/02 03:21:41 PM Epoch 1, Iteration 0, loss = 0.5468\n",
      "06/02 03:21:42 PM Epoch 1, Iteration 100, loss = 0.5073\n",
      "06/02 03:21:43 PM Epoch 1, Iteration 200, loss = 0.5049\n",
      "06/02 03:21:43 PM Checking accuracy on training set\n",
      "06/02 03:21:45 PM Loss (0.537192)\n",
      "06/02 03:21:45 PM Got 43844 / 71381 correct (61.42)\n",
      "06/02 03:21:45 PM Checking accuracy on validation set\n",
      "06/02 03:21:45 PM Loss (0.220172)\n",
      "06/02 03:21:45 PM Got 24852 / 39868 correct (62.34)\n",
      "06/02 03:21:45 PM \n",
      "06/02 03:21:45 PM Epoch 2, Iteration 0, loss = 0.5912\n",
      "06/02 03:21:46 PM Epoch 2, Iteration 100, loss = 0.5383\n",
      "06/02 03:21:47 PM Epoch 2, Iteration 200, loss = 0.5399\n",
      "06/02 03:21:48 PM Checking accuracy on training set\n",
      "06/02 03:21:49 PM Loss (0.522017)\n",
      "06/02 03:21:49 PM Got 49147 / 71381 correct (68.85)\n",
      "06/02 03:21:49 PM Checking accuracy on validation set\n",
      "06/02 03:21:50 PM Loss (0.280394)\n",
      "06/02 03:21:50 PM Got 27232 / 39868 correct (68.31)\n",
      "06/02 03:21:50 PM \n",
      "06/02 03:21:50 PM Epoch 3, Iteration 0, loss = 0.6169\n",
      "06/02 03:21:51 PM Epoch 3, Iteration 100, loss = 0.6305\n",
      "06/02 03:21:52 PM Epoch 3, Iteration 200, loss = 0.5183\n",
      "06/02 03:21:53 PM Checking accuracy on training set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/02 03:21:54 PM Loss (0.564779)\n",
      "06/02 03:21:54 PM Got 49244 / 71381 correct (68.99)\n",
      "06/02 03:21:54 PM Checking accuracy on validation set\n",
      "06/02 03:21:55 PM Loss (0.220964)\n",
      "06/02 03:21:55 PM Got 27305 / 39868 correct (68.49)\n",
      "06/02 03:21:55 PM \n",
      "06/02 03:21:55 PM Epoch 4, Iteration 0, loss = 0.5416\n",
      "06/02 03:21:56 PM Epoch 4, Iteration 100, loss = 0.5403\n",
      "06/02 03:21:57 PM Epoch 4, Iteration 200, loss = 0.4999\n",
      "06/02 03:21:57 PM Checking accuracy on training set\n",
      "06/02 03:21:59 PM Loss (0.502333)\n",
      "06/02 03:21:59 PM Got 51679 / 71381 correct (72.40)\n",
      "06/02 03:21:59 PM Checking accuracy on validation set\n",
      "06/02 03:21:59 PM Loss (0.228522)\n",
      "06/02 03:21:59 PM Got 28278 / 39868 correct (70.93)\n",
      "06/02 03:21:59 PM \n",
      "06/02 03:21:59 PM Epoch 5, Iteration 0, loss = 0.5109\n",
      "06/02 03:22:00 PM Epoch 5, Iteration 100, loss = 0.4593\n",
      "06/02 03:22:01 PM Epoch 5, Iteration 200, loss = 0.5449\n",
      "06/02 03:22:02 PM Checking accuracy on training set\n",
      "06/02 03:22:03 PM Loss (0.496548)\n",
      "06/02 03:22:03 PM Got 50061 / 71381 correct (70.13)\n",
      "06/02 03:22:03 PM Checking accuracy on validation set\n",
      "06/02 03:22:04 PM Loss (0.262371)\n",
      "06/02 03:22:04 PM Got 27466 / 39868 correct (68.89)\n",
      "06/02 03:22:04 PM \n",
      "06/02 03:22:04 PM Epoch 6, Iteration 0, loss = 0.4737\n",
      "06/02 03:22:05 PM Epoch 6, Iteration 100, loss = 0.5253\n",
      "06/02 03:22:06 PM Epoch 6, Iteration 200, loss = 0.5665\n",
      "06/02 03:22:07 PM Checking accuracy on training set\n",
      "06/02 03:22:08 PM Loss (0.499162)\n",
      "06/02 03:22:08 PM Got 51221 / 71381 correct (71.76)\n",
      "06/02 03:22:08 PM Checking accuracy on validation set\n",
      "06/02 03:22:09 PM Loss (0.229438)\n",
      "06/02 03:22:09 PM Got 27963 / 39868 correct (70.14)\n",
      "06/02 03:22:09 PM \n",
      "06/02 03:22:09 PM Epoch 7, Iteration 0, loss = 0.5074\n",
      "06/02 03:22:10 PM Epoch 7, Iteration 100, loss = 0.4694\n",
      "06/02 03:22:11 PM Epoch 7, Iteration 200, loss = 0.5044\n",
      "06/02 03:22:12 PM Checking accuracy on training set\n",
      "06/02 03:22:13 PM Loss (0.486044)\n",
      "06/02 03:22:13 PM Got 52246 / 71381 correct (73.19)\n",
      "06/02 03:22:13 PM Checking accuracy on validation set\n",
      "06/02 03:22:14 PM Loss (0.202394)\n",
      "06/02 03:22:14 PM Got 28345 / 39868 correct (71.10)\n",
      "06/02 03:22:14 PM \n",
      "06/02 03:22:14 PM Epoch 8, Iteration 0, loss = 0.4493\n",
      "06/02 03:22:15 PM Epoch 8, Iteration 100, loss = 0.3963\n",
      "06/02 03:22:16 PM Epoch 8, Iteration 200, loss = 0.4626\n",
      "06/02 03:22:16 PM Checking accuracy on training set\n",
      "06/02 03:22:18 PM Loss (0.492801)\n",
      "06/02 03:22:18 PM Got 53526 / 71381 correct (74.99)\n",
      "06/02 03:22:18 PM Checking accuracy on validation set\n",
      "06/02 03:22:18 PM Loss (0.232703)\n",
      "06/02 03:22:18 PM Got 29043 / 39868 correct (72.85)\n",
      "06/02 03:22:18 PM \n",
      "06/02 03:22:18 PM Epoch 9, Iteration 0, loss = 0.4582\n",
      "06/02 03:22:19 PM Epoch 9, Iteration 100, loss = 0.4395\n",
      "06/02 03:22:20 PM Epoch 9, Iteration 200, loss = 0.4800\n",
      "06/02 03:22:21 PM Checking accuracy on training set\n",
      "06/02 03:22:22 PM Loss (0.463694)\n",
      "06/02 03:22:22 PM Got 52671 / 71381 correct (73.79)\n",
      "06/02 03:22:22 PM Checking accuracy on validation set\n",
      "06/02 03:22:23 PM Loss (0.224168)\n",
      "06/02 03:22:23 PM Got 28585 / 39868 correct (71.70)\n",
      "06/02 03:22:23 PM \n",
      "06/02 03:22:23 PM Epoch 10, Iteration 0, loss = 0.4327\n",
      "06/02 03:22:24 PM Epoch 10, Iteration 100, loss = 0.4347\n",
      "06/02 03:22:25 PM Epoch 10, Iteration 200, loss = 0.4462\n",
      "06/02 03:22:26 PM Checking accuracy on training set\n",
      "06/02 03:22:27 PM Loss (0.461907)\n",
      "06/02 03:22:27 PM Got 54377 / 71381 correct (76.18)\n",
      "06/02 03:22:27 PM Checking accuracy on validation set\n",
      "06/02 03:22:28 PM Loss (0.199462)\n",
      "06/02 03:22:28 PM Got 29031 / 39868 correct (72.82)\n",
      "06/02 03:22:28 PM \n",
      "06/02 03:22:28 PM Epoch 11, Iteration 0, loss = 0.4186\n",
      "06/02 03:22:29 PM Epoch 11, Iteration 100, loss = 0.4721\n",
      "06/02 03:22:30 PM Epoch 11, Iteration 200, loss = 0.4594\n",
      "06/02 03:22:31 PM Checking accuracy on training set\n",
      "06/02 03:22:32 PM Loss (0.409828)\n",
      "06/02 03:22:32 PM Got 53455 / 71381 correct (74.89)\n",
      "06/02 03:22:32 PM Checking accuracy on validation set\n",
      "06/02 03:22:33 PM Loss (0.146441)\n",
      "06/02 03:22:33 PM Got 28989 / 39868 correct (72.71)\n",
      "06/02 03:22:33 PM \n",
      "06/02 03:22:33 PM Epoch 12, Iteration 0, loss = 0.4326\n",
      "06/02 03:22:34 PM Epoch 12, Iteration 100, loss = 0.4364\n",
      "06/02 03:22:35 PM Epoch 12, Iteration 200, loss = 0.5026\n",
      "06/02 03:22:35 PM Checking accuracy on training set\n",
      "06/02 03:22:37 PM Loss (0.406068)\n",
      "06/02 03:22:37 PM Got 55500 / 71381 correct (77.75)\n",
      "06/02 03:22:37 PM Checking accuracy on validation set\n",
      "06/02 03:22:37 PM Loss (0.177604)\n",
      "06/02 03:22:37 PM Got 29441 / 39868 correct (73.85)\n",
      "06/02 03:22:37 PM \n",
      "06/02 03:22:37 PM Epoch 13, Iteration 0, loss = 0.4885\n",
      "06/02 03:22:38 PM Epoch 13, Iteration 100, loss = 0.4357\n",
      "06/02 03:22:39 PM Epoch 13, Iteration 200, loss = 0.4095\n",
      "06/02 03:22:40 PM Checking accuracy on training set\n",
      "06/02 03:22:41 PM Loss (0.509097)\n",
      "06/02 03:22:41 PM Got 53667 / 71381 correct (75.18)\n",
      "06/02 03:22:41 PM Checking accuracy on validation set\n",
      "06/02 03:22:42 PM Loss (0.222480)\n",
      "06/02 03:22:42 PM Got 29029 / 39868 correct (72.81)\n",
      "06/02 03:22:42 PM \n",
      "06/02 03:22:42 PM Epoch 14, Iteration 0, loss = 0.5145\n",
      "06/02 03:22:43 PM Epoch 14, Iteration 100, loss = 0.4671\n",
      "06/02 03:22:44 PM Epoch 14, Iteration 200, loss = 0.4687\n",
      "06/02 03:22:45 PM Checking accuracy on training set\n",
      "06/02 03:22:46 PM Loss (0.408706)\n",
      "06/02 03:22:46 PM Got 54324 / 71381 correct (76.10)\n",
      "06/02 03:22:46 PM Checking accuracy on validation set\n",
      "06/02 03:22:47 PM Loss (0.191003)\n",
      "06/02 03:22:47 PM Got 29156 / 39868 correct (73.13)\n",
      "06/02 03:22:47 PM \n",
      "06/02 03:22:47 PM Epoch 15, Iteration 0, loss = 0.4441\n",
      "06/02 03:22:48 PM Epoch 15, Iteration 100, loss = 0.4153\n",
      "06/02 03:22:49 PM Epoch 15, Iteration 200, loss = 0.4577\n",
      "06/02 03:22:50 PM Checking accuracy on training set\n",
      "06/02 03:22:51 PM Loss (0.398388)\n",
      "06/02 03:22:51 PM Got 54777 / 71381 correct (76.74)\n",
      "06/02 03:22:51 PM Checking accuracy on validation set\n",
      "06/02 03:22:52 PM Loss (0.211012)\n",
      "06/02 03:22:52 PM Got 29292 / 39868 correct (73.47)\n",
      "06/02 03:22:52 PM \n",
      "06/02 03:22:52 PM Epoch 16, Iteration 0, loss = 0.4321\n",
      "06/02 03:22:53 PM Epoch 16, Iteration 100, loss = 0.4014\n",
      "06/02 03:22:54 PM Epoch 16, Iteration 200, loss = 0.4716\n",
      "06/02 03:22:54 PM Checking accuracy on training set\n",
      "06/02 03:22:56 PM Loss (0.567188)\n",
      "06/02 03:22:56 PM Got 43597 / 71381 correct (61.08)\n",
      "06/02 03:22:56 PM Checking accuracy on validation set\n",
      "06/02 03:22:56 PM Loss (0.362648)\n",
      "06/02 03:22:56 PM Got 24979 / 39868 correct (62.65)\n",
      "06/02 03:22:56 PM \n",
      "06/02 03:22:56 PM Epoch 17, Iteration 0, loss = 0.5807\n",
      "06/02 03:22:57 PM Epoch 17, Iteration 100, loss = 0.6002\n",
      "06/02 03:22:58 PM Epoch 17, Iteration 200, loss = 0.5330\n",
      "06/02 03:22:59 PM Checking accuracy on training set\n",
      "06/02 03:23:00 PM Loss (0.583167)\n",
      "06/02 03:23:00 PM Got 43597 / 71381 correct (61.08)\n",
      "06/02 03:23:00 PM Checking accuracy on validation set\n",
      "06/02 03:23:01 PM Loss (0.338692)\n",
      "06/02 03:23:01 PM Got 24980 / 39868 correct (62.66)\n",
      "06/02 03:23:01 PM \n",
      "06/02 03:23:01 PM Epoch 18, Iteration 0, loss = 0.6215\n",
      "06/02 03:23:02 PM Epoch 18, Iteration 100, loss = 0.6256\n",
      "06/02 03:23:03 PM Epoch 18, Iteration 200, loss = 0.5788\n",
      "06/02 03:23:04 PM Checking accuracy on training set\n",
      "06/02 03:23:05 PM Loss (0.626555)\n",
      "06/02 03:23:05 PM Got 43604 / 71381 correct (61.09)\n",
      "06/02 03:23:05 PM Checking accuracy on validation set\n",
      "06/02 03:23:06 PM Loss (0.344138)\n",
      "06/02 03:23:06 PM Got 24981 / 39868 correct (62.66)\n",
      "06/02 03:23:06 PM \n",
      "06/02 03:23:06 PM Epoch 19, Iteration 0, loss = 0.6133\n",
      "06/02 03:23:07 PM Epoch 19, Iteration 100, loss = 0.6087\n",
      "06/02 03:23:08 PM Epoch 19, Iteration 200, loss = 0.6086\n",
      "06/02 03:23:09 PM Checking accuracy on training set\n",
      "06/02 03:23:10 PM Loss (0.596982)\n",
      "06/02 03:23:10 PM Got 43597 / 71381 correct (61.08)\n",
      "06/02 03:23:10 PM Checking accuracy on validation set\n",
      "06/02 03:23:11 PM Loss (0.345047)\n",
      "06/02 03:23:11 PM Got 24980 / 39868 correct (62.66)\n",
      "06/02 03:23:11 PM \n",
      "06/02 03:23:11 PM Epoch 20, Iteration 0, loss = 0.6145\n",
      "06/02 03:23:12 PM Epoch 20, Iteration 100, loss = 0.5730\n",
      "06/02 03:23:13 PM Epoch 20, Iteration 200, loss = 0.5911\n",
      "06/02 03:23:13 PM Checking accuracy on training set\n",
      "06/02 03:23:15 PM Loss (0.592126)\n",
      "06/02 03:23:15 PM Got 43597 / 71381 correct (61.08)\n",
      "06/02 03:23:15 PM Checking accuracy on validation set\n",
      "06/02 03:23:15 PM Loss (0.343919)\n",
      "06/02 03:23:15 PM Got 24980 / 39868 correct (62.66)\n",
      "06/02 03:23:15 PM \n",
      "06/02 03:23:15 PM Epoch 21, Iteration 0, loss = 0.5832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/02 03:23:16 PM Epoch 21, Iteration 100, loss = 0.6304\n",
      "06/02 03:23:17 PM Epoch 21, Iteration 200, loss = 0.6327\n",
      "06/02 03:23:18 PM Checking accuracy on training set\n",
      "06/02 03:23:19 PM Loss (0.625260)\n",
      "06/02 03:23:19 PM Got 43597 / 71381 correct (61.08)\n",
      "06/02 03:23:19 PM Checking accuracy on validation set\n",
      "06/02 03:23:20 PM Loss (0.343380)\n",
      "06/02 03:23:20 PM Got 24980 / 39868 correct (62.66)\n",
      "06/02 03:23:20 PM \n",
      "06/02 03:23:20 PM Epoch 22, Iteration 0, loss = 0.6123\n",
      "06/02 03:23:21 PM Epoch 22, Iteration 100, loss = 0.5725\n",
      "06/02 03:23:22 PM Epoch 22, Iteration 200, loss = 0.5874\n",
      "06/02 03:23:23 PM Checking accuracy on training set\n",
      "06/02 03:23:24 PM Loss (0.616428)\n",
      "06/02 03:23:24 PM Got 43597 / 71381 correct (61.08)\n",
      "06/02 03:23:24 PM Checking accuracy on validation set\n",
      "06/02 03:23:25 PM Loss (0.338146)\n",
      "06/02 03:23:25 PM Got 24980 / 39868 correct (62.66)\n",
      "06/02 03:23:25 PM \n",
      "06/02 03:23:25 PM Epoch 23, Iteration 0, loss = 0.5969\n",
      "06/02 03:23:26 PM Epoch 23, Iteration 100, loss = 0.6308\n",
      "06/02 03:23:27 PM Epoch 23, Iteration 200, loss = 0.6248\n",
      "06/02 03:23:28 PM Checking accuracy on training set\n",
      "06/02 03:23:29 PM Loss (0.619761)\n",
      "06/02 03:23:29 PM Got 43597 / 71381 correct (61.08)\n",
      "06/02 03:23:29 PM Checking accuracy on validation set\n",
      "06/02 03:23:30 PM Loss (0.338460)\n",
      "06/02 03:23:30 PM Got 24980 / 39868 correct (62.66)\n",
      "06/02 03:23:30 PM \n",
      "06/02 03:23:30 PM Epoch 24, Iteration 0, loss = 0.5680\n",
      "06/02 03:23:31 PM Epoch 24, Iteration 100, loss = 0.5682\n",
      "06/02 03:23:32 PM Epoch 24, Iteration 200, loss = 0.6139\n",
      "06/02 03:23:32 PM Checking accuracy on training set\n",
      "06/02 03:23:34 PM Loss (0.615788)\n",
      "06/02 03:23:34 PM Got 43606 / 71381 correct (61.09)\n",
      "06/02 03:23:34 PM Checking accuracy on validation set\n",
      "06/02 03:23:34 PM Loss (0.339206)\n",
      "06/02 03:23:34 PM Got 24980 / 39868 correct (62.66)\n",
      "06/02 03:23:34 PM \n",
      "06/02 03:23:34 PM Epoch 25, Iteration 0, loss = 0.6234\n",
      "06/02 03:23:35 PM Epoch 25, Iteration 100, loss = 0.5704\n",
      "06/02 03:23:36 PM Epoch 25, Iteration 200, loss = 0.5781\n",
      "06/02 03:23:37 PM Checking accuracy on training set\n",
      "06/02 03:23:38 PM Loss (0.581882)\n",
      "06/02 03:23:38 PM Got 43614 / 71381 correct (61.10)\n",
      "06/02 03:23:38 PM Checking accuracy on validation set\n",
      "06/02 03:23:39 PM Loss (0.341520)\n",
      "06/02 03:23:39 PM Got 24978 / 39868 correct (62.65)\n",
      "06/02 03:23:39 PM \n",
      "06/02 03:23:39 PM Epoch 26, Iteration 0, loss = 0.6627\n",
      "06/02 03:23:40 PM Epoch 26, Iteration 100, loss = 0.5610\n",
      "06/02 03:23:41 PM Epoch 26, Iteration 200, loss = 0.5751\n",
      "06/02 03:23:42 PM Checking accuracy on training set\n",
      "06/02 03:23:43 PM Loss (0.571172)\n",
      "06/02 03:23:43 PM Got 43598 / 71381 correct (61.08)\n",
      "06/02 03:23:43 PM Checking accuracy on validation set\n",
      "06/02 03:23:44 PM Loss (0.344024)\n",
      "06/02 03:23:44 PM Got 24980 / 39868 correct (62.66)\n",
      "06/02 03:23:44 PM \n",
      "06/02 03:23:44 PM Epoch 27, Iteration 0, loss = 0.6033\n",
      "06/02 03:23:45 PM Epoch 27, Iteration 100, loss = 0.5777\n",
      "06/02 03:23:46 PM Epoch 27, Iteration 200, loss = 0.5915\n",
      "06/02 03:23:47 PM Checking accuracy on training set\n",
      "06/02 03:23:48 PM Loss (0.633406)\n",
      "06/02 03:23:48 PM Got 43675 / 71381 correct (61.19)\n",
      "06/02 03:23:48 PM Checking accuracy on validation set\n",
      "06/02 03:23:48 PM Loss (0.344580)\n",
      "06/02 03:23:48 PM Got 24970 / 39868 correct (62.63)\n",
      "06/02 03:23:48 PM \n",
      "06/02 03:23:49 PM Epoch 28, Iteration 0, loss = 0.6099\n",
      "06/02 03:23:50 PM Epoch 28, Iteration 100, loss = 0.5865\n",
      "06/02 03:23:51 PM Epoch 28, Iteration 200, loss = 0.5920\n",
      "06/02 03:23:51 PM Checking accuracy on training set\n",
      "06/02 03:23:53 PM Loss (0.600074)\n",
      "06/02 03:23:53 PM Got 43887 / 71381 correct (61.48)\n",
      "06/02 03:23:53 PM Checking accuracy on validation set\n",
      "06/02 03:23:53 PM Loss (0.344290)\n",
      "06/02 03:23:53 PM Got 24905 / 39868 correct (62.47)\n",
      "06/02 03:23:53 PM \n",
      "06/02 03:23:53 PM Epoch 29, Iteration 0, loss = 0.5895\n",
      "06/02 03:23:54 PM Epoch 29, Iteration 100, loss = 0.6233\n",
      "06/02 03:23:55 PM Epoch 29, Iteration 200, loss = 0.5603\n",
      "06/02 03:23:56 PM Checking accuracy on training set\n",
      "06/02 03:23:57 PM Loss (0.591139)\n",
      "06/02 03:23:57 PM Got 43834 / 71381 correct (61.41)\n",
      "06/02 03:23:57 PM Checking accuracy on validation set\n",
      "06/02 03:23:58 PM Loss (0.342204)\n",
      "06/02 03:23:58 PM Got 24945 / 39868 correct (62.57)\n",
      "06/02 03:23:58 PM \n",
      "06/02 03:23:58 PM Epoch 30, Iteration 0, loss = 0.5624\n",
      "06/02 03:23:59 PM Epoch 30, Iteration 100, loss = 0.6492\n",
      "06/02 03:24:00 PM Epoch 30, Iteration 200, loss = 0.5630\n",
      "06/02 03:24:01 PM Checking accuracy on training set\n",
      "06/02 03:24:02 PM Loss (0.569012)\n",
      "06/02 03:24:02 PM Got 43681 / 71381 correct (61.19)\n",
      "06/02 03:24:02 PM Checking accuracy on validation set\n",
      "06/02 03:24:03 PM Loss (0.340868)\n",
      "06/02 03:24:03 PM Got 24973 / 39868 correct (62.64)\n",
      "06/02 03:24:03 PM \n",
      "06/02 03:24:03 PM Epoch 31, Iteration 0, loss = 0.5784\n",
      "06/02 03:24:04 PM Epoch 31, Iteration 100, loss = 0.5866\n",
      "06/02 03:24:05 PM Epoch 31, Iteration 200, loss = 0.5731\n",
      "06/02 03:24:06 PM Checking accuracy on training set\n",
      "06/02 03:24:07 PM Loss (0.580031)\n",
      "06/02 03:24:07 PM Got 43664 / 71381 correct (61.17)\n",
      "06/02 03:24:07 PM Checking accuracy on validation set\n",
      "06/02 03:24:08 PM Loss (0.347287)\n",
      "06/02 03:24:08 PM Got 24973 / 39868 correct (62.64)\n",
      "06/02 03:24:08 PM \n",
      "06/02 03:24:08 PM Epoch 32, Iteration 0, loss = 0.5690\n",
      "06/02 03:24:09 PM Epoch 32, Iteration 100, loss = 0.5695\n",
      "06/02 03:24:10 PM Epoch 32, Iteration 200, loss = 0.6298\n",
      "06/02 03:24:10 PM Checking accuracy on training set\n",
      "06/02 03:24:12 PM Loss (0.555658)\n",
      "06/02 03:24:12 PM Got 43750 / 71381 correct (61.29)\n",
      "06/02 03:24:12 PM Checking accuracy on validation set\n",
      "06/02 03:24:12 PM Loss (0.345309)\n",
      "06/02 03:24:12 PM Got 24965 / 39868 correct (62.62)\n",
      "06/02 03:24:12 PM \n",
      "06/02 03:24:12 PM Epoch 33, Iteration 0, loss = 0.6121\n",
      "06/02 03:24:13 PM Epoch 33, Iteration 100, loss = 0.6082\n",
      "06/02 03:24:14 PM Epoch 33, Iteration 200, loss = 0.5976\n",
      "06/02 03:24:15 PM Checking accuracy on training set\n",
      "06/02 03:24:16 PM Loss (0.593642)\n",
      "06/02 03:24:16 PM Got 43976 / 71381 correct (61.61)\n",
      "06/02 03:24:16 PM Checking accuracy on validation set\n",
      "06/02 03:24:17 PM Loss (0.344589)\n",
      "06/02 03:24:17 PM Got 24932 / 39868 correct (62.54)\n",
      "06/02 03:24:17 PM \n",
      "06/02 03:24:17 PM Epoch 34, Iteration 0, loss = 0.6211\n",
      "06/02 03:24:18 PM Epoch 34, Iteration 100, loss = 0.6406\n",
      "06/02 03:24:19 PM Epoch 34, Iteration 200, loss = 0.6101\n",
      "06/02 03:24:20 PM Checking accuracy on training set\n",
      "06/02 03:24:21 PM Loss (0.620023)\n",
      "06/02 03:24:21 PM Got 43996 / 71381 correct (61.64)\n",
      "06/02 03:24:21 PM Checking accuracy on validation set\n",
      "06/02 03:24:22 PM Loss (0.340792)\n",
      "06/02 03:24:22 PM Got 24933 / 39868 correct (62.54)\n",
      "06/02 03:24:22 PM \n",
      "06/02 03:24:22 PM Epoch 35, Iteration 0, loss = 0.5936\n",
      "06/02 03:24:23 PM Epoch 35, Iteration 100, loss = 0.5896\n",
      "06/02 03:24:24 PM Epoch 35, Iteration 200, loss = 0.6070\n",
      "06/02 03:24:25 PM Checking accuracy on training set\n",
      "06/02 03:24:26 PM Loss (0.617777)\n",
      "06/02 03:24:26 PM Got 43903 / 71381 correct (61.51)\n",
      "06/02 03:24:26 PM Checking accuracy on validation set\n",
      "06/02 03:24:26 PM Loss (0.343352)\n",
      "06/02 03:24:26 PM Got 24955 / 39868 correct (62.59)\n",
      "06/02 03:24:26 PM \n",
      "06/02 03:24:26 PM Epoch 36, Iteration 0, loss = 0.6204\n",
      "06/02 03:24:28 PM Epoch 36, Iteration 100, loss = 0.5923\n",
      "06/02 03:24:29 PM Epoch 36, Iteration 200, loss = 0.6081\n",
      "06/02 03:24:29 PM Checking accuracy on training set\n",
      "06/02 03:24:31 PM Loss (0.572207)\n",
      "06/02 03:24:31 PM Got 43733 / 71381 correct (61.27)\n",
      "06/02 03:24:31 PM Checking accuracy on validation set\n",
      "06/02 03:24:31 PM Loss (0.338759)\n",
      "06/02 03:24:31 PM Got 24969 / 39868 correct (62.63)\n",
      "06/02 03:24:31 PM \n",
      "06/02 03:24:31 PM Epoch 37, Iteration 0, loss = 0.5759\n",
      "06/02 03:24:32 PM Epoch 37, Iteration 100, loss = 0.6302\n",
      "06/02 03:24:33 PM Epoch 37, Iteration 200, loss = 0.5907\n",
      "06/02 03:24:34 PM Checking accuracy on training set\n",
      "06/02 03:24:35 PM Loss (0.575744)\n",
      "06/02 03:24:35 PM Got 44033 / 71381 correct (61.69)\n",
      "06/02 03:24:35 PM Checking accuracy on validation set\n",
      "06/02 03:24:36 PM Loss (0.342100)\n",
      "06/02 03:24:36 PM Got 24929 / 39868 correct (62.53)\n",
      "06/02 03:24:36 PM \n",
      "06/02 03:24:36 PM Epoch 38, Iteration 0, loss = 0.5681\n",
      "06/02 03:24:37 PM Epoch 38, Iteration 100, loss = 0.5963\n",
      "06/02 03:24:38 PM Epoch 38, Iteration 200, loss = 0.5984\n",
      "06/02 03:24:39 PM Checking accuracy on training set\n",
      "06/02 03:24:40 PM Loss (0.612116)\n",
      "06/02 03:24:40 PM Got 44088 / 71381 correct (61.76)\n",
      "06/02 03:24:40 PM Checking accuracy on validation set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/02 03:24:41 PM Loss (0.342820)\n",
      "06/02 03:24:41 PM Got 24924 / 39868 correct (62.52)\n",
      "06/02 03:24:41 PM \n",
      "06/02 03:24:41 PM Epoch 39, Iteration 0, loss = 0.5885\n",
      "06/02 03:24:42 PM Epoch 39, Iteration 100, loss = 0.5676\n",
      "06/02 03:24:43 PM Epoch 39, Iteration 200, loss = 0.6057\n",
      "06/02 03:24:44 PM Checking accuracy on training set\n",
      "06/02 03:24:45 PM Loss (0.576039)\n",
      "06/02 03:24:45 PM Got 43616 / 71381 correct (61.10)\n",
      "06/02 03:24:45 PM Checking accuracy on validation set\n",
      "06/02 03:24:45 PM Loss (0.339843)\n",
      "06/02 03:24:45 PM Got 24973 / 39868 correct (62.64)\n",
      "06/02 03:24:45 PM \n",
      "06/02 03:24:46 PM Epoch 0, Iteration 0, loss = 5.5805\n",
      "06/02 03:24:47 PM Epoch 0, Iteration 100, loss = 0.6762\n",
      "06/02 03:24:48 PM Epoch 0, Iteration 200, loss = 0.6473\n",
      "06/02 03:24:48 PM Checking accuracy on training set\n",
      "06/02 03:24:50 PM Loss (0.641453)\n",
      "06/02 03:24:50 PM Got 43597 / 71381 correct (61.08)\n",
      "06/02 03:24:50 PM Checking accuracy on validation set\n",
      "06/02 03:24:50 PM Loss (0.525871)\n",
      "06/02 03:24:50 PM Got 24980 / 39868 correct (62.66)\n",
      "06/02 03:24:50 PM \n",
      "06/02 03:24:50 PM Epoch 1, Iteration 0, loss = 0.6109\n",
      "06/02 03:24:51 PM Epoch 1, Iteration 100, loss = 0.6044\n",
      "06/02 03:24:52 PM Epoch 1, Iteration 200, loss = 0.5997\n",
      "06/02 03:24:53 PM Checking accuracy on training set\n",
      "06/02 03:24:54 PM Loss (0.615445)\n",
      "06/02 03:24:54 PM Got 43597 / 71381 correct (61.08)\n",
      "06/02 03:24:54 PM Checking accuracy on validation set\n",
      "06/02 03:24:55 PM Loss (0.415296)\n",
      "06/02 03:24:55 PM Got 24980 / 39868 correct (62.66)\n",
      "06/02 03:24:55 PM \n",
      "06/02 03:24:55 PM Epoch 2, Iteration 0, loss = 0.6034\n",
      "06/02 03:24:56 PM Epoch 2, Iteration 100, loss = 0.6457\n",
      "06/02 03:24:57 PM Epoch 2, Iteration 200, loss = 0.5954\n",
      "06/02 03:24:58 PM Checking accuracy on training set\n",
      "06/02 03:24:59 PM Loss (0.585876)\n",
      "06/02 03:24:59 PM Got 43597 / 71381 correct (61.08)\n",
      "06/02 03:24:59 PM Checking accuracy on validation set\n",
      "06/02 03:25:00 PM Loss (0.367034)\n",
      "06/02 03:25:00 PM Got 24980 / 39868 correct (62.66)\n",
      "06/02 03:25:00 PM \n",
      "06/02 03:25:00 PM Epoch 3, Iteration 0, loss = 0.5812\n",
      "06/02 03:25:01 PM Epoch 3, Iteration 100, loss = 0.6583\n",
      "06/02 03:25:02 PM Epoch 3, Iteration 200, loss = 0.5936\n",
      "06/02 03:25:03 PM Checking accuracy on training set\n",
      "06/02 03:25:04 PM Loss (0.553120)\n",
      "06/02 03:25:04 PM Got 43597 / 71381 correct (61.08)\n",
      "06/02 03:25:04 PM Checking accuracy on validation set\n",
      "06/02 03:25:05 PM Loss (0.348367)\n",
      "06/02 03:25:05 PM Got 24980 / 39868 correct (62.66)\n",
      "06/02 03:25:05 PM \n",
      "06/02 03:25:05 PM Epoch 4, Iteration 0, loss = 0.5993\n",
      "06/02 03:25:06 PM Epoch 4, Iteration 100, loss = 0.5785\n",
      "06/02 03:25:07 PM Epoch 4, Iteration 200, loss = 0.6022\n",
      "06/02 03:25:07 PM Checking accuracy on training set\n",
      "06/02 03:25:09 PM Loss (0.645869)\n",
      "06/02 03:25:09 PM Got 43597 / 71381 correct (61.08)\n",
      "06/02 03:25:09 PM Checking accuracy on validation set\n",
      "06/02 03:25:09 PM Loss (0.343927)\n",
      "06/02 03:25:09 PM Got 24980 / 39868 correct (62.66)\n",
      "06/02 03:25:09 PM \n",
      "06/02 03:25:09 PM Epoch 5, Iteration 0, loss = 0.5553\n",
      "06/02 03:25:10 PM Epoch 5, Iteration 100, loss = 0.6268\n",
      "06/02 03:25:11 PM Epoch 5, Iteration 200, loss = 0.6173\n",
      "06/02 03:25:12 PM Checking accuracy on training set\n",
      "06/02 03:25:13 PM Loss (0.579868)\n",
      "06/02 03:25:13 PM Got 43597 / 71381 correct (61.08)\n",
      "06/02 03:25:13 PM Checking accuracy on validation set\n",
      "06/02 03:25:14 PM Loss (0.342112)\n",
      "06/02 03:25:14 PM Got 24980 / 39868 correct (62.66)\n",
      "06/02 03:25:14 PM \n",
      "06/02 03:25:14 PM Epoch 6, Iteration 0, loss = 0.6113\n",
      "06/02 03:25:15 PM Epoch 6, Iteration 100, loss = 0.6083\n",
      "06/02 03:25:16 PM Epoch 6, Iteration 200, loss = 0.5584\n",
      "06/02 03:25:17 PM Checking accuracy on training set\n",
      "06/02 03:25:18 PM Loss (0.642685)\n",
      "06/02 03:25:18 PM Got 43597 / 71381 correct (61.08)\n",
      "06/02 03:25:18 PM Checking accuracy on validation set\n",
      "06/02 03:25:19 PM Loss (0.340080)\n",
      "06/02 03:25:19 PM Got 24980 / 39868 correct (62.66)\n",
      "06/02 03:25:19 PM \n",
      "06/02 03:25:19 PM Epoch 7, Iteration 0, loss = 0.5721\n",
      "06/02 03:25:20 PM Epoch 7, Iteration 100, loss = 0.6145\n",
      "06/02 03:25:21 PM Epoch 7, Iteration 200, loss = 0.5871\n",
      "06/02 03:25:22 PM Checking accuracy on training set\n",
      "06/02 03:25:23 PM Loss (0.586928)\n",
      "06/02 03:25:23 PM Got 43597 / 71381 correct (61.08)\n",
      "06/02 03:25:23 PM Checking accuracy on validation set\n",
      "06/02 03:25:24 PM Loss (0.340759)\n",
      "06/02 03:25:24 PM Got 24980 / 39868 correct (62.66)\n",
      "06/02 03:25:24 PM \n",
      "06/02 03:25:24 PM Epoch 8, Iteration 0, loss = 0.6145\n",
      "06/02 03:25:25 PM Epoch 8, Iteration 100, loss = 0.6332\n",
      "06/02 03:25:26 PM Epoch 8, Iteration 200, loss = 0.5664\n",
      "06/02 03:25:26 PM Checking accuracy on training set\n",
      "06/02 03:25:28 PM Loss (0.627146)\n",
      "06/02 03:25:28 PM Got 43597 / 71381 correct (61.08)\n",
      "06/02 03:25:28 PM Checking accuracy on validation set\n",
      "06/02 03:25:28 PM Loss (0.343450)\n",
      "06/02 03:25:28 PM Got 24980 / 39868 correct (62.66)\n",
      "06/02 03:25:28 PM \n",
      "06/02 03:25:28 PM Epoch 9, Iteration 0, loss = 0.6205\n",
      "06/02 03:25:29 PM Epoch 9, Iteration 100, loss = 0.5962\n",
      "06/02 03:25:30 PM Epoch 9, Iteration 200, loss = 0.6272\n",
      "06/02 03:25:31 PM Checking accuracy on training set\n",
      "06/02 03:25:32 PM Loss (0.594231)\n",
      "06/02 03:25:32 PM Got 43597 / 71381 correct (61.08)\n",
      "06/02 03:25:32 PM Checking accuracy on validation set\n",
      "06/02 03:25:33 PM Loss (0.343283)\n",
      "06/02 03:25:33 PM Got 24980 / 39868 correct (62.66)\n",
      "06/02 03:25:33 PM \n",
      "06/02 03:25:33 PM Epoch 10, Iteration 0, loss = 0.6360\n",
      "06/02 03:25:34 PM Epoch 10, Iteration 100, loss = 0.6083\n",
      "06/02 03:25:35 PM Epoch 10, Iteration 200, loss = 0.6237\n",
      "06/02 03:25:36 PM Checking accuracy on training set\n",
      "06/02 03:25:37 PM Loss (0.616147)\n",
      "06/02 03:25:37 PM Got 43597 / 71381 correct (61.08)\n",
      "06/02 03:25:37 PM Checking accuracy on validation set\n",
      "06/02 03:25:38 PM Loss (0.341542)\n",
      "06/02 03:25:38 PM Got 24980 / 39868 correct (62.66)\n",
      "06/02 03:25:38 PM \n",
      "06/02 03:25:38 PM Epoch 11, Iteration 0, loss = 0.5931\n",
      "06/02 03:25:39 PM Epoch 11, Iteration 100, loss = 0.6394\n",
      "06/02 03:25:40 PM Epoch 11, Iteration 200, loss = 0.6425\n",
      "06/02 03:25:41 PM Checking accuracy on training set\n",
      "06/02 03:25:42 PM Loss (0.665555)\n",
      "06/02 03:25:42 PM Got 43597 / 71381 correct (61.08)\n",
      "06/02 03:25:42 PM Checking accuracy on validation set\n",
      "06/02 03:25:43 PM Loss (0.341731)\n",
      "06/02 03:25:43 PM Got 24980 / 39868 correct (62.66)\n",
      "06/02 03:25:43 PM \n",
      "06/02 03:25:43 PM Epoch 12, Iteration 0, loss = 0.6083\n",
      "06/02 03:25:44 PM Epoch 12, Iteration 100, loss = 0.5552\n",
      "06/02 03:25:45 PM Epoch 12, Iteration 200, loss = 0.5991\n",
      "06/02 03:25:45 PM Checking accuracy on training set\n",
      "06/02 03:25:47 PM Loss (0.544586)\n",
      "06/02 03:25:47 PM Got 43597 / 71381 correct (61.08)\n",
      "06/02 03:25:47 PM Checking accuracy on validation set\n",
      "06/02 03:25:47 PM Loss (0.340140)\n",
      "06/02 03:25:47 PM Got 24980 / 39868 correct (62.66)\n",
      "06/02 03:25:47 PM \n",
      "06/02 03:25:47 PM Epoch 13, Iteration 0, loss = 0.5931\n",
      "06/02 03:25:48 PM Epoch 13, Iteration 100, loss = 0.6114\n",
      "06/02 03:25:49 PM Epoch 13, Iteration 200, loss = 0.6052\n",
      "06/02 03:25:50 PM Checking accuracy on training set\n",
      "06/02 03:25:51 PM Loss (0.634792)\n",
      "06/02 03:25:51 PM Got 43597 / 71381 correct (61.08)\n",
      "06/02 03:25:51 PM Checking accuracy on validation set\n",
      "06/02 03:25:52 PM Loss (0.342082)\n",
      "06/02 03:25:52 PM Got 24980 / 39868 correct (62.66)\n",
      "06/02 03:25:52 PM \n",
      "06/02 03:25:52 PM Epoch 14, Iteration 0, loss = 0.6113\n",
      "06/02 03:25:53 PM Epoch 14, Iteration 100, loss = 0.5778\n",
      "06/02 03:25:54 PM Epoch 14, Iteration 200, loss = 0.6116\n",
      "06/02 03:25:55 PM Checking accuracy on training set\n",
      "06/02 03:25:56 PM Loss (0.573299)\n",
      "06/02 03:25:56 PM Got 43597 / 71381 correct (61.08)\n",
      "06/02 03:25:56 PM Checking accuracy on validation set\n",
      "06/02 03:25:57 PM Loss (0.346486)\n",
      "06/02 03:25:57 PM Got 24980 / 39868 correct (62.66)\n",
      "06/02 03:25:57 PM \n",
      "06/02 03:25:57 PM Epoch 15, Iteration 0, loss = 0.5787\n",
      "06/02 03:25:58 PM Epoch 15, Iteration 100, loss = 0.6082\n",
      "06/02 03:25:59 PM Epoch 15, Iteration 200, loss = 0.5992\n",
      "06/02 03:26:00 PM Checking accuracy on training set\n",
      "06/02 03:26:01 PM Loss (0.579686)\n",
      "06/02 03:26:01 PM Got 43597 / 71381 correct (61.08)\n",
      "06/02 03:26:01 PM Checking accuracy on validation set\n",
      "06/02 03:26:02 PM Loss (0.339905)\n",
      "06/02 03:26:02 PM Got 24980 / 39868 correct (62.66)\n",
      "06/02 03:26:02 PM \n",
      "06/02 03:26:02 PM Epoch 16, Iteration 0, loss = 0.5840\n",
      "06/02 03:26:03 PM Epoch 16, Iteration 100, loss = 0.6234\n",
      "06/02 03:26:04 PM Epoch 16, Iteration 200, loss = 0.6518\n",
      "06/02 03:26:04 PM Checking accuracy on training set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/02 03:26:06 PM Loss (0.575965)\n",
      "06/02 03:26:06 PM Got 43597 / 71381 correct (61.08)\n",
      "06/02 03:26:06 PM Checking accuracy on validation set\n",
      "06/02 03:26:06 PM Loss (0.338332)\n",
      "06/02 03:26:06 PM Got 24980 / 39868 correct (62.66)\n",
      "06/02 03:26:06 PM \n",
      "06/02 03:26:06 PM Epoch 17, Iteration 0, loss = 0.6053\n",
      "06/02 03:26:07 PM Epoch 17, Iteration 100, loss = 0.6176\n",
      "06/02 03:26:08 PM Epoch 17, Iteration 200, loss = 0.6393\n",
      "06/02 03:26:09 PM Checking accuracy on training set\n",
      "06/02 03:26:10 PM Loss (0.623606)\n",
      "06/02 03:26:10 PM Got 43597 / 71381 correct (61.08)\n",
      "06/02 03:26:10 PM Checking accuracy on validation set\n",
      "06/02 03:26:11 PM Loss (0.341320)\n",
      "06/02 03:26:11 PM Got 24980 / 39868 correct (62.66)\n",
      "06/02 03:26:11 PM \n",
      "06/02 03:26:11 PM Epoch 18, Iteration 0, loss = 0.5723\n",
      "06/02 03:26:12 PM Epoch 18, Iteration 100, loss = 0.6022\n",
      "06/02 03:26:13 PM Epoch 18, Iteration 200, loss = 0.5900\n",
      "06/02 03:26:14 PM Checking accuracy on training set\n",
      "06/02 03:26:15 PM Loss (0.573038)\n",
      "06/02 03:26:15 PM Got 43597 / 71381 correct (61.08)\n",
      "06/02 03:26:15 PM Checking accuracy on validation set\n",
      "06/02 03:26:16 PM Loss (0.344288)\n",
      "06/02 03:26:16 PM Got 24980 / 39868 correct (62.66)\n",
      "06/02 03:26:16 PM \n",
      "06/02 03:26:16 PM Epoch 19, Iteration 0, loss = 0.5902\n",
      "06/02 03:26:17 PM Epoch 19, Iteration 100, loss = 0.5961\n",
      "06/02 03:26:18 PM Epoch 19, Iteration 200, loss = 0.6547\n",
      "06/02 03:26:19 PM Checking accuracy on training set\n",
      "06/02 03:26:20 PM Loss (0.642322)\n",
      "06/02 03:26:20 PM Got 43597 / 71381 correct (61.08)\n",
      "06/02 03:26:20 PM Checking accuracy on validation set\n",
      "06/02 03:26:21 PM Loss (0.342376)\n",
      "06/02 03:26:21 PM Got 24980 / 39868 correct (62.66)\n",
      "06/02 03:26:21 PM \n",
      "06/02 03:26:21 PM Epoch 20, Iteration 0, loss = 0.6113\n",
      "06/02 03:26:22 PM Epoch 20, Iteration 100, loss = 0.5991\n",
      "06/02 03:26:23 PM Epoch 20, Iteration 200, loss = 0.6114\n",
      "06/02 03:26:23 PM Checking accuracy on training set\n",
      "06/02 03:26:25 PM Loss (0.601451)\n",
      "06/02 03:26:25 PM Got 43597 / 71381 correct (61.08)\n",
      "06/02 03:26:25 PM Checking accuracy on validation set\n",
      "06/02 03:26:25 PM Loss (0.343835)\n",
      "06/02 03:26:25 PM Got 24980 / 39868 correct (62.66)\n",
      "06/02 03:26:25 PM \n",
      "06/02 03:26:25 PM Epoch 21, Iteration 0, loss = 0.5992\n",
      "06/02 03:26:26 PM Epoch 21, Iteration 100, loss = 0.5752\n",
      "06/02 03:26:27 PM Epoch 21, Iteration 200, loss = 0.6716\n",
      "06/02 03:26:28 PM Checking accuracy on training set\n",
      "06/02 03:26:29 PM Loss (0.616099)\n",
      "06/02 03:26:29 PM Got 43597 / 71381 correct (61.08)\n",
      "06/02 03:26:29 PM Checking accuracy on validation set\n",
      "06/02 03:26:30 PM Loss (0.342419)\n",
      "06/02 03:26:30 PM Got 24980 / 39868 correct (62.66)\n",
      "06/02 03:26:30 PM \n",
      "06/02 03:26:30 PM Epoch 22, Iteration 0, loss = 0.5872\n",
      "06/02 03:26:31 PM Epoch 22, Iteration 100, loss = 0.6269\n",
      "06/02 03:26:32 PM Epoch 22, Iteration 200, loss = 0.5961\n",
      "06/02 03:26:33 PM Checking accuracy on training set\n",
      "06/02 03:26:34 PM Loss (0.551383)\n",
      "06/02 03:26:34 PM Got 43597 / 71381 correct (61.08)\n",
      "06/02 03:26:34 PM Checking accuracy on validation set\n",
      "06/02 03:26:35 PM Loss (0.339511)\n",
      "06/02 03:26:35 PM Got 24980 / 39868 correct (62.66)\n",
      "06/02 03:26:35 PM \n",
      "06/02 03:26:35 PM Epoch 23, Iteration 0, loss = 0.6429\n",
      "06/02 03:26:36 PM Epoch 23, Iteration 100, loss = 0.5992\n",
      "06/02 03:26:37 PM Epoch 23, Iteration 200, loss = 0.5992\n",
      "06/02 03:26:38 PM Checking accuracy on training set\n",
      "06/02 03:26:39 PM Loss (0.594114)\n",
      "06/02 03:26:39 PM Got 43597 / 71381 correct (61.08)\n",
      "06/02 03:26:39 PM Checking accuracy on validation set\n",
      "06/02 03:26:40 PM Loss (0.339000)\n",
      "06/02 03:26:40 PM Got 24980 / 39868 correct (62.66)\n",
      "06/02 03:26:40 PM \n",
      "06/02 03:26:40 PM Epoch 24, Iteration 0, loss = 0.6177\n",
      "06/02 03:26:41 PM Epoch 24, Iteration 100, loss = 0.6240\n",
      "06/02 03:26:42 PM Epoch 24, Iteration 200, loss = 0.6236\n",
      "06/02 03:26:42 PM Checking accuracy on training set\n",
      "06/02 03:26:44 PM Loss (0.616157)\n",
      "06/02 03:26:44 PM Got 43597 / 71381 correct (61.08)\n",
      "06/02 03:26:44 PM Checking accuracy on validation set\n",
      "06/02 03:26:44 PM Loss (0.341362)\n",
      "06/02 03:26:44 PM Got 24980 / 39868 correct (62.66)\n",
      "06/02 03:26:44 PM \n",
      "06/02 03:26:44 PM Epoch 25, Iteration 0, loss = 0.6237\n",
      "06/02 03:26:45 PM Epoch 25, Iteration 100, loss = 0.6144\n",
      "06/02 03:26:46 PM Epoch 25, Iteration 200, loss = 0.5992\n",
      "06/02 03:26:47 PM Checking accuracy on training set\n",
      "06/02 03:26:48 PM Loss (0.558359)\n",
      "06/02 03:26:48 PM Got 43597 / 71381 correct (61.08)\n",
      "06/02 03:26:48 PM Checking accuracy on validation set\n",
      "06/02 03:26:49 PM Loss (0.339451)\n",
      "06/02 03:26:49 PM Got 24980 / 39868 correct (62.66)\n",
      "06/02 03:26:49 PM \n",
      "06/02 03:26:49 PM Epoch 26, Iteration 0, loss = 0.5780\n",
      "06/02 03:26:50 PM Epoch 26, Iteration 100, loss = 0.6300\n",
      "06/02 03:26:51 PM Epoch 26, Iteration 200, loss = 0.5931\n",
      "06/02 03:26:52 PM Checking accuracy on training set\n",
      "06/02 03:26:53 PM Loss (0.587067)\n",
      "06/02 03:26:53 PM Got 43597 / 71381 correct (61.08)\n",
      "06/02 03:26:53 PM Checking accuracy on validation set\n",
      "06/02 03:26:54 PM Loss (0.343191)\n",
      "06/02 03:26:54 PM Got 24980 / 39868 correct (62.66)\n",
      "06/02 03:26:54 PM \n",
      "06/02 03:26:54 PM Epoch 27, Iteration 0, loss = 0.5992\n",
      "06/02 03:26:55 PM Epoch 27, Iteration 100, loss = 0.5962\n",
      "06/02 03:26:56 PM Epoch 27, Iteration 200, loss = 0.6300\n",
      "06/02 03:26:57 PM Checking accuracy on training set\n",
      "06/02 03:26:58 PM Loss (0.616277)\n",
      "06/02 03:26:58 PM Got 43597 / 71381 correct (61.08)\n",
      "06/02 03:26:58 PM Checking accuracy on validation set\n",
      "06/02 03:26:59 PM Loss (0.339334)\n",
      "06/02 03:26:59 PM Got 24980 / 39868 correct (62.66)\n",
      "06/02 03:26:59 PM \n",
      "06/02 03:26:59 PM Epoch 28, Iteration 0, loss = 0.5991\n",
      "06/02 03:27:00 PM Epoch 28, Iteration 100, loss = 0.5961\n",
      "06/02 03:27:01 PM Epoch 28, Iteration 200, loss = 0.6113\n",
      "06/02 03:27:01 PM Checking accuracy on training set\n",
      "06/02 03:27:03 PM Loss (0.579790)\n",
      "06/02 03:27:03 PM Got 43597 / 71381 correct (61.08)\n",
      "06/02 03:27:03 PM Checking accuracy on validation set\n",
      "06/02 03:27:03 PM Loss (0.341178)\n",
      "06/02 03:27:03 PM Got 24980 / 39868 correct (62.66)\n",
      "06/02 03:27:03 PM \n",
      "06/02 03:27:03 PM Epoch 29, Iteration 0, loss = 0.6144\n",
      "06/02 03:27:04 PM Epoch 29, Iteration 100, loss = 0.5903\n",
      "06/02 03:27:05 PM Epoch 29, Iteration 200, loss = 0.5720\n",
      "06/02 03:27:06 PM Checking accuracy on training set\n",
      "06/02 03:27:07 PM Loss (0.547815)\n",
      "06/02 03:27:07 PM Got 43597 / 71381 correct (61.08)\n",
      "06/02 03:27:07 PM Checking accuracy on validation set\n",
      "06/02 03:27:08 PM Loss (0.339033)\n",
      "06/02 03:27:08 PM Got 24980 / 39868 correct (62.66)\n",
      "06/02 03:27:08 PM \n",
      "06/02 03:27:08 PM Epoch 30, Iteration 0, loss = 0.6334\n",
      "06/02 03:27:09 PM Epoch 30, Iteration 100, loss = 0.6115\n",
      "06/02 03:27:10 PM Epoch 30, Iteration 200, loss = 0.6422\n",
      "06/02 03:27:11 PM Checking accuracy on training set\n",
      "06/02 03:27:12 PM Loss (0.601443)\n",
      "06/02 03:27:12 PM Got 43597 / 71381 correct (61.08)\n",
      "06/02 03:27:12 PM Checking accuracy on validation set\n",
      "06/02 03:27:13 PM Loss (0.341422)\n",
      "06/02 03:27:13 PM Got 24980 / 39868 correct (62.66)\n",
      "06/02 03:27:13 PM \n",
      "06/02 03:27:13 PM Epoch 31, Iteration 0, loss = 0.5992\n",
      "06/02 03:27:14 PM Epoch 31, Iteration 100, loss = 0.5635\n",
      "06/02 03:27:15 PM Epoch 31, Iteration 200, loss = 0.6113\n",
      "06/02 03:27:16 PM Checking accuracy on training set\n",
      "06/02 03:27:17 PM Loss (0.605091)\n",
      "06/02 03:27:17 PM Got 43597 / 71381 correct (61.08)\n",
      "06/02 03:27:17 PM Checking accuracy on validation set\n",
      "06/02 03:27:18 PM Loss (0.341981)\n",
      "06/02 03:27:18 PM Got 24980 / 39868 correct (62.66)\n",
      "06/02 03:27:18 PM \n",
      "06/02 03:27:18 PM Epoch 32, Iteration 0, loss = 0.5871\n",
      "06/02 03:27:19 PM Epoch 32, Iteration 100, loss = 0.5961\n",
      "06/02 03:27:20 PM Epoch 32, Iteration 200, loss = 0.6206\n",
      "06/02 03:27:20 PM Checking accuracy on training set\n",
      "06/02 03:27:22 PM Loss (0.597815)\n",
      "06/02 03:27:22 PM Got 43597 / 71381 correct (61.08)\n",
      "06/02 03:27:22 PM Checking accuracy on validation set\n",
      "06/02 03:27:22 PM Loss (0.342293)\n",
      "06/02 03:27:22 PM Got 24980 / 39868 correct (62.66)\n",
      "06/02 03:27:22 PM \n",
      "06/02 03:27:22 PM Epoch 33, Iteration 0, loss = 0.5636\n",
      "06/02 03:27:23 PM Epoch 33, Iteration 100, loss = 0.5874\n",
      "06/02 03:27:24 PM Epoch 33, Iteration 200, loss = 0.5812\n",
      "06/02 03:27:25 PM Checking accuracy on training set\n",
      "06/02 03:27:26 PM Loss (0.579670)\n",
      "06/02 03:27:26 PM Got 43597 / 71381 correct (61.08)\n",
      "06/02 03:27:26 PM Checking accuracy on validation set\n",
      "06/02 03:27:27 PM Loss (0.339702)\n",
      "06/02 03:27:27 PM Got 24980 / 39868 correct (62.66)\n",
      "06/02 03:27:27 PM \n",
      "06/02 03:27:27 PM Epoch 34, Iteration 0, loss = 0.5840\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/02 03:27:28 PM Epoch 34, Iteration 100, loss = 0.6022\n",
      "06/02 03:27:29 PM Epoch 34, Iteration 200, loss = 0.6206\n",
      "06/02 03:27:30 PM Checking accuracy on training set\n",
      "06/02 03:27:31 PM Loss (0.590405)\n",
      "06/02 03:27:31 PM Got 43597 / 71381 correct (61.08)\n",
      "06/02 03:27:31 PM Checking accuracy on validation set\n",
      "06/02 03:27:32 PM Loss (0.337135)\n",
      "06/02 03:27:32 PM Got 24980 / 39868 correct (62.66)\n",
      "06/02 03:27:32 PM \n",
      "06/02 03:27:32 PM Epoch 35, Iteration 0, loss = 0.5899\n",
      "06/02 03:27:33 PM Epoch 35, Iteration 100, loss = 0.5870\n",
      "06/02 03:27:34 PM Epoch 35, Iteration 200, loss = 0.5754\n",
      "06/02 03:27:35 PM Checking accuracy on training set\n",
      "06/02 03:27:36 PM Loss (0.627377)\n",
      "06/02 03:27:36 PM Got 43597 / 71381 correct (61.08)\n",
      "06/02 03:27:36 PM Checking accuracy on validation set\n",
      "06/02 03:27:37 PM Loss (0.341073)\n",
      "06/02 03:27:37 PM Got 24980 / 39868 correct (62.66)\n",
      "06/02 03:27:37 PM \n",
      "06/02 03:27:37 PM Epoch 36, Iteration 0, loss = 0.5841\n",
      "06/02 03:27:38 PM Epoch 36, Iteration 100, loss = 0.6391\n",
      "06/02 03:27:39 PM Epoch 36, Iteration 200, loss = 0.6515\n",
      "06/02 03:27:39 PM Checking accuracy on training set\n",
      "06/02 03:27:41 PM Loss (0.608993)\n",
      "06/02 03:27:41 PM Got 43597 / 71381 correct (61.08)\n",
      "06/02 03:27:41 PM Checking accuracy on validation set\n",
      "06/02 03:27:41 PM Loss (0.335198)\n",
      "06/02 03:27:41 PM Got 24980 / 39868 correct (62.66)\n",
      "06/02 03:27:41 PM \n",
      "06/02 03:27:41 PM Epoch 37, Iteration 0, loss = 0.5777\n",
      "06/02 03:27:42 PM Epoch 37, Iteration 100, loss = 0.6267\n",
      "06/02 03:27:43 PM Epoch 37, Iteration 200, loss = 0.5779\n",
      "06/02 03:27:44 PM Checking accuracy on training set\n",
      "06/02 03:27:45 PM Loss (0.627750)\n",
      "06/02 03:27:45 PM Got 43597 / 71381 correct (61.08)\n",
      "06/02 03:27:45 PM Checking accuracy on validation set\n",
      "06/02 03:27:46 PM Loss (0.337529)\n",
      "06/02 03:27:46 PM Got 24980 / 39868 correct (62.66)\n",
      "06/02 03:27:46 PM \n",
      "06/02 03:27:46 PM Epoch 38, Iteration 0, loss = 0.5900\n",
      "06/02 03:27:47 PM Epoch 38, Iteration 100, loss = 0.5900\n",
      "06/02 03:27:48 PM Epoch 38, Iteration 200, loss = 0.5903\n",
      "06/02 03:27:49 PM Checking accuracy on training set\n",
      "06/02 03:27:50 PM Loss (0.608797)\n",
      "06/02 03:27:50 PM Got 43597 / 71381 correct (61.08)\n",
      "06/02 03:27:50 PM Checking accuracy on validation set\n",
      "06/02 03:27:51 PM Loss (0.340472)\n",
      "06/02 03:27:51 PM Got 24980 / 39868 correct (62.66)\n",
      "06/02 03:27:51 PM \n",
      "06/02 03:27:51 PM Epoch 39, Iteration 0, loss = 0.6459\n",
      "06/02 03:27:52 PM Epoch 39, Iteration 100, loss = 0.6394\n",
      "06/02 03:27:53 PM Epoch 39, Iteration 200, loss = 0.6052\n",
      "06/02 03:27:54 PM Checking accuracy on training set\n",
      "06/02 03:27:55 PM Loss (0.634890)\n",
      "06/02 03:27:55 PM Got 43597 / 71381 correct (61.08)\n",
      "06/02 03:27:55 PM Checking accuracy on validation set\n",
      "06/02 03:27:56 PM Loss (0.341311)\n",
      "06/02 03:27:56 PM Got 24980 / 39868 correct (62.66)\n",
      "06/02 03:27:56 PM \n",
      "06/02 03:27:56 PM Epoch 0, Iteration 0, loss = 1.9867\n",
      "06/02 03:27:57 PM Epoch 0, Iteration 100, loss = 0.6402\n",
      "06/02 03:27:58 PM Epoch 0, Iteration 200, loss = 0.5218\n",
      "06/02 03:27:59 PM Checking accuracy on training set\n",
      "06/02 03:28:00 PM Loss (0.554298)\n",
      "06/02 03:28:00 PM Got 43794 / 71381 correct (61.35)\n",
      "06/02 03:28:00 PM Checking accuracy on validation set\n",
      "06/02 03:28:00 PM Loss (0.265263)\n",
      "06/02 03:28:00 PM Got 24907 / 39868 correct (62.47)\n",
      "06/02 03:28:00 PM \n",
      "06/02 03:28:00 PM Epoch 1, Iteration 0, loss = 0.6180\n",
      "06/02 03:28:01 PM Epoch 1, Iteration 100, loss = 0.5770\n",
      "06/02 03:28:02 PM Epoch 1, Iteration 200, loss = 0.5497\n",
      "06/02 03:28:03 PM Checking accuracy on training set\n",
      "06/02 03:28:05 PM Loss (0.576991)\n",
      "06/02 03:28:05 PM Got 43960 / 71381 correct (61.59)\n",
      "06/02 03:28:05 PM Checking accuracy on validation set\n",
      "06/02 03:28:05 PM Loss (0.253221)\n",
      "06/02 03:28:05 PM Got 24878 / 39868 correct (62.40)\n",
      "06/02 03:28:05 PM \n",
      "06/02 03:28:05 PM Epoch 2, Iteration 0, loss = 0.5122\n",
      "06/02 03:28:06 PM Epoch 2, Iteration 100, loss = 0.5377\n",
      "06/02 03:28:07 PM Epoch 2, Iteration 200, loss = 0.5547\n",
      "06/02 03:28:08 PM Checking accuracy on training set\n",
      "06/02 03:28:09 PM Loss (0.504490)\n",
      "06/02 03:28:09 PM Got 43651 / 71381 correct (61.15)\n",
      "06/02 03:28:09 PM Checking accuracy on validation set\n",
      "06/02 03:28:10 PM Loss (0.273125)\n",
      "06/02 03:28:10 PM Got 24973 / 39868 correct (62.64)\n",
      "06/02 03:28:10 PM \n",
      "06/02 03:28:10 PM Epoch 3, Iteration 0, loss = 0.5936\n",
      "06/02 03:28:11 PM Epoch 3, Iteration 100, loss = 0.5110\n",
      "06/02 03:28:12 PM Epoch 3, Iteration 200, loss = 0.5335\n",
      "06/02 03:28:13 PM Checking accuracy on training set\n",
      "06/02 03:28:14 PM Loss (0.531701)\n",
      "06/02 03:28:14 PM Got 43848 / 71381 correct (61.43)\n",
      "06/02 03:28:14 PM Checking accuracy on validation set\n",
      "06/02 03:28:15 PM Loss (0.254771)\n",
      "06/02 03:28:15 PM Got 24936 / 39868 correct (62.55)\n",
      "06/02 03:28:15 PM \n",
      "06/02 03:28:15 PM Epoch 4, Iteration 0, loss = 0.5544\n",
      "06/02 03:28:16 PM Epoch 4, Iteration 100, loss = 0.5626\n",
      "06/02 03:28:17 PM Epoch 4, Iteration 200, loss = 0.5195\n",
      "06/02 03:28:17 PM Checking accuracy on training set\n",
      "06/02 03:28:19 PM Loss (0.558357)\n",
      "06/02 03:28:19 PM Got 47453 / 71381 correct (66.48)\n",
      "06/02 03:28:19 PM Checking accuracy on validation set\n",
      "06/02 03:28:19 PM Loss (0.274242)\n",
      "06/02 03:28:19 PM Got 26785 / 39868 correct (67.18)\n",
      "06/02 03:28:19 PM \n",
      "06/02 03:28:19 PM Epoch 5, Iteration 0, loss = 0.7128\n",
      "06/02 03:28:20 PM Epoch 5, Iteration 100, loss = 0.5433\n",
      "06/02 03:28:21 PM Epoch 5, Iteration 200, loss = 0.5022\n",
      "06/02 03:28:22 PM Checking accuracy on training set\n",
      "06/02 03:28:23 PM Loss (0.508187)\n",
      "06/02 03:28:23 PM Got 50080 / 71381 correct (70.16)\n",
      "06/02 03:28:23 PM Checking accuracy on validation set\n",
      "06/02 03:28:24 PM Loss (0.238586)\n",
      "06/02 03:28:24 PM Got 27840 / 39868 correct (69.83)\n",
      "06/02 03:28:24 PM \n",
      "06/02 03:28:24 PM Epoch 6, Iteration 0, loss = 0.5452\n",
      "06/02 03:28:25 PM Epoch 6, Iteration 100, loss = 0.5202\n",
      "06/02 03:28:26 PM Epoch 6, Iteration 200, loss = 0.5065\n",
      "06/02 03:28:27 PM Checking accuracy on training set\n",
      "06/02 03:28:28 PM Loss (0.489344)\n",
      "06/02 03:28:28 PM Got 50690 / 71381 correct (71.01)\n",
      "06/02 03:28:28 PM Checking accuracy on validation set\n",
      "06/02 03:28:29 PM Loss (0.202530)\n",
      "06/02 03:28:29 PM Got 28098 / 39868 correct (70.48)\n",
      "06/02 03:28:29 PM \n",
      "06/02 03:28:29 PM Epoch 7, Iteration 0, loss = 0.5070\n",
      "06/02 03:28:30 PM Epoch 7, Iteration 100, loss = 0.4813\n",
      "06/02 03:28:31 PM Epoch 7, Iteration 200, loss = 0.4692\n",
      "06/02 03:28:32 PM Checking accuracy on training set\n",
      "06/02 03:28:33 PM Loss (0.471727)\n",
      "06/02 03:28:33 PM Got 52156 / 71381 correct (73.07)\n",
      "06/02 03:28:33 PM Checking accuracy on validation set\n",
      "06/02 03:28:34 PM Loss (0.168231)\n",
      "06/02 03:28:34 PM Got 28640 / 39868 correct (71.84)\n",
      "06/02 03:28:34 PM \n",
      "06/02 03:28:34 PM Epoch 8, Iteration 0, loss = 0.5361\n",
      "06/02 03:28:35 PM Epoch 8, Iteration 100, loss = 0.4257\n",
      "06/02 03:28:36 PM Epoch 8, Iteration 200, loss = 0.4833\n",
      "06/02 03:28:37 PM Checking accuracy on training set\n",
      "06/02 03:28:38 PM Loss (0.528191)\n",
      "06/02 03:28:38 PM Got 52300 / 71381 correct (73.27)\n",
      "06/02 03:28:38 PM Checking accuracy on validation set\n",
      "06/02 03:28:39 PM Loss (0.157715)\n",
      "06/02 03:28:39 PM Got 28495 / 39868 correct (71.47)\n",
      "06/02 03:28:39 PM \n",
      "06/02 03:28:39 PM Epoch 9, Iteration 0, loss = 0.5215\n",
      "06/02 03:28:40 PM Epoch 9, Iteration 100, loss = 0.4332\n",
      "06/02 03:28:41 PM Epoch 9, Iteration 200, loss = 0.4776\n",
      "06/02 03:28:41 PM Checking accuracy on training set\n",
      "06/02 03:28:43 PM Loss (0.449274)\n",
      "06/02 03:28:43 PM Got 51864 / 71381 correct (72.66)\n",
      "06/02 03:28:43 PM Checking accuracy on validation set\n",
      "06/02 03:28:43 PM Loss (0.166984)\n",
      "06/02 03:28:43 PM Got 28581 / 39868 correct (71.69)\n",
      "06/02 03:28:43 PM \n",
      "06/02 03:28:43 PM Epoch 10, Iteration 0, loss = 0.4299\n",
      "06/02 03:28:44 PM Epoch 10, Iteration 100, loss = 0.4575\n",
      "06/02 03:28:45 PM Epoch 10, Iteration 200, loss = 0.4771\n",
      "06/02 03:28:46 PM Checking accuracy on training set\n",
      "06/02 03:28:47 PM Loss (0.412799)\n",
      "06/02 03:28:47 PM Got 53150 / 71381 correct (74.46)\n",
      "06/02 03:28:47 PM Checking accuracy on validation set\n",
      "06/02 03:28:48 PM Loss (0.404916)\n",
      "06/02 03:28:48 PM Got 28945 / 39868 correct (72.60)\n",
      "06/02 03:28:48 PM \n",
      "06/02 03:28:48 PM Epoch 11, Iteration 0, loss = 0.4939\n",
      "06/02 03:28:49 PM Epoch 11, Iteration 100, loss = 0.4158\n",
      "06/02 03:28:50 PM Epoch 11, Iteration 200, loss = 0.4607\n",
      "06/02 03:28:51 PM Checking accuracy on training set\n",
      "06/02 03:28:52 PM Loss (0.412833)\n",
      "06/02 03:28:52 PM Got 53733 / 71381 correct (75.28)\n",
      "06/02 03:28:52 PM Checking accuracy on validation set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/02 03:28:53 PM Loss (0.176664)\n",
      "06/02 03:28:53 PM Got 29209 / 39868 correct (73.26)\n",
      "06/02 03:28:53 PM \n",
      "06/02 03:28:53 PM Epoch 12, Iteration 0, loss = 0.3976\n",
      "06/02 03:28:54 PM Epoch 12, Iteration 100, loss = 0.4795\n",
      "06/02 03:28:55 PM Epoch 12, Iteration 200, loss = 0.6071\n",
      "06/02 03:28:56 PM Checking accuracy on training set\n",
      "06/02 03:28:57 PM Loss (0.512306)\n",
      "06/02 03:28:57 PM Got 48061 / 71381 correct (67.33)\n",
      "06/02 03:28:57 PM Checking accuracy on validation set\n",
      "06/02 03:28:58 PM Loss (0.264283)\n",
      "06/02 03:28:58 PM Got 26856 / 39868 correct (67.36)\n",
      "06/02 03:28:58 PM \n",
      "06/02 03:28:58 PM Epoch 13, Iteration 0, loss = 0.5049\n",
      "06/02 03:28:59 PM Epoch 13, Iteration 100, loss = 0.4617\n",
      "06/02 03:29:00 PM Epoch 13, Iteration 200, loss = 0.4167\n",
      "06/02 03:29:01 PM Checking accuracy on training set\n",
      "06/02 03:29:02 PM Loss (0.484392)\n",
      "06/02 03:29:02 PM Got 53623 / 71381 correct (75.12)\n",
      "06/02 03:29:02 PM Checking accuracy on validation set\n",
      "06/02 03:29:02 PM Loss (0.192318)\n",
      "06/02 03:29:02 PM Got 29074 / 39868 correct (72.93)\n",
      "06/02 03:29:02 PM \n",
      "06/02 03:29:03 PM Epoch 14, Iteration 0, loss = 0.4127\n",
      "06/02 03:29:04 PM Epoch 14, Iteration 100, loss = 0.4512\n",
      "06/02 03:29:05 PM Epoch 14, Iteration 200, loss = 0.4159\n",
      "06/02 03:29:05 PM Checking accuracy on training set\n",
      "06/02 03:29:07 PM Loss (0.496436)\n",
      "06/02 03:29:07 PM Got 52736 / 71381 correct (73.88)\n",
      "06/02 03:29:07 PM Checking accuracy on validation set\n",
      "06/02 03:29:07 PM Loss (0.168258)\n",
      "06/02 03:29:07 PM Got 28796 / 39868 correct (72.23)\n",
      "06/02 03:29:07 PM \n",
      "06/02 03:29:07 PM Epoch 15, Iteration 0, loss = 0.4445\n",
      "06/02 03:29:08 PM Epoch 15, Iteration 100, loss = 0.4887\n",
      "06/02 03:29:09 PM Epoch 15, Iteration 200, loss = 0.4561\n",
      "06/02 03:29:10 PM Checking accuracy on training set\n",
      "06/02 03:29:11 PM Loss (0.424898)\n",
      "06/02 03:29:11 PM Got 53510 / 71381 correct (74.96)\n",
      "06/02 03:29:11 PM Checking accuracy on validation set\n",
      "06/02 03:29:12 PM Loss (0.160140)\n",
      "06/02 03:29:12 PM Got 29184 / 39868 correct (73.20)\n",
      "06/02 03:29:12 PM \n",
      "06/02 03:29:12 PM Epoch 16, Iteration 0, loss = 0.4418\n",
      "06/02 03:29:13 PM Epoch 16, Iteration 100, loss = 0.4411\n",
      "06/02 03:29:14 PM Epoch 16, Iteration 200, loss = 0.4812\n",
      "06/02 03:29:15 PM Checking accuracy on training set\n",
      "06/02 03:29:16 PM Loss (0.455771)\n",
      "06/02 03:29:16 PM Got 54982 / 71381 correct (77.03)\n",
      "06/02 03:29:16 PM Checking accuracy on validation set\n",
      "06/02 03:29:17 PM Loss (0.161565)\n",
      "06/02 03:29:17 PM Got 29487 / 39868 correct (73.96)\n",
      "06/02 03:29:17 PM \n",
      "06/02 03:29:17 PM Epoch 17, Iteration 0, loss = 0.4700\n",
      "06/02 03:29:18 PM Epoch 17, Iteration 100, loss = 0.4026\n",
      "06/02 03:29:19 PM Epoch 17, Iteration 200, loss = 0.4210\n",
      "06/02 03:29:20 PM Checking accuracy on training set\n",
      "06/02 03:29:21 PM Loss (0.420021)\n",
      "06/02 03:29:21 PM Got 54821 / 71381 correct (76.80)\n",
      "06/02 03:29:21 PM Checking accuracy on validation set\n",
      "06/02 03:29:22 PM Loss (0.174221)\n",
      "06/02 03:29:22 PM Got 29411 / 39868 correct (73.77)\n",
      "06/02 03:29:22 PM \n",
      "06/02 03:29:22 PM Epoch 18, Iteration 0, loss = 0.3972\n",
      "06/02 03:29:23 PM Epoch 18, Iteration 100, loss = 0.4707\n",
      "06/02 03:29:24 PM Epoch 18, Iteration 200, loss = 0.3506\n",
      "06/02 03:29:25 PM Checking accuracy on training set\n",
      "06/02 03:29:26 PM Loss (0.465544)\n",
      "06/02 03:29:26 PM Got 55413 / 71381 correct (77.63)\n",
      "06/02 03:29:26 PM Checking accuracy on validation set\n",
      "06/02 03:29:27 PM Loss (0.220359)\n",
      "06/02 03:29:27 PM Got 29589 / 39868 correct (74.22)\n",
      "06/02 03:29:27 PM \n",
      "06/02 03:29:27 PM Epoch 19, Iteration 0, loss = 0.4712\n",
      "06/02 03:29:28 PM Epoch 19, Iteration 100, loss = 0.4343\n",
      "06/02 03:29:29 PM Epoch 19, Iteration 200, loss = 0.4228\n",
      "06/02 03:29:29 PM Checking accuracy on training set\n",
      "06/02 03:29:31 PM Loss (0.422961)\n",
      "06/02 03:29:31 PM Got 55658 / 71381 correct (77.97)\n",
      "06/02 03:29:31 PM Checking accuracy on validation set\n",
      "06/02 03:29:31 PM Loss (0.206307)\n",
      "06/02 03:29:31 PM Got 29401 / 39868 correct (73.75)\n",
      "06/02 03:29:31 PM \n",
      "06/02 03:29:31 PM Epoch 20, Iteration 0, loss = 0.4132\n",
      "06/02 03:29:32 PM Epoch 20, Iteration 100, loss = 0.3957\n",
      "06/02 03:29:33 PM Epoch 20, Iteration 200, loss = 0.3950\n",
      "06/02 03:29:34 PM Checking accuracy on training set\n",
      "06/02 03:29:35 PM Loss (0.402358)\n",
      "06/02 03:29:35 PM Got 55749 / 71381 correct (78.10)\n",
      "06/02 03:29:35 PM Checking accuracy on validation set\n",
      "06/02 03:29:36 PM Loss (0.226878)\n",
      "06/02 03:29:36 PM Got 29550 / 39868 correct (74.12)\n",
      "06/02 03:29:36 PM \n",
      "06/02 03:29:36 PM Epoch 21, Iteration 0, loss = 0.5391\n",
      "06/02 03:29:37 PM Epoch 21, Iteration 100, loss = 0.4328\n",
      "06/02 03:29:38 PM Epoch 21, Iteration 200, loss = 0.4168\n",
      "06/02 03:29:39 PM Checking accuracy on training set\n",
      "06/02 03:29:40 PM Loss (0.413483)\n",
      "06/02 03:29:40 PM Got 54935 / 71381 correct (76.96)\n",
      "06/02 03:29:40 PM Checking accuracy on validation set\n",
      "06/02 03:29:41 PM Loss (0.168676)\n",
      "06/02 03:29:41 PM Got 29376 / 39868 correct (73.68)\n",
      "06/02 03:29:41 PM \n",
      "06/02 03:29:41 PM Epoch 22, Iteration 0, loss = 0.3820\n",
      "06/02 03:29:42 PM Epoch 22, Iteration 100, loss = 0.4270\n",
      "06/02 03:29:43 PM Epoch 22, Iteration 200, loss = 0.4297\n",
      "06/02 03:29:44 PM Checking accuracy on training set\n",
      "06/02 03:29:45 PM Loss (0.496807)\n",
      "06/02 03:29:45 PM Got 53049 / 71381 correct (74.32)\n",
      "06/02 03:29:45 PM Checking accuracy on validation set\n",
      "06/02 03:29:46 PM Loss (0.335133)\n",
      "06/02 03:29:46 PM Got 28737 / 39868 correct (72.08)\n",
      "06/02 03:29:46 PM \n",
      "06/02 03:29:46 PM Epoch 23, Iteration 0, loss = 0.4935\n",
      "06/02 03:29:47 PM Epoch 23, Iteration 100, loss = 0.4648\n",
      "06/02 03:29:48 PM Epoch 23, Iteration 200, loss = 0.4418\n",
      "06/02 03:29:49 PM Checking accuracy on training set\n",
      "06/02 03:29:50 PM Loss (0.451870)\n",
      "06/02 03:29:50 PM Got 55976 / 71381 correct (78.42)\n",
      "06/02 03:29:50 PM Checking accuracy on validation set\n",
      "06/02 03:29:51 PM Loss (0.213127)\n",
      "06/02 03:29:51 PM Got 29517 / 39868 correct (74.04)\n",
      "06/02 03:29:51 PM \n",
      "06/02 03:29:51 PM Epoch 24, Iteration 0, loss = 0.4231\n",
      "06/02 03:29:52 PM Epoch 24, Iteration 100, loss = 0.3987\n",
      "06/02 03:29:53 PM Epoch 24, Iteration 200, loss = 0.4226\n",
      "06/02 03:29:53 PM Checking accuracy on training set\n",
      "06/02 03:29:55 PM Loss (0.438207)\n",
      "06/02 03:29:55 PM Got 55365 / 71381 correct (77.56)\n",
      "06/02 03:29:55 PM Checking accuracy on validation set\n",
      "06/02 03:29:55 PM Loss (0.197887)\n",
      "06/02 03:29:55 PM Got 29257 / 39868 correct (73.38)\n",
      "06/02 03:29:55 PM \n",
      "06/02 03:29:55 PM Epoch 25, Iteration 0, loss = 0.4321\n",
      "06/02 03:29:57 PM Epoch 25, Iteration 100, loss = 0.3877\n",
      "06/02 03:29:58 PM Epoch 25, Iteration 200, loss = 0.4629\n",
      "06/02 03:29:58 PM Checking accuracy on training set\n",
      "06/02 03:30:00 PM Loss (0.405048)\n",
      "06/02 03:30:00 PM Got 55900 / 71381 correct (78.31)\n",
      "06/02 03:30:00 PM Checking accuracy on validation set\n",
      "06/02 03:30:00 PM Loss (0.191563)\n",
      "06/02 03:30:00 PM Got 29414 / 39868 correct (73.78)\n",
      "06/02 03:30:00 PM \n",
      "06/02 03:30:00 PM Epoch 26, Iteration 0, loss = 0.3976\n",
      "06/02 03:30:01 PM Epoch 26, Iteration 100, loss = 0.3616\n",
      "06/02 03:30:02 PM Epoch 26, Iteration 200, loss = 0.4040\n",
      "06/02 03:30:03 PM Checking accuracy on training set\n",
      "06/02 03:30:04 PM Loss (0.437936)\n",
      "06/02 03:30:04 PM Got 56583 / 71381 correct (79.27)\n",
      "06/02 03:30:04 PM Checking accuracy on validation set\n",
      "06/02 03:30:05 PM Loss (0.276421)\n",
      "06/02 03:30:05 PM Got 29360 / 39868 correct (73.64)\n",
      "06/02 03:30:05 PM \n",
      "06/02 03:30:05 PM Epoch 27, Iteration 0, loss = 0.4772\n",
      "06/02 03:30:06 PM Epoch 27, Iteration 100, loss = 0.3846\n",
      "06/02 03:30:07 PM Epoch 27, Iteration 200, loss = 0.4144\n",
      "06/02 03:30:08 PM Checking accuracy on training set\n",
      "06/02 03:30:09 PM Loss (0.376287)\n",
      "06/02 03:30:09 PM Got 56637 / 71381 correct (79.34)\n",
      "06/02 03:30:09 PM Checking accuracy on validation set\n",
      "06/02 03:30:10 PM Loss (0.202893)\n",
      "06/02 03:30:10 PM Got 29518 / 39868 correct (74.04)\n",
      "06/02 03:30:10 PM \n",
      "06/02 03:30:10 PM Epoch 28, Iteration 0, loss = 0.4161\n",
      "06/02 03:30:11 PM Epoch 28, Iteration 100, loss = 0.4217\n",
      "06/02 03:30:12 PM Epoch 28, Iteration 200, loss = 0.3672\n",
      "06/02 03:30:13 PM Checking accuracy on training set\n",
      "06/02 03:30:14 PM Loss (0.392827)\n",
      "06/02 03:30:14 PM Got 56922 / 71381 correct (79.74)\n",
      "06/02 03:30:14 PM Checking accuracy on validation set\n",
      "06/02 03:30:15 PM Loss (0.171917)\n",
      "06/02 03:30:15 PM Got 29402 / 39868 correct (73.75)\n",
      "06/02 03:30:15 PM \n",
      "06/02 03:30:15 PM Epoch 29, Iteration 0, loss = 0.6328\n",
      "06/02 03:30:16 PM Epoch 29, Iteration 100, loss = 0.4378\n",
      "06/02 03:30:17 PM Epoch 29, Iteration 200, loss = 0.4092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/02 03:30:18 PM Checking accuracy on training set\n",
      "06/02 03:30:19 PM Loss (0.369390)\n",
      "06/02 03:30:19 PM Got 56788 / 71381 correct (79.56)\n",
      "06/02 03:30:19 PM Checking accuracy on validation set\n",
      "06/02 03:30:20 PM Loss (0.177877)\n",
      "06/02 03:30:20 PM Got 29511 / 39868 correct (74.02)\n",
      "06/02 03:30:20 PM \n",
      "06/02 03:30:20 PM Epoch 30, Iteration 0, loss = 0.3585\n",
      "06/02 03:30:21 PM Epoch 30, Iteration 100, loss = 0.3537\n",
      "06/02 03:30:22 PM Epoch 30, Iteration 200, loss = 0.3897\n",
      "06/02 03:30:23 PM Checking accuracy on training set\n",
      "06/02 03:30:24 PM Loss (0.380613)\n",
      "06/02 03:30:24 PM Got 56781 / 71381 correct (79.55)\n",
      "06/02 03:30:24 PM Checking accuracy on validation set\n",
      "06/02 03:30:24 PM Loss (0.221987)\n",
      "06/02 03:30:24 PM Got 29467 / 39868 correct (73.91)\n",
      "06/02 03:30:24 PM \n",
      "06/02 03:30:25 PM Epoch 31, Iteration 0, loss = 0.3774\n",
      "06/02 03:30:26 PM Epoch 31, Iteration 100, loss = 0.4476\n",
      "06/02 03:30:27 PM Epoch 31, Iteration 200, loss = 0.3973\n",
      "06/02 03:30:27 PM Checking accuracy on training set\n",
      "06/02 03:30:29 PM Loss (0.366103)\n",
      "06/02 03:30:29 PM Got 57587 / 71381 correct (80.68)\n",
      "06/02 03:30:29 PM Checking accuracy on validation set\n",
      "06/02 03:30:29 PM Loss (0.278661)\n",
      "06/02 03:30:29 PM Got 29437 / 39868 correct (73.84)\n",
      "06/02 03:30:29 PM \n",
      "06/02 03:30:29 PM Epoch 32, Iteration 0, loss = 0.3574\n",
      "06/02 03:30:30 PM Epoch 32, Iteration 100, loss = 0.3541\n",
      "06/02 03:30:32 PM Epoch 32, Iteration 200, loss = 0.3798\n",
      "06/02 03:30:32 PM Checking accuracy on training set\n",
      "06/02 03:30:34 PM Loss (0.403736)\n",
      "06/02 03:30:34 PM Got 56233 / 71381 correct (78.78)\n",
      "06/02 03:30:34 PM Checking accuracy on validation set\n",
      "06/02 03:30:34 PM Loss (0.188632)\n",
      "06/02 03:30:34 PM Got 29322 / 39868 correct (73.55)\n",
      "06/02 03:30:34 PM \n",
      "06/02 03:30:34 PM Epoch 33, Iteration 0, loss = 0.4012\n",
      "06/02 03:30:35 PM Epoch 33, Iteration 100, loss = 0.3270\n",
      "06/02 03:30:36 PM Epoch 33, Iteration 200, loss = 0.5238\n",
      "06/02 03:30:37 PM Checking accuracy on training set\n",
      "06/02 03:30:38 PM Loss (0.452182)\n",
      "06/02 03:30:38 PM Got 53927 / 71381 correct (75.55)\n",
      "06/02 03:30:38 PM Checking accuracy on validation set\n",
      "06/02 03:30:39 PM Loss (0.235132)\n",
      "06/02 03:30:39 PM Got 29043 / 39868 correct (72.85)\n",
      "06/02 03:30:39 PM \n",
      "06/02 03:30:39 PM Epoch 34, Iteration 0, loss = 0.4982\n",
      "06/02 03:30:40 PM Epoch 34, Iteration 100, loss = 0.4257\n",
      "06/02 03:30:41 PM Epoch 34, Iteration 200, loss = 0.4970\n",
      "06/02 03:30:42 PM Checking accuracy on training set\n",
      "06/02 03:30:43 PM Loss (0.432393)\n",
      "06/02 03:30:43 PM Got 55738 / 71381 correct (78.09)\n",
      "06/02 03:30:43 PM Checking accuracy on validation set\n",
      "06/02 03:30:44 PM Loss (0.140852)\n",
      "06/02 03:30:44 PM Got 29188 / 39868 correct (73.21)\n",
      "06/02 03:30:44 PM \n",
      "06/02 03:30:44 PM Epoch 35, Iteration 0, loss = 0.4854\n",
      "06/02 03:30:45 PM Epoch 35, Iteration 100, loss = 0.3506\n",
      "06/02 03:30:46 PM Epoch 35, Iteration 200, loss = 0.4177\n",
      "06/02 03:30:47 PM Checking accuracy on training set\n",
      "06/02 03:30:48 PM Loss (0.341159)\n",
      "06/02 03:30:48 PM Got 57338 / 71381 correct (80.33)\n",
      "06/02 03:30:48 PM Checking accuracy on validation set\n",
      "06/02 03:30:49 PM Loss (0.148873)\n",
      "06/02 03:30:49 PM Got 29521 / 39868 correct (74.05)\n",
      "06/02 03:30:49 PM \n",
      "06/02 03:30:49 PM Epoch 36, Iteration 0, loss = 0.3509\n",
      "06/02 03:30:50 PM Epoch 36, Iteration 100, loss = 0.3746\n",
      "06/02 03:30:51 PM Epoch 36, Iteration 200, loss = 0.3623\n",
      "06/02 03:30:52 PM Checking accuracy on training set\n",
      "06/02 03:30:53 PM Loss (0.388225)\n",
      "06/02 03:30:53 PM Got 57707 / 71381 correct (80.84)\n",
      "06/02 03:30:53 PM Checking accuracy on validation set\n",
      "06/02 03:30:54 PM Loss (0.164766)\n",
      "06/02 03:30:54 PM Got 29605 / 39868 correct (74.26)\n",
      "06/02 03:30:54 PM \n",
      "06/02 03:30:54 PM Epoch 37, Iteration 0, loss = 0.3486\n",
      "06/02 03:30:55 PM Epoch 37, Iteration 100, loss = 0.3859\n",
      "06/02 03:30:56 PM Epoch 37, Iteration 200, loss = 0.4066\n",
      "06/02 03:30:56 PM Checking accuracy on training set\n",
      "06/02 03:30:58 PM Loss (0.355117)\n",
      "06/02 03:30:58 PM Got 57730 / 71381 correct (80.88)\n",
      "06/02 03:30:58 PM Checking accuracy on validation set\n",
      "06/02 03:30:58 PM Loss (0.231682)\n",
      "06/02 03:30:58 PM Got 29521 / 39868 correct (74.05)\n",
      "06/02 03:30:58 PM \n",
      "06/02 03:30:58 PM Epoch 38, Iteration 0, loss = 0.3625\n",
      "06/02 03:30:59 PM Epoch 38, Iteration 100, loss = 0.3613\n",
      "06/02 03:31:01 PM Epoch 38, Iteration 200, loss = 0.3361\n",
      "06/02 03:31:01 PM Checking accuracy on training set\n",
      "06/02 03:31:03 PM Loss (0.382055)\n",
      "06/02 03:31:03 PM Got 58235 / 71381 correct (81.58)\n",
      "06/02 03:31:03 PM Checking accuracy on validation set\n",
      "06/02 03:31:03 PM Loss (0.157750)\n",
      "06/02 03:31:03 PM Got 29583 / 39868 correct (74.20)\n",
      "06/02 03:31:03 PM \n",
      "06/02 03:31:03 PM Epoch 39, Iteration 0, loss = 0.3338\n",
      "06/02 03:31:04 PM Epoch 39, Iteration 100, loss = 0.3289\n",
      "06/02 03:31:05 PM Epoch 39, Iteration 200, loss = 0.4929\n",
      "06/02 03:31:06 PM Checking accuracy on training set\n",
      "06/02 03:31:07 PM Loss (0.449649)\n",
      "06/02 03:31:07 PM Got 55229 / 71381 correct (77.37)\n",
      "06/02 03:31:07 PM Checking accuracy on validation set\n",
      "06/02 03:31:08 PM Loss (0.240363)\n",
      "06/02 03:31:08 PM Got 28935 / 39868 correct (72.58)\n",
      "06/02 03:31:08 PM \n",
      "06/02 03:31:08 PM Epoch 0, Iteration 0, loss = 19.9520\n",
      "06/02 03:31:09 PM Epoch 0, Iteration 100, loss = 0.6062\n",
      "06/02 03:31:10 PM Epoch 0, Iteration 200, loss = 0.5814\n",
      "06/02 03:31:11 PM Checking accuracy on training set\n",
      "06/02 03:31:12 PM Loss (0.601214)\n",
      "06/02 03:31:12 PM Got 43598 / 71381 correct (61.08)\n",
      "06/02 03:31:12 PM Checking accuracy on validation set\n",
      "06/02 03:31:13 PM Loss (0.348008)\n",
      "06/02 03:31:13 PM Got 24970 / 39868 correct (62.63)\n",
      "06/02 03:31:13 PM \n",
      "06/02 03:31:13 PM Epoch 1, Iteration 0, loss = 0.5723\n",
      "06/02 03:31:14 PM Epoch 1, Iteration 100, loss = 0.6025\n",
      "06/02 03:31:15 PM Epoch 1, Iteration 200, loss = 0.6059\n",
      "06/02 03:31:16 PM Checking accuracy on training set\n",
      "06/02 03:31:17 PM Loss (0.532930)\n",
      "06/02 03:31:17 PM Got 43976 / 71381 correct (61.61)\n",
      "06/02 03:31:17 PM Checking accuracy on validation set\n",
      "06/02 03:31:18 PM Loss (0.282731)\n",
      "06/02 03:31:18 PM Got 25133 / 39868 correct (63.04)\n",
      "06/02 03:31:18 PM \n",
      "06/02 03:31:18 PM Epoch 2, Iteration 0, loss = 0.5493\n",
      "06/02 03:31:19 PM Epoch 2, Iteration 100, loss = 0.5552\n",
      "06/02 03:31:20 PM Epoch 2, Iteration 200, loss = 0.5706\n",
      "06/02 03:31:21 PM Checking accuracy on training set\n",
      "06/02 03:31:22 PM Loss (0.547789)\n",
      "06/02 03:31:22 PM Got 46870 / 71381 correct (65.66)\n",
      "06/02 03:31:22 PM Checking accuracy on validation set\n",
      "06/02 03:31:22 PM Loss (0.235306)\n",
      "06/02 03:31:22 PM Got 26453 / 39868 correct (66.35)\n",
      "06/02 03:31:22 PM \n",
      "06/02 03:31:22 PM Epoch 3, Iteration 0, loss = 0.5655\n",
      "06/02 03:31:23 PM Epoch 3, Iteration 100, loss = 0.5077\n",
      "06/02 03:31:24 PM Epoch 3, Iteration 200, loss = 0.5269\n",
      "06/02 03:31:25 PM Checking accuracy on training set\n",
      "06/02 03:31:26 PM Loss (0.509136)\n",
      "06/02 03:31:26 PM Got 48384 / 71381 correct (67.78)\n",
      "06/02 03:31:26 PM Checking accuracy on validation set\n",
      "06/02 03:31:27 PM Loss (0.170949)\n",
      "06/02 03:31:27 PM Got 27040 / 39868 correct (67.82)\n",
      "06/02 03:31:27 PM \n",
      "06/02 03:31:27 PM Epoch 4, Iteration 0, loss = 0.5178\n",
      "06/02 03:31:28 PM Epoch 4, Iteration 100, loss = 0.4739\n",
      "06/02 03:31:29 PM Epoch 4, Iteration 200, loss = 0.5806\n",
      "06/02 03:31:30 PM Checking accuracy on training set\n",
      "06/02 03:31:31 PM Loss (0.599288)\n",
      "06/02 03:31:31 PM Got 49744 / 71381 correct (69.69)\n",
      "06/02 03:31:31 PM Checking accuracy on validation set\n",
      "06/02 03:31:32 PM Loss (0.192161)\n",
      "06/02 03:31:32 PM Got 27648 / 39868 correct (69.35)\n",
      "06/02 03:31:32 PM \n",
      "06/02 03:31:32 PM Epoch 5, Iteration 0, loss = 0.4248\n",
      "06/02 03:31:33 PM Epoch 5, Iteration 100, loss = 0.5400\n",
      "06/02 03:31:34 PM Epoch 5, Iteration 200, loss = 0.4958\n",
      "06/02 03:31:35 PM Checking accuracy on training set\n",
      "06/02 03:31:36 PM Loss (0.508351)\n",
      "06/02 03:31:36 PM Got 51094 / 71381 correct (71.58)\n",
      "06/02 03:31:36 PM Checking accuracy on validation set\n",
      "06/02 03:31:37 PM Loss (0.194542)\n",
      "06/02 03:31:37 PM Got 27956 / 39868 correct (70.12)\n",
      "06/02 03:31:37 PM \n",
      "06/02 03:31:37 PM Epoch 6, Iteration 0, loss = 0.5078\n",
      "06/02 03:31:38 PM Epoch 6, Iteration 100, loss = 0.5450\n",
      "06/02 03:31:39 PM Epoch 6, Iteration 200, loss = 0.4965\n",
      "06/02 03:31:39 PM Checking accuracy on training set\n",
      "06/02 03:31:41 PM Loss (0.475895)\n",
      "06/02 03:31:41 PM Got 49633 / 71381 correct (69.53)\n",
      "06/02 03:31:41 PM Checking accuracy on validation set\n",
      "06/02 03:31:41 PM Loss (0.201976)\n",
      "06/02 03:31:41 PM Got 27365 / 39868 correct (68.64)\n",
      "06/02 03:31:41 PM \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/02 03:31:41 PM Epoch 7, Iteration 0, loss = 0.4556\n",
      "06/02 03:31:42 PM Epoch 7, Iteration 100, loss = 0.4615\n",
      "06/02 03:31:43 PM Epoch 7, Iteration 200, loss = 0.5288\n",
      "06/02 03:31:44 PM Checking accuracy on training set\n",
      "06/02 03:31:46 PM Loss (0.500590)\n",
      "06/02 03:31:46 PM Got 50816 / 71381 correct (71.19)\n",
      "06/02 03:31:46 PM Checking accuracy on validation set\n",
      "06/02 03:31:46 PM Loss (0.219642)\n",
      "06/02 03:31:46 PM Got 27730 / 39868 correct (69.55)\n",
      "06/02 03:31:46 PM \n",
      "06/02 03:31:46 PM Epoch 8, Iteration 0, loss = 0.4546\n",
      "06/02 03:31:47 PM Epoch 8, Iteration 100, loss = 0.5182\n",
      "06/02 03:31:48 PM Epoch 8, Iteration 200, loss = 0.5019\n",
      "06/02 03:31:49 PM Checking accuracy on training set\n",
      "06/02 03:31:50 PM Loss (0.465254)\n",
      "06/02 03:31:50 PM Got 51511 / 71381 correct (72.16)\n",
      "06/02 03:31:50 PM Checking accuracy on validation set\n",
      "06/02 03:31:51 PM Loss (0.159883)\n",
      "06/02 03:31:51 PM Got 27988 / 39868 correct (70.20)\n",
      "06/02 03:31:51 PM \n",
      "06/02 03:31:51 PM Epoch 9, Iteration 0, loss = 0.4862\n",
      "06/02 03:31:52 PM Epoch 9, Iteration 100, loss = 0.4330\n",
      "06/02 03:31:53 PM Epoch 9, Iteration 200, loss = 0.4645\n",
      "06/02 03:31:54 PM Checking accuracy on training set\n",
      "06/02 03:31:55 PM Loss (0.478787)\n",
      "06/02 03:31:55 PM Got 51833 / 71381 correct (72.61)\n",
      "06/02 03:31:55 PM Checking accuracy on validation set\n",
      "06/02 03:31:56 PM Loss (0.272489)\n",
      "06/02 03:31:56 PM Got 28138 / 39868 correct (70.58)\n",
      "06/02 03:31:56 PM \n",
      "06/02 03:31:56 PM Epoch 10, Iteration 0, loss = 0.4659\n",
      "06/02 03:31:57 PM Epoch 10, Iteration 100, loss = 0.4379\n",
      "06/02 03:31:58 PM Epoch 10, Iteration 200, loss = 0.4660\n",
      "06/02 03:31:59 PM Checking accuracy on training set\n",
      "06/02 03:32:00 PM Loss (0.529597)\n",
      "06/02 03:32:00 PM Got 50301 / 71381 correct (70.47)\n",
      "06/02 03:32:00 PM Checking accuracy on validation set\n",
      "06/02 03:32:01 PM Loss (0.240023)\n",
      "06/02 03:32:01 PM Got 27756 / 39868 correct (69.62)\n",
      "06/02 03:32:01 PM \n",
      "06/02 03:32:01 PM Epoch 11, Iteration 0, loss = 0.5122\n",
      "06/02 03:32:02 PM Epoch 11, Iteration 100, loss = 0.5261\n",
      "06/02 03:32:03 PM Epoch 11, Iteration 200, loss = 0.4698\n",
      "06/02 03:32:03 PM Checking accuracy on training set\n",
      "06/02 03:32:05 PM Loss (0.481131)\n",
      "06/02 03:32:05 PM Got 53498 / 71381 correct (74.95)\n",
      "06/02 03:32:05 PM Checking accuracy on validation set\n",
      "06/02 03:32:05 PM Loss (0.224448)\n",
      "06/02 03:32:05 PM Got 28961 / 39868 correct (72.64)\n",
      "06/02 03:32:05 PM \n",
      "06/02 03:32:05 PM Epoch 12, Iteration 0, loss = 0.4741\n",
      "06/02 03:32:06 PM Epoch 12, Iteration 100, loss = 0.4087\n",
      "06/02 03:32:07 PM Epoch 12, Iteration 200, loss = 0.4757\n",
      "06/02 03:32:08 PM Checking accuracy on training set\n",
      "06/02 03:32:09 PM Loss (0.474831)\n",
      "06/02 03:32:09 PM Got 52559 / 71381 correct (73.63)\n",
      "06/02 03:32:09 PM Checking accuracy on validation set\n",
      "06/02 03:32:10 PM Loss (0.186079)\n",
      "06/02 03:32:10 PM Got 28474 / 39868 correct (71.42)\n",
      "06/02 03:32:10 PM \n",
      "06/02 03:32:10 PM Epoch 13, Iteration 0, loss = 0.4525\n",
      "06/02 03:32:11 PM Epoch 13, Iteration 100, loss = 0.5515\n",
      "06/02 03:32:12 PM Epoch 13, Iteration 200, loss = 0.5086\n",
      "06/02 03:32:13 PM Checking accuracy on training set\n",
      "06/02 03:32:14 PM Loss (0.483924)\n",
      "06/02 03:32:14 PM Got 51763 / 71381 correct (72.52)\n",
      "06/02 03:32:14 PM Checking accuracy on validation set\n",
      "06/02 03:32:15 PM Loss (0.229044)\n",
      "06/02 03:32:15 PM Got 28188 / 39868 correct (70.70)\n",
      "06/02 03:32:15 PM \n",
      "06/02 03:32:15 PM Epoch 14, Iteration 0, loss = 0.4908\n",
      "06/02 03:32:16 PM Epoch 14, Iteration 100, loss = 0.4809\n",
      "06/02 03:32:17 PM Epoch 14, Iteration 200, loss = 0.4190\n",
      "06/02 03:32:18 PM Checking accuracy on training set\n",
      "06/02 03:32:19 PM Loss (0.462332)\n",
      "06/02 03:32:19 PM Got 52524 / 71381 correct (73.58)\n",
      "06/02 03:32:19 PM Checking accuracy on validation set\n",
      "06/02 03:32:20 PM Loss (0.170230)\n",
      "06/02 03:32:20 PM Got 28424 / 39868 correct (71.30)\n",
      "06/02 03:32:20 PM \n",
      "06/02 03:32:20 PM Epoch 15, Iteration 0, loss = 0.4076\n",
      "06/02 03:32:21 PM Epoch 15, Iteration 100, loss = 0.4645\n",
      "06/02 03:32:22 PM Epoch 15, Iteration 200, loss = 0.4579\n",
      "06/02 03:32:23 PM Checking accuracy on training set\n",
      "06/02 03:32:24 PM Loss (0.404654)\n",
      "06/02 03:32:24 PM Got 54943 / 71381 correct (76.97)\n",
      "06/02 03:32:24 PM Checking accuracy on validation set\n",
      "06/02 03:32:25 PM Loss (0.190774)\n",
      "06/02 03:32:25 PM Got 29182 / 39868 correct (73.20)\n",
      "06/02 03:32:25 PM \n",
      "06/02 03:32:25 PM Epoch 16, Iteration 0, loss = 0.4599\n",
      "06/02 03:32:26 PM Epoch 16, Iteration 100, loss = 0.4290\n",
      "06/02 03:32:27 PM Epoch 16, Iteration 200, loss = 0.3813\n",
      "06/02 03:32:27 PM Checking accuracy on training set\n",
      "06/02 03:32:29 PM Loss (0.391499)\n",
      "06/02 03:32:29 PM Got 55325 / 71381 correct (77.51)\n",
      "06/02 03:32:29 PM Checking accuracy on validation set\n",
      "06/02 03:32:29 PM Loss (0.205925)\n",
      "06/02 03:32:29 PM Got 29392 / 39868 correct (73.72)\n",
      "06/02 03:32:29 PM \n",
      "06/02 03:32:29 PM Epoch 17, Iteration 0, loss = 0.4987\n",
      "06/02 03:32:30 PM Epoch 17, Iteration 100, loss = 0.4935\n",
      "06/02 03:32:31 PM Epoch 17, Iteration 200, loss = 0.4296\n",
      "06/02 03:32:32 PM Checking accuracy on training set\n",
      "06/02 03:32:34 PM Loss (0.384961)\n",
      "06/02 03:32:34 PM Got 55445 / 71381 correct (77.67)\n",
      "06/02 03:32:34 PM Checking accuracy on validation set\n",
      "06/02 03:32:34 PM Loss (0.174325)\n",
      "06/02 03:32:34 PM Got 29415 / 39868 correct (73.78)\n",
      "06/02 03:32:34 PM \n",
      "06/02 03:32:34 PM Epoch 18, Iteration 0, loss = 0.4454\n",
      "06/02 03:32:35 PM Epoch 18, Iteration 100, loss = 0.4898\n",
      "06/02 03:32:36 PM Epoch 18, Iteration 200, loss = 0.4199\n",
      "06/02 03:32:37 PM Checking accuracy on training set\n",
      "06/02 03:32:38 PM Loss (0.414075)\n",
      "06/02 03:32:38 PM Got 55665 / 71381 correct (77.98)\n",
      "06/02 03:32:38 PM Checking accuracy on validation set\n",
      "06/02 03:32:39 PM Loss (0.178658)\n",
      "06/02 03:32:39 PM Got 29317 / 39868 correct (73.54)\n",
      "06/02 03:32:39 PM \n",
      "06/02 03:32:39 PM Epoch 19, Iteration 0, loss = 0.4646\n",
      "06/02 03:32:40 PM Epoch 19, Iteration 100, loss = 0.3887\n",
      "06/02 03:32:41 PM Epoch 19, Iteration 200, loss = 0.4339\n",
      "06/02 03:32:42 PM Checking accuracy on training set\n",
      "06/02 03:32:43 PM Loss (0.376080)\n",
      "06/02 03:32:43 PM Got 56161 / 71381 correct (78.68)\n",
      "06/02 03:32:43 PM Checking accuracy on validation set\n",
      "06/02 03:32:44 PM Loss (0.197013)\n",
      "06/02 03:32:44 PM Got 29512 / 39868 correct (74.02)\n",
      "06/02 03:32:44 PM \n",
      "06/02 03:32:44 PM Epoch 20, Iteration 0, loss = 0.3927\n",
      "06/02 03:32:45 PM Epoch 20, Iteration 100, loss = 0.3826\n",
      "06/02 03:32:46 PM Epoch 20, Iteration 200, loss = 0.4327\n",
      "06/02 03:32:47 PM Checking accuracy on training set\n",
      "06/02 03:32:48 PM Loss (0.413474)\n",
      "06/02 03:32:48 PM Got 55603 / 71381 correct (77.90)\n",
      "06/02 03:32:48 PM Checking accuracy on validation set\n",
      "06/02 03:32:49 PM Loss (0.178984)\n",
      "06/02 03:32:49 PM Got 29379 / 39868 correct (73.69)\n",
      "06/02 03:32:49 PM \n",
      "06/02 03:32:49 PM Epoch 21, Iteration 0, loss = 0.4216\n",
      "06/02 03:32:50 PM Epoch 21, Iteration 100, loss = 0.4162\n",
      "06/02 03:32:51 PM Epoch 21, Iteration 200, loss = 0.4228\n",
      "06/02 03:32:52 PM Checking accuracy on training set\n",
      "06/02 03:32:53 PM Loss (0.448876)\n",
      "06/02 03:32:53 PM Got 56465 / 71381 correct (79.10)\n",
      "06/02 03:32:53 PM Checking accuracy on validation set\n",
      "06/02 03:32:53 PM Loss (0.337648)\n",
      "06/02 03:32:53 PM Got 29338 / 39868 correct (73.59)\n",
      "06/02 03:32:53 PM \n",
      "06/02 03:32:54 PM Epoch 22, Iteration 0, loss = 0.4351\n",
      "06/02 03:32:55 PM Epoch 22, Iteration 100, loss = 0.4116\n",
      "06/02 03:32:56 PM Epoch 22, Iteration 200, loss = 0.4282\n",
      "06/02 03:32:56 PM Checking accuracy on training set\n",
      "06/02 03:32:58 PM Loss (0.379085)\n",
      "06/02 03:32:58 PM Got 56904 / 71381 correct (79.72)\n",
      "06/02 03:32:58 PM Checking accuracy on validation set\n",
      "06/02 03:32:58 PM Loss (0.258798)\n",
      "06/02 03:32:58 PM Got 29545 / 39868 correct (74.11)\n",
      "06/02 03:32:58 PM \n",
      "06/02 03:32:58 PM Epoch 23, Iteration 0, loss = 0.4501\n",
      "06/02 03:32:59 PM Epoch 23, Iteration 100, loss = 0.3884\n",
      "06/02 03:33:00 PM Epoch 23, Iteration 200, loss = 0.4179\n",
      "06/02 03:33:01 PM Checking accuracy on training set\n",
      "06/02 03:33:02 PM Loss (0.386036)\n",
      "06/02 03:33:02 PM Got 56836 / 71381 correct (79.62)\n",
      "06/02 03:33:02 PM Checking accuracy on validation set\n",
      "06/02 03:33:03 PM Loss (0.205637)\n",
      "06/02 03:33:03 PM Got 29424 / 39868 correct (73.80)\n",
      "06/02 03:33:03 PM \n",
      "06/02 03:33:03 PM Epoch 24, Iteration 0, loss = 0.3877\n",
      "06/02 03:33:04 PM Epoch 24, Iteration 100, loss = 0.3600\n",
      "06/02 03:33:05 PM Epoch 24, Iteration 200, loss = 0.4197\n",
      "06/02 03:33:06 PM Checking accuracy on training set\n",
      "06/02 03:33:07 PM Loss (0.385231)\n",
      "06/02 03:33:07 PM Got 57582 / 71381 correct (80.67)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/02 03:33:07 PM Checking accuracy on validation set\n",
      "06/02 03:33:08 PM Loss (0.194527)\n",
      "06/02 03:33:08 PM Got 29474 / 39868 correct (73.93)\n",
      "06/02 03:33:08 PM \n",
      "06/02 03:33:08 PM Epoch 25, Iteration 0, loss = 0.3649\n",
      "06/02 03:33:09 PM Epoch 25, Iteration 100, loss = 0.4008\n",
      "06/02 03:33:10 PM Epoch 25, Iteration 200, loss = 0.3819\n",
      "06/02 03:33:11 PM Checking accuracy on training set\n",
      "06/02 03:33:12 PM Loss (0.377903)\n",
      "06/02 03:33:12 PM Got 58107 / 71381 correct (81.40)\n",
      "06/02 03:33:12 PM Checking accuracy on validation set\n",
      "06/02 03:33:13 PM Loss (0.178939)\n",
      "06/02 03:33:13 PM Got 29268 / 39868 correct (73.41)\n",
      "06/02 03:33:13 PM \n",
      "06/02 03:33:13 PM Epoch 26, Iteration 0, loss = 0.3731\n",
      "06/02 03:33:14 PM Epoch 26, Iteration 100, loss = 0.3853\n",
      "06/02 03:33:15 PM Epoch 26, Iteration 200, loss = 0.3855\n",
      "06/02 03:33:16 PM Checking accuracy on training set\n",
      "06/02 03:33:17 PM Loss (0.379135)\n",
      "06/02 03:33:17 PM Got 57298 / 71381 correct (80.27)\n",
      "06/02 03:33:17 PM Checking accuracy on validation set\n",
      "06/02 03:33:17 PM Loss (0.139499)\n",
      "06/02 03:33:17 PM Got 29372 / 39868 correct (73.67)\n",
      "06/02 03:33:17 PM \n",
      "06/02 03:33:18 PM Epoch 27, Iteration 0, loss = 0.3980\n",
      "06/02 03:33:19 PM Epoch 27, Iteration 100, loss = 0.3785\n",
      "06/02 03:33:20 PM Epoch 27, Iteration 200, loss = 0.5027\n",
      "06/02 03:33:20 PM Checking accuracy on training set\n",
      "06/02 03:33:22 PM Loss (0.403976)\n",
      "06/02 03:33:22 PM Got 58651 / 71381 correct (82.17)\n",
      "06/02 03:33:22 PM Checking accuracy on validation set\n",
      "06/02 03:33:22 PM Loss (0.180590)\n",
      "06/02 03:33:22 PM Got 29536 / 39868 correct (74.08)\n",
      "06/02 03:33:22 PM \n",
      "06/02 03:33:22 PM Epoch 28, Iteration 0, loss = 0.3303\n",
      "06/02 03:33:23 PM Epoch 28, Iteration 100, loss = 0.3395\n",
      "06/02 03:33:24 PM Epoch 28, Iteration 200, loss = 0.4280\n",
      "06/02 03:33:25 PM Checking accuracy on training set\n",
      "06/02 03:33:26 PM Loss (0.435361)\n",
      "06/02 03:33:26 PM Got 52145 / 71381 correct (73.05)\n",
      "06/02 03:33:26 PM Checking accuracy on validation set\n",
      "06/02 03:33:27 PM Loss (0.193165)\n",
      "06/02 03:33:27 PM Got 28155 / 39868 correct (70.62)\n",
      "06/02 03:33:27 PM \n",
      "06/02 03:33:27 PM Epoch 29, Iteration 0, loss = 0.4573\n",
      "06/02 03:33:28 PM Epoch 29, Iteration 100, loss = 0.4231\n",
      "06/02 03:33:29 PM Epoch 29, Iteration 200, loss = 0.4057\n",
      "06/02 03:33:30 PM Checking accuracy on training set\n",
      "06/02 03:33:31 PM Loss (0.358928)\n",
      "06/02 03:33:31 PM Got 56882 / 71381 correct (79.69)\n",
      "06/02 03:33:31 PM Checking accuracy on validation set\n",
      "06/02 03:33:32 PM Loss (0.184426)\n",
      "06/02 03:33:32 PM Got 29419 / 39868 correct (73.79)\n",
      "06/02 03:33:32 PM \n",
      "06/02 03:33:32 PM Epoch 30, Iteration 0, loss = 0.4141\n",
      "06/02 03:33:33 PM Epoch 30, Iteration 100, loss = 0.4379\n",
      "06/02 03:33:34 PM Epoch 30, Iteration 200, loss = 0.4701\n",
      "06/02 03:33:35 PM Checking accuracy on training set\n",
      "06/02 03:33:36 PM Loss (0.372112)\n",
      "06/02 03:33:36 PM Got 57545 / 71381 correct (80.62)\n",
      "06/02 03:33:36 PM Checking accuracy on validation set\n",
      "06/02 03:33:37 PM Loss (0.191634)\n",
      "06/02 03:33:37 PM Got 29408 / 39868 correct (73.76)\n",
      "06/02 03:33:37 PM \n",
      "06/02 03:33:37 PM Epoch 31, Iteration 0, loss = 0.3713\n",
      "06/02 03:33:38 PM Epoch 31, Iteration 100, loss = 0.4024\n",
      "06/02 03:33:39 PM Epoch 31, Iteration 200, loss = 0.4152\n",
      "06/02 03:33:39 PM Checking accuracy on training set\n",
      "06/02 03:33:41 PM Loss (0.382009)\n",
      "06/02 03:33:41 PM Got 56716 / 71381 correct (79.46)\n",
      "06/02 03:33:41 PM Checking accuracy on validation set\n",
      "06/02 03:33:41 PM Loss (0.173332)\n",
      "06/02 03:33:41 PM Got 29407 / 39868 correct (73.76)\n",
      "06/02 03:33:41 PM \n",
      "06/02 03:33:41 PM Epoch 32, Iteration 0, loss = 0.4014\n",
      "06/02 03:33:42 PM Epoch 32, Iteration 100, loss = 0.4048\n",
      "06/02 03:33:43 PM Epoch 32, Iteration 200, loss = 0.4089\n",
      "06/02 03:33:44 PM Checking accuracy on training set\n",
      "06/02 03:33:45 PM Loss (0.371769)\n",
      "06/02 03:33:45 PM Got 57968 / 71381 correct (81.21)\n",
      "06/02 03:33:45 PM Checking accuracy on validation set\n",
      "06/02 03:33:46 PM Loss (0.180977)\n",
      "06/02 03:33:46 PM Got 29442 / 39868 correct (73.85)\n",
      "06/02 03:33:46 PM \n",
      "06/02 03:33:46 PM Epoch 33, Iteration 0, loss = 0.3776\n",
      "06/02 03:33:47 PM Epoch 33, Iteration 100, loss = 0.4448\n",
      "06/02 03:33:48 PM Epoch 33, Iteration 200, loss = 0.3447\n",
      "06/02 03:33:49 PM Checking accuracy on training set\n",
      "06/02 03:33:50 PM Loss (0.392861)\n",
      "06/02 03:33:50 PM Got 58806 / 71381 correct (82.38)\n",
      "06/02 03:33:50 PM Checking accuracy on validation set\n",
      "06/02 03:33:51 PM Loss (0.191319)\n",
      "06/02 03:33:51 PM Got 29360 / 39868 correct (73.64)\n",
      "06/02 03:33:51 PM \n",
      "06/02 03:33:51 PM Epoch 34, Iteration 0, loss = 0.3436\n",
      "06/02 03:33:52 PM Epoch 34, Iteration 100, loss = 0.3185\n",
      "06/02 03:33:53 PM Epoch 34, Iteration 200, loss = 0.3316\n",
      "06/02 03:33:54 PM Checking accuracy on training set\n",
      "06/02 03:33:55 PM Loss (0.325537)\n",
      "06/02 03:33:55 PM Got 57007 / 71381 correct (79.86)\n",
      "06/02 03:33:55 PM Checking accuracy on validation set\n",
      "06/02 03:33:56 PM Loss (0.134485)\n",
      "06/02 03:33:56 PM Got 28948 / 39868 correct (72.61)\n",
      "06/02 03:33:56 PM \n",
      "06/02 03:33:56 PM Epoch 35, Iteration 0, loss = 0.3492\n",
      "06/02 03:33:57 PM Epoch 35, Iteration 100, loss = 0.3684\n",
      "06/02 03:33:58 PM Epoch 35, Iteration 200, loss = 0.3276\n",
      "06/02 03:33:59 PM Checking accuracy on training set\n",
      "06/02 03:34:00 PM Loss (0.336169)\n",
      "06/02 03:34:00 PM Got 59089 / 71381 correct (82.78)\n",
      "06/02 03:34:00 PM Checking accuracy on validation set\n",
      "06/02 03:34:00 PM Loss (0.176076)\n",
      "06/02 03:34:00 PM Got 29468 / 39868 correct (73.91)\n",
      "06/02 03:34:00 PM \n",
      "06/02 03:34:00 PM Epoch 36, Iteration 0, loss = 0.3397\n",
      "06/02 03:34:02 PM Epoch 36, Iteration 100, loss = 0.3376\n",
      "06/02 03:34:03 PM Epoch 36, Iteration 200, loss = 0.3520\n",
      "06/02 03:34:03 PM Checking accuracy on training set\n",
      "06/02 03:34:05 PM Loss (0.317724)\n",
      "06/02 03:34:05 PM Got 61082 / 71381 correct (85.57)\n",
      "06/02 03:34:05 PM Checking accuracy on validation set\n",
      "06/02 03:34:05 PM Loss (0.178034)\n",
      "06/02 03:34:05 PM Got 29417 / 39868 correct (73.79)\n",
      "06/02 03:34:05 PM \n",
      "06/02 03:34:05 PM Epoch 37, Iteration 0, loss = 0.4132\n",
      "06/02 03:34:06 PM Epoch 37, Iteration 100, loss = 0.4045\n",
      "06/02 03:34:07 PM Epoch 37, Iteration 200, loss = 0.5232\n",
      "06/02 03:34:08 PM Checking accuracy on training set\n",
      "06/02 03:34:09 PM Loss (0.431061)\n",
      "06/02 03:34:09 PM Got 53643 / 71381 correct (75.15)\n",
      "06/02 03:34:09 PM Checking accuracy on validation set\n",
      "06/02 03:34:10 PM Loss (0.181623)\n",
      "06/02 03:34:10 PM Got 28466 / 39868 correct (71.40)\n",
      "06/02 03:34:10 PM \n",
      "06/02 03:34:10 PM Epoch 38, Iteration 0, loss = 0.4232\n",
      "06/02 03:34:11 PM Epoch 38, Iteration 100, loss = 0.4190\n",
      "06/02 03:34:12 PM Epoch 38, Iteration 200, loss = 0.4043\n",
      "06/02 03:34:13 PM Checking accuracy on training set\n",
      "06/02 03:34:14 PM Loss (0.450739)\n",
      "06/02 03:34:14 PM Got 55939 / 71381 correct (78.37)\n",
      "06/02 03:34:14 PM Checking accuracy on validation set\n",
      "06/02 03:34:15 PM Loss (0.223088)\n",
      "06/02 03:34:15 PM Got 28953 / 39868 correct (72.62)\n",
      "06/02 03:34:15 PM \n",
      "06/02 03:34:15 PM Epoch 39, Iteration 0, loss = 0.4650\n",
      "06/02 03:34:16 PM Epoch 39, Iteration 100, loss = 0.4360\n",
      "06/02 03:34:17 PM Epoch 39, Iteration 200, loss = 0.4292\n",
      "06/02 03:34:18 PM Checking accuracy on training set\n",
      "06/02 03:34:19 PM Loss (0.409727)\n",
      "06/02 03:34:19 PM Got 57247 / 71381 correct (80.20)\n",
      "06/02 03:34:19 PM Checking accuracy on validation set\n",
      "06/02 03:34:20 PM Loss (0.200930)\n",
      "06/02 03:34:20 PM Got 28965 / 39868 correct (72.65)\n",
      "06/02 03:34:20 PM \n",
      "06/02 03:34:20 PM Epoch 0, Iteration 0, loss = 2.2170\n",
      "06/02 03:34:21 PM Epoch 0, Iteration 100, loss = 0.6967\n",
      "06/02 03:34:22 PM Epoch 0, Iteration 200, loss = 0.6277\n",
      "06/02 03:34:22 PM Checking accuracy on training set\n",
      "06/02 03:34:24 PM Loss (0.539853)\n",
      "06/02 03:34:24 PM Got 43610 / 71381 correct (61.09)\n",
      "06/02 03:34:24 PM Checking accuracy on validation set\n",
      "06/02 03:34:24 PM Loss (0.328416)\n",
      "06/02 03:34:24 PM Got 24980 / 39868 correct (62.66)\n",
      "06/02 03:34:24 PM \n",
      "06/02 03:34:24 PM Epoch 1, Iteration 0, loss = 0.5586\n",
      "06/02 03:34:25 PM Epoch 1, Iteration 100, loss = 0.5295\n",
      "06/02 03:34:26 PM Epoch 1, Iteration 200, loss = 0.5537\n",
      "06/02 03:34:27 PM Checking accuracy on training set\n",
      "06/02 03:34:28 PM Loss (0.575643)\n",
      "06/02 03:34:28 PM Got 43682 / 71381 correct (61.20)\n",
      "06/02 03:34:28 PM Checking accuracy on validation set\n",
      "06/02 03:34:29 PM Loss (0.321550)\n",
      "06/02 03:34:29 PM Got 24992 / 39868 correct (62.69)\n",
      "06/02 03:34:29 PM \n",
      "06/02 03:34:29 PM Epoch 2, Iteration 0, loss = 0.5716\n",
      "06/02 03:34:30 PM Epoch 2, Iteration 100, loss = 0.6184\n",
      "06/02 03:34:31 PM Epoch 2, Iteration 200, loss = 0.6874\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/02 03:34:32 PM Checking accuracy on training set\n",
      "06/02 03:34:33 PM Loss (0.536591)\n",
      "06/02 03:34:33 PM Got 44199 / 71381 correct (61.92)\n",
      "06/02 03:34:33 PM Checking accuracy on validation set\n",
      "06/02 03:34:34 PM Loss (0.246492)\n",
      "06/02 03:34:34 PM Got 25279 / 39868 correct (63.41)\n",
      "06/02 03:34:34 PM \n",
      "06/02 03:34:34 PM Epoch 3, Iteration 0, loss = 0.5015\n",
      "06/02 03:34:35 PM Epoch 3, Iteration 100, loss = 0.5709\n",
      "06/02 03:34:36 PM Epoch 3, Iteration 200, loss = 0.5749\n",
      "06/02 03:34:37 PM Checking accuracy on training set\n",
      "06/02 03:34:38 PM Loss (0.558653)\n",
      "06/02 03:34:38 PM Got 45820 / 71381 correct (64.19)\n",
      "06/02 03:34:38 PM Checking accuracy on validation set\n",
      "06/02 03:34:39 PM Loss (0.211629)\n",
      "06/02 03:34:39 PM Got 26200 / 39868 correct (65.72)\n",
      "06/02 03:34:39 PM \n",
      "06/02 03:34:39 PM Epoch 4, Iteration 0, loss = 0.5712\n",
      "06/02 03:34:40 PM Epoch 4, Iteration 100, loss = 0.5126\n",
      "06/02 03:34:41 PM Epoch 4, Iteration 200, loss = 0.5277\n",
      "06/02 03:34:41 PM Checking accuracy on training set\n",
      "06/02 03:34:43 PM Loss (0.543228)\n",
      "06/02 03:34:43 PM Got 45069 / 71381 correct (63.14)\n",
      "06/02 03:34:43 PM Checking accuracy on validation set\n",
      "06/02 03:34:43 PM Loss (0.264525)\n",
      "06/02 03:34:43 PM Got 25702 / 39868 correct (64.47)\n",
      "06/02 03:34:43 PM \n",
      "06/02 03:34:43 PM Epoch 5, Iteration 0, loss = 0.5589\n",
      "06/02 03:34:44 PM Epoch 5, Iteration 100, loss = 0.5728\n",
      "06/02 03:34:45 PM Epoch 5, Iteration 200, loss = 0.5032\n",
      "06/02 03:34:46 PM Checking accuracy on training set\n",
      "06/02 03:34:47 PM Loss (0.526136)\n",
      "06/02 03:34:47 PM Got 50210 / 71381 correct (70.34)\n",
      "06/02 03:34:47 PM Checking accuracy on validation set\n",
      "06/02 03:34:48 PM Loss (0.215223)\n",
      "06/02 03:34:48 PM Got 27864 / 39868 correct (69.89)\n",
      "06/02 03:34:48 PM \n",
      "06/02 03:34:48 PM Epoch 6, Iteration 0, loss = 0.5247\n",
      "06/02 03:34:49 PM Epoch 6, Iteration 100, loss = 0.4821\n",
      "06/02 03:34:50 PM Epoch 6, Iteration 200, loss = 0.4761\n",
      "06/02 03:34:51 PM Checking accuracy on training set\n",
      "06/02 03:34:52 PM Loss (0.456586)\n",
      "06/02 03:34:52 PM Got 49058 / 71381 correct (68.73)\n",
      "06/02 03:34:52 PM Checking accuracy on validation set\n",
      "06/02 03:34:53 PM Loss (0.174871)\n",
      "06/02 03:34:53 PM Got 27444 / 39868 correct (68.84)\n",
      "06/02 03:34:53 PM \n",
      "06/02 03:34:53 PM Epoch 7, Iteration 0, loss = 0.6821\n",
      "06/02 03:34:54 PM Epoch 7, Iteration 100, loss = 0.4442\n",
      "06/02 03:34:55 PM Epoch 7, Iteration 200, loss = 0.4725\n",
      "06/02 03:34:56 PM Checking accuracy on training set\n",
      "06/02 03:34:57 PM Loss (0.502671)\n",
      "06/02 03:34:57 PM Got 48732 / 71381 correct (68.27)\n",
      "06/02 03:34:57 PM Checking accuracy on validation set\n",
      "06/02 03:34:58 PM Loss (0.206395)\n",
      "06/02 03:34:58 PM Got 27440 / 39868 correct (68.83)\n",
      "06/02 03:34:58 PM \n",
      "06/02 03:34:58 PM Epoch 8, Iteration 0, loss = 0.4487\n",
      "06/02 03:34:59 PM Epoch 8, Iteration 100, loss = 0.5152\n",
      "06/02 03:35:00 PM Epoch 8, Iteration 200, loss = 0.4314\n",
      "06/02 03:35:00 PM Checking accuracy on training set\n",
      "06/02 03:35:02 PM Loss (0.449767)\n",
      "06/02 03:35:02 PM Got 51694 / 71381 correct (72.42)\n",
      "06/02 03:35:02 PM Checking accuracy on validation set\n",
      "06/02 03:35:02 PM Loss (0.223267)\n",
      "06/02 03:35:02 PM Got 28420 / 39868 correct (71.29)\n",
      "06/02 03:35:02 PM \n",
      "06/02 03:35:02 PM Epoch 9, Iteration 0, loss = 0.5531\n",
      "06/02 03:35:03 PM Epoch 9, Iteration 100, loss = 0.4943\n",
      "06/02 03:35:04 PM Epoch 9, Iteration 200, loss = 0.4488\n",
      "06/02 03:35:05 PM Checking accuracy on training set\n",
      "06/02 03:35:06 PM Loss (0.459817)\n",
      "06/02 03:35:06 PM Got 51805 / 71381 correct (72.58)\n",
      "06/02 03:35:06 PM Checking accuracy on validation set\n",
      "06/02 03:35:07 PM Loss (0.141635)\n",
      "06/02 03:35:07 PM Got 28376 / 39868 correct (71.17)\n",
      "06/02 03:35:07 PM \n",
      "06/02 03:35:07 PM Epoch 10, Iteration 0, loss = 0.4703\n",
      "06/02 03:35:08 PM Epoch 10, Iteration 100, loss = 0.4491\n",
      "06/02 03:35:09 PM Epoch 10, Iteration 200, loss = 0.4827\n",
      "06/02 03:35:10 PM Checking accuracy on training set\n",
      "06/02 03:35:11 PM Loss (0.419936)\n",
      "06/02 03:35:11 PM Got 53824 / 71381 correct (75.40)\n",
      "06/02 03:35:11 PM Checking accuracy on validation set\n",
      "06/02 03:35:12 PM Loss (0.227529)\n",
      "06/02 03:35:12 PM Got 28986 / 39868 correct (72.70)\n",
      "06/02 03:35:12 PM \n",
      "06/02 03:35:12 PM Epoch 11, Iteration 0, loss = 0.4245\n",
      "06/02 03:35:13 PM Epoch 11, Iteration 100, loss = 0.5007\n",
      "06/02 03:35:14 PM Epoch 11, Iteration 200, loss = 0.4635\n",
      "06/02 03:35:15 PM Checking accuracy on training set\n",
      "06/02 03:35:16 PM Loss (0.393924)\n",
      "06/02 03:35:16 PM Got 53852 / 71381 correct (75.44)\n",
      "06/02 03:35:16 PM Checking accuracy on validation set\n",
      "06/02 03:35:17 PM Loss (0.194847)\n",
      "06/02 03:35:17 PM Got 29053 / 39868 correct (72.87)\n",
      "06/02 03:35:17 PM \n",
      "06/02 03:35:17 PM Epoch 12, Iteration 0, loss = 0.4639\n",
      "06/02 03:35:18 PM Epoch 12, Iteration 100, loss = 0.4668\n",
      "06/02 03:35:19 PM Epoch 12, Iteration 200, loss = 0.4274\n",
      "06/02 03:35:19 PM Checking accuracy on training set\n",
      "06/02 03:35:21 PM Loss (0.434025)\n",
      "06/02 03:35:21 PM Got 54385 / 71381 correct (76.19)\n",
      "06/02 03:35:21 PM Checking accuracy on validation set\n",
      "06/02 03:35:21 PM Loss (0.175654)\n",
      "06/02 03:35:21 PM Got 29116 / 39868 correct (73.03)\n",
      "06/02 03:35:21 PM \n",
      "06/02 03:35:22 PM Epoch 13, Iteration 0, loss = 0.4391\n",
      "06/02 03:35:23 PM Epoch 13, Iteration 100, loss = 0.4452\n",
      "06/02 03:35:24 PM Epoch 13, Iteration 200, loss = 0.4004\n",
      "06/02 03:35:24 PM Checking accuracy on training set\n",
      "06/02 03:35:26 PM Loss (0.400262)\n",
      "06/02 03:35:26 PM Got 54017 / 71381 correct (75.67)\n",
      "06/02 03:35:26 PM Checking accuracy on validation set\n",
      "06/02 03:35:26 PM Loss (0.185820)\n",
      "06/02 03:35:26 PM Got 28975 / 39868 correct (72.68)\n",
      "06/02 03:35:26 PM \n",
      "06/02 03:35:26 PM Epoch 14, Iteration 0, loss = 0.4373\n",
      "06/02 03:35:27 PM Epoch 14, Iteration 100, loss = 0.4123\n",
      "06/02 03:35:28 PM Epoch 14, Iteration 200, loss = 0.4140\n",
      "06/02 03:35:29 PM Checking accuracy on training set\n",
      "06/02 03:35:30 PM Loss (0.401994)\n",
      "06/02 03:35:30 PM Got 55083 / 71381 correct (77.17)\n",
      "06/02 03:35:30 PM Checking accuracy on validation set\n",
      "06/02 03:35:31 PM Loss (0.218187)\n",
      "06/02 03:35:31 PM Got 29126 / 39868 correct (73.06)\n",
      "06/02 03:35:31 PM \n",
      "06/02 03:35:31 PM Epoch 15, Iteration 0, loss = 0.4433\n",
      "06/02 03:35:32 PM Epoch 15, Iteration 100, loss = 0.4201\n",
      "06/02 03:35:33 PM Epoch 15, Iteration 200, loss = 0.4171\n",
      "06/02 03:35:34 PM Checking accuracy on training set\n",
      "06/02 03:35:35 PM Loss (0.503925)\n",
      "06/02 03:35:35 PM Got 54220 / 71381 correct (75.96)\n",
      "06/02 03:35:35 PM Checking accuracy on validation set\n",
      "06/02 03:35:36 PM Loss (0.189360)\n",
      "06/02 03:35:36 PM Got 28996 / 39868 correct (72.73)\n",
      "06/02 03:35:36 PM \n",
      "06/02 03:35:36 PM Epoch 16, Iteration 0, loss = 0.5111\n",
      "06/02 03:35:37 PM Epoch 16, Iteration 100, loss = 0.4271\n",
      "06/02 03:35:38 PM Epoch 16, Iteration 200, loss = 0.4321\n",
      "06/02 03:35:39 PM Checking accuracy on training set\n",
      "06/02 03:35:40 PM Loss (0.507038)\n",
      "06/02 03:35:40 PM Got 47853 / 71381 correct (67.04)\n",
      "06/02 03:35:40 PM Checking accuracy on validation set\n",
      "06/02 03:35:41 PM Loss (0.303381)\n",
      "06/02 03:35:41 PM Got 26723 / 39868 correct (67.03)\n",
      "06/02 03:35:41 PM \n",
      "06/02 03:35:41 PM Epoch 17, Iteration 0, loss = 0.5830\n",
      "06/02 03:35:42 PM Epoch 17, Iteration 100, loss = 0.4630\n",
      "06/02 03:35:43 PM Epoch 17, Iteration 200, loss = 0.5184\n",
      "06/02 03:35:43 PM Checking accuracy on training set\n",
      "06/02 03:35:45 PM Loss (0.471621)\n",
      "06/02 03:35:45 PM Got 52269 / 71381 correct (73.23)\n",
      "06/02 03:35:45 PM Checking accuracy on validation set\n",
      "06/02 03:35:45 PM Loss (0.223967)\n",
      "06/02 03:35:45 PM Got 28610 / 39868 correct (71.76)\n",
      "06/02 03:35:45 PM \n",
      "06/02 03:35:45 PM Epoch 18, Iteration 0, loss = 0.4628\n",
      "06/02 03:35:46 PM Epoch 18, Iteration 100, loss = 0.4901\n",
      "06/02 03:35:47 PM Epoch 18, Iteration 200, loss = 0.5727\n",
      "06/02 03:35:48 PM Checking accuracy on training set\n",
      "06/02 03:35:49 PM Loss (0.575986)\n",
      "06/02 03:35:49 PM Got 43596 / 71381 correct (61.08)\n",
      "06/02 03:35:49 PM Checking accuracy on validation set\n",
      "06/02 03:35:50 PM Loss (0.337983)\n",
      "06/02 03:35:50 PM Got 24980 / 39868 correct (62.66)\n",
      "06/02 03:35:50 PM \n",
      "06/02 03:35:50 PM Epoch 19, Iteration 0, loss = 0.5792\n",
      "06/02 03:35:51 PM Epoch 19, Iteration 100, loss = 0.6217\n",
      "06/02 03:35:52 PM Epoch 19, Iteration 200, loss = 0.5840\n",
      "06/02 03:35:53 PM Checking accuracy on training set\n",
      "06/02 03:35:54 PM Loss (0.562896)\n",
      "06/02 03:35:54 PM Got 43598 / 71381 correct (61.08)\n",
      "06/02 03:35:54 PM Checking accuracy on validation set\n",
      "06/02 03:35:55 PM Loss (0.319940)\n",
      "06/02 03:35:55 PM Got 24979 / 39868 correct (62.65)\n",
      "06/02 03:35:55 PM \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/02 03:35:55 PM Epoch 20, Iteration 0, loss = 0.6118\n",
      "06/02 03:35:56 PM Epoch 20, Iteration 100, loss = 0.5568\n",
      "06/02 03:35:57 PM Epoch 20, Iteration 200, loss = 0.5272\n",
      "06/02 03:35:58 PM Checking accuracy on training set\n",
      "06/02 03:35:59 PM Loss (0.571461)\n",
      "06/02 03:35:59 PM Got 43602 / 71381 correct (61.08)\n",
      "06/02 03:35:59 PM Checking accuracy on validation set\n",
      "06/02 03:36:00 PM Loss (0.242713)\n",
      "06/02 03:36:00 PM Got 24965 / 39868 correct (62.62)\n",
      "06/02 03:36:00 PM \n",
      "06/02 03:36:00 PM Epoch 21, Iteration 0, loss = 0.5368\n",
      "06/02 03:36:01 PM Epoch 21, Iteration 100, loss = 0.6344\n",
      "06/02 03:36:02 PM Epoch 21, Iteration 200, loss = 0.5147\n",
      "06/02 03:36:02 PM Checking accuracy on training set\n",
      "06/02 03:36:04 PM Loss (0.580060)\n",
      "06/02 03:36:04 PM Got 43598 / 71381 correct (61.08)\n",
      "06/02 03:36:04 PM Checking accuracy on validation set\n",
      "06/02 03:36:04 PM Loss (0.345859)\n",
      "06/02 03:36:04 PM Got 24977 / 39868 correct (62.65)\n",
      "06/02 03:36:04 PM \n",
      "06/02 03:36:04 PM Epoch 22, Iteration 0, loss = 0.5807\n",
      "06/02 03:36:05 PM Epoch 22, Iteration 100, loss = 0.5713\n",
      "06/02 03:36:06 PM Epoch 22, Iteration 200, loss = 0.5347\n",
      "06/02 03:36:07 PM Checking accuracy on training set\n",
      "06/02 03:36:08 PM Loss (0.558045)\n",
      "06/02 03:36:08 PM Got 45862 / 71381 correct (64.25)\n",
      "06/02 03:36:08 PM Checking accuracy on validation set\n",
      "06/02 03:36:09 PM Loss (0.272293)\n",
      "06/02 03:36:09 PM Got 25872 / 39868 correct (64.89)\n",
      "06/02 03:36:09 PM \n",
      "06/02 03:36:09 PM Epoch 23, Iteration 0, loss = 0.5872\n",
      "06/02 03:36:10 PM Epoch 23, Iteration 100, loss = 0.5861\n",
      "06/02 03:36:11 PM Epoch 23, Iteration 200, loss = 0.4720\n",
      "06/02 03:36:12 PM Checking accuracy on training set\n",
      "06/02 03:36:13 PM Loss (0.480193)\n",
      "06/02 03:36:13 PM Got 47715 / 71381 correct (66.85)\n",
      "06/02 03:36:13 PM Checking accuracy on validation set\n",
      "06/02 03:36:14 PM Loss (0.245526)\n",
      "06/02 03:36:14 PM Got 26738 / 39868 correct (67.07)\n",
      "06/02 03:36:14 PM \n",
      "06/02 03:36:14 PM Epoch 24, Iteration 0, loss = 0.4746\n",
      "06/02 03:36:15 PM Epoch 24, Iteration 100, loss = 0.4960\n",
      "06/02 03:36:16 PM Epoch 24, Iteration 200, loss = 0.4917\n",
      "06/02 03:36:17 PM Checking accuracy on training set\n",
      "06/02 03:36:18 PM Loss (0.501506)\n",
      "06/02 03:36:18 PM Got 52731 / 71381 correct (73.87)\n",
      "06/02 03:36:18 PM Checking accuracy on validation set\n",
      "06/02 03:36:19 PM Loss (0.235665)\n",
      "06/02 03:36:19 PM Got 28904 / 39868 correct (72.50)\n",
      "06/02 03:36:19 PM \n",
      "06/02 03:36:19 PM Epoch 25, Iteration 0, loss = 0.5381\n",
      "06/02 03:36:20 PM Epoch 25, Iteration 100, loss = 0.5247\n",
      "06/02 03:36:21 PM Epoch 25, Iteration 200, loss = 0.5536\n",
      "06/02 03:36:21 PM Checking accuracy on training set\n",
      "06/02 03:36:23 PM Loss (0.508706)\n",
      "06/02 03:36:23 PM Got 51242 / 71381 correct (71.79)\n",
      "06/02 03:36:23 PM Checking accuracy on validation set\n",
      "06/02 03:36:23 PM Loss (0.199083)\n",
      "06/02 03:36:23 PM Got 28231 / 39868 correct (70.81)\n",
      "06/02 03:36:23 PM \n",
      "06/02 03:36:23 PM Epoch 26, Iteration 0, loss = 0.4556\n",
      "06/02 03:36:24 PM Epoch 26, Iteration 100, loss = 0.5022\n",
      "06/02 03:36:25 PM Epoch 26, Iteration 200, loss = 0.4157\n",
      "06/02 03:36:26 PM Checking accuracy on training set\n",
      "06/02 03:36:27 PM Loss (0.421590)\n",
      "06/02 03:36:27 PM Got 53658 / 71381 correct (75.17)\n",
      "06/02 03:36:27 PM Checking accuracy on validation set\n",
      "06/02 03:36:28 PM Loss (0.148189)\n",
      "06/02 03:36:28 PM Got 29019 / 39868 correct (72.79)\n",
      "06/02 03:36:28 PM \n",
      "06/02 03:36:28 PM Epoch 27, Iteration 0, loss = 0.3994\n",
      "06/02 03:36:29 PM Epoch 27, Iteration 100, loss = 0.5029\n",
      "06/02 03:36:30 PM Epoch 27, Iteration 200, loss = 0.4435\n",
      "06/02 03:36:31 PM Checking accuracy on training set\n",
      "06/02 03:36:32 PM Loss (0.417282)\n",
      "06/02 03:36:32 PM Got 54363 / 71381 correct (76.16)\n",
      "06/02 03:36:32 PM Checking accuracy on validation set\n",
      "06/02 03:36:33 PM Loss (0.207037)\n",
      "06/02 03:36:33 PM Got 29212 / 39868 correct (73.27)\n",
      "06/02 03:36:33 PM \n",
      "06/02 03:36:33 PM Epoch 28, Iteration 0, loss = 0.4706\n",
      "06/02 03:36:34 PM Epoch 28, Iteration 100, loss = 0.4390\n",
      "06/02 03:36:35 PM Epoch 28, Iteration 200, loss = 0.4696\n",
      "06/02 03:36:36 PM Checking accuracy on training set\n",
      "06/02 03:36:37 PM Loss (0.470823)\n",
      "06/02 03:36:37 PM Got 52396 / 71381 correct (73.40)\n",
      "06/02 03:36:37 PM Checking accuracy on validation set\n",
      "06/02 03:36:38 PM Loss (0.321199)\n",
      "06/02 03:36:38 PM Got 28589 / 39868 correct (71.71)\n",
      "06/02 03:36:38 PM \n",
      "06/02 03:36:38 PM Epoch 29, Iteration 0, loss = 0.4789\n",
      "06/02 03:36:39 PM Epoch 29, Iteration 100, loss = 0.4717\n",
      "06/02 03:36:40 PM Epoch 29, Iteration 200, loss = 0.4559\n",
      "06/02 03:36:41 PM Checking accuracy on training set\n",
      "06/02 03:36:42 PM Loss (0.414815)\n",
      "06/02 03:36:42 PM Got 54273 / 71381 correct (76.03)\n",
      "06/02 03:36:42 PM Checking accuracy on validation set\n",
      "06/02 03:36:43 PM Loss (0.177648)\n",
      "06/02 03:36:43 PM Got 29218 / 39868 correct (73.29)\n",
      "06/02 03:36:43 PM \n",
      "06/02 03:36:43 PM Epoch 30, Iteration 0, loss = 0.4460\n",
      "06/02 03:36:44 PM Epoch 30, Iteration 100, loss = 0.4398\n",
      "06/02 03:36:45 PM Epoch 30, Iteration 200, loss = 0.5893\n",
      "06/02 03:36:46 PM Checking accuracy on training set\n",
      "06/02 03:36:47 PM Loss (0.453857)\n",
      "06/02 03:36:47 PM Got 54027 / 71381 correct (75.69)\n",
      "06/02 03:36:47 PM Checking accuracy on validation set\n",
      "06/02 03:36:48 PM Loss (0.294559)\n",
      "06/02 03:36:48 PM Got 29090 / 39868 correct (72.97)\n",
      "06/02 03:36:48 PM \n",
      "06/02 03:36:48 PM Epoch 31, Iteration 0, loss = 0.4933\n",
      "06/02 03:36:49 PM Epoch 31, Iteration 100, loss = 0.4240\n",
      "06/02 03:36:50 PM Epoch 31, Iteration 200, loss = 0.3723\n",
      "06/02 03:36:50 PM Checking accuracy on training set\n",
      "06/02 03:36:52 PM Loss (0.418420)\n",
      "06/02 03:36:52 PM Got 54754 / 71381 correct (76.71)\n",
      "06/02 03:36:52 PM Checking accuracy on validation set\n",
      "06/02 03:36:52 PM Loss (0.233553)\n",
      "06/02 03:36:52 PM Got 29146 / 39868 correct (73.11)\n",
      "06/02 03:36:52 PM \n",
      "06/02 03:36:52 PM Epoch 32, Iteration 0, loss = 0.4519\n",
      "06/02 03:36:53 PM Epoch 32, Iteration 100, loss = 0.4513\n",
      "06/02 03:36:54 PM Epoch 32, Iteration 200, loss = 0.3482\n",
      "06/02 03:36:55 PM Checking accuracy on training set\n",
      "06/02 03:36:56 PM Loss (0.396497)\n",
      "06/02 03:36:56 PM Got 55156 / 71381 correct (77.27)\n",
      "06/02 03:36:56 PM Checking accuracy on validation set\n",
      "06/02 03:36:57 PM Loss (0.155372)\n",
      "06/02 03:36:57 PM Got 29441 / 39868 correct (73.85)\n",
      "06/02 03:36:57 PM \n",
      "06/02 03:36:57 PM Epoch 33, Iteration 0, loss = 0.4469\n",
      "06/02 03:36:58 PM Epoch 33, Iteration 100, loss = 0.3938\n",
      "06/02 03:36:59 PM Epoch 33, Iteration 200, loss = 0.4139\n",
      "06/02 03:37:00 PM Checking accuracy on training set\n",
      "06/02 03:37:01 PM Loss (0.407791)\n",
      "06/02 03:37:01 PM Got 53694 / 71381 correct (75.22)\n",
      "06/02 03:37:01 PM Checking accuracy on validation set\n",
      "06/02 03:37:02 PM Loss (0.157240)\n",
      "06/02 03:37:02 PM Got 28905 / 39868 correct (72.50)\n",
      "06/02 03:37:02 PM \n",
      "06/02 03:37:02 PM Epoch 34, Iteration 0, loss = 0.4298\n",
      "06/02 03:37:03 PM Epoch 34, Iteration 100, loss = 0.4855\n",
      "06/02 03:37:04 PM Epoch 34, Iteration 200, loss = 0.3704\n",
      "06/02 03:37:05 PM Checking accuracy on training set\n",
      "06/02 03:37:06 PM Loss (0.432016)\n",
      "06/02 03:37:06 PM Got 55433 / 71381 correct (77.66)\n",
      "06/02 03:37:06 PM Checking accuracy on validation set\n",
      "06/02 03:37:07 PM Loss (0.245758)\n",
      "06/02 03:37:07 PM Got 29382 / 39868 correct (73.70)\n",
      "06/02 03:37:07 PM \n",
      "06/02 03:37:07 PM Epoch 35, Iteration 0, loss = 0.4208\n",
      "06/02 03:37:08 PM Epoch 35, Iteration 100, loss = 0.4236\n",
      "06/02 03:37:09 PM Epoch 35, Iteration 200, loss = 0.4268\n",
      "06/02 03:37:10 PM Checking accuracy on training set\n",
      "06/02 03:37:11 PM Loss (0.390750)\n",
      "06/02 03:37:11 PM Got 55951 / 71381 correct (78.38)\n",
      "06/02 03:37:11 PM Checking accuracy on validation set\n",
      "06/02 03:37:12 PM Loss (0.188518)\n",
      "06/02 03:37:12 PM Got 29538 / 39868 correct (74.09)\n",
      "06/02 03:37:12 PM \n",
      "06/02 03:37:12 PM Epoch 36, Iteration 0, loss = 0.4253\n",
      "06/02 03:37:13 PM Epoch 36, Iteration 100, loss = 0.4239\n",
      "06/02 03:37:14 PM Epoch 36, Iteration 200, loss = 0.4189\n",
      "06/02 03:37:14 PM Checking accuracy on training set\n",
      "06/02 03:37:16 PM Loss (0.379501)\n",
      "06/02 03:37:16 PM Got 54833 / 71381 correct (76.82)\n",
      "06/02 03:37:16 PM Checking accuracy on validation set\n",
      "06/02 03:37:16 PM Loss (0.230619)\n",
      "06/02 03:37:16 PM Got 29423 / 39868 correct (73.80)\n",
      "06/02 03:37:16 PM \n",
      "06/02 03:37:16 PM Epoch 37, Iteration 0, loss = 0.3995\n",
      "06/02 03:37:17 PM Epoch 37, Iteration 100, loss = 0.3642\n",
      "06/02 03:37:18 PM Epoch 37, Iteration 200, loss = 0.5237\n",
      "06/02 03:37:19 PM Checking accuracy on training set\n",
      "06/02 03:37:20 PM Loss (0.372428)\n",
      "06/02 03:37:20 PM Got 55384 / 71381 correct (77.59)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06/02 03:37:20 PM Checking accuracy on validation set\n",
      "06/02 03:37:21 PM Loss (0.149817)\n",
      "06/02 03:37:21 PM Got 29287 / 39868 correct (73.46)\n",
      "06/02 03:37:21 PM \n",
      "06/02 03:37:21 PM Epoch 38, Iteration 0, loss = 0.4050\n",
      "06/02 03:37:22 PM Epoch 38, Iteration 100, loss = 0.4064\n",
      "06/02 03:37:23 PM Epoch 38, Iteration 200, loss = 0.3759\n",
      "06/02 03:37:24 PM Checking accuracy on training set\n",
      "06/02 03:37:25 PM Loss (0.423505)\n",
      "06/02 03:37:25 PM Got 56129 / 71381 correct (78.63)\n",
      "06/02 03:37:25 PM Checking accuracy on validation set\n",
      "06/02 03:37:26 PM Loss (0.156915)\n",
      "06/02 03:37:26 PM Got 29614 / 39868 correct (74.28)\n",
      "06/02 03:37:26 PM \n",
      "06/02 03:37:26 PM Epoch 39, Iteration 0, loss = 0.4435\n",
      "06/02 03:37:27 PM Epoch 39, Iteration 100, loss = 0.3391\n",
      "06/02 03:37:28 PM Epoch 39, Iteration 200, loss = 0.4223\n",
      "06/02 03:37:29 PM Checking accuracy on training set\n",
      "06/02 03:37:30 PM Loss (0.522937)\n",
      "06/02 03:37:30 PM Got 52023 / 71381 correct (72.88)\n",
      "06/02 03:37:30 PM Checking accuracy on validation set\n",
      "06/02 03:37:31 PM Loss (0.403396)\n",
      "06/02 03:37:31 PM Got 28380 / 39868 correct (71.18)\n",
      "06/02 03:37:31 PM \n"
     ]
    }
   ],
   "source": [
    "# train model multiple times, each with different random seed\n",
    "logger = Logger() # initialize logger to be used throughout\n",
    "experiment_name = 'original-ages-Conv1d-Adam'\n",
    "batch_size = 256\n",
    "loader_train = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "loader_val = DataLoader(val_data, batch_size=batch_size)\n",
    "for s in range(2, 10):\n",
    "    model = run_experiment(s, experiment_name, 'raw',loader_train, loader_val,40)\n",
    "# model = run_experiment(0, experiment_name, 'raw', loader_train, loader_val,70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_x, test_data_labels = load_data(path, 'test', winLength, numChan, srate, feature, one_channel)\n",
    "test_data_y = test_data_labels.copy()\n",
    "test_data_y[np.logical_and(test_data_labels <= 2,test_data_labels >= 0)] = 0\n",
    "test_data_y[test_data_labels > 2] = 1\n",
    "test_data = EEGDataset(test_data_x, test_data_y, False, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([8797.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "        7128.]),\n",
       " array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(test_data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5524018838304553"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8797/(8797+7128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(loader, model):\n",
    "    '''\n",
    "    Check accuracy and get confusion matrix of the model \n",
    "    param:\n",
    "        loader: An EEGDataset object\n",
    "        model: A PyTorch Module to test\n",
    "    '''\n",
    "    if loader.dataset.train:\n",
    "        logger.log('Checking accuracy on training set')\n",
    "    elif loader.dataset.val:\n",
    "        logger.log('Checking accuracy on validation set')\n",
    "    else:\n",
    "        logger.log('Checking accuracy on test set')   \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    tp = 0\n",
    "    tn = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    lossTotal = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            x = x.squeeze(1)\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            scores = model(x)\n",
    "            loss = F.cross_entropy(scores, y, weight=torch.tensor([class_0_weight,class_1_weight], dtype=dtype,device=device))\n",
    "            lossTotal += loss.item()\n",
    "#             print(f\"label {y}, prediction {scores}\")\n",
    "            _, preds = scores.max(1)\n",
    "            class_0 = y==0\n",
    "            class_1 = y==1\n",
    "            tp += (preds[class_1] == y[class_1]).sum()\n",
    "            tn += (preds[class_0] == y[class_0]).sum()\n",
    "            fp += (y[class_0] != preds[class_0]).sum()\n",
    "            fn += (y[class_1] != preds[class_1]).sum()\n",
    "            num_correct += (preds == y).sum()\n",
    "            assert num_correct == (tp+tn)\n",
    "            num_samples += preds.size(0)\n",
    "    precision = tp/(tp+fp)\n",
    "    acc = float(num_correct) / num_samples\n",
    "    lossTotal = lossTotal / len(loader)\n",
    "    logger.log('Loss (%f)' % (loss))\n",
    "    logger.log('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
    "    logger.log('Precision: (%.2f)' % (precision))\n",
    "    \n",
    "    return acc,lossTotal,tp,tn,fp,fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('./saved-model/original-ages-Conv1d-Adam-raw/model-original-ages-Conv1d-Adam-raw-seed9-valacc74.09-epoch35'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on test set\n",
      "Loss (0.327033)\n",
      "Got 11359 / 15925 correct (71.33)\n",
      "Precision: (0.83)\n"
     ]
    }
   ],
   "source": [
    "logger = Logger(mode='debug')\n",
    "loader_test = DataLoader(test_data, batch_size=1)\n",
    "model.to(device=device)\n",
    "acc,lossTotal,tp,tn,fp,fn = confusion_matrix(loader_test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp: 3600\n",
      "tn: 7799\n",
      "fp: 998\n",
      "fn: 3528\n",
      "precision: 0.7829490900039673\n",
      "recall: 0.5050504803657532\n"
     ]
    }
   ],
   "source": [
    "print(f'tp: {tp}')\n",
    "print(f'tn: {tn}')\n",
    "print(f'fp: {fp}')\n",
    "print(f'fn: {fn}')\n",
    "print(f'precision: {tp/(tp+fp)}')\n",
    "print(f'recall: {tp/(tp+fn)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_all_seeds(partial_model_path, epoch, num_seed, isBalanced=True):\n",
    "    '''\n",
    "    Given name of saved model and epoch, check test accuracy for all random seeds in range(num_seed)\n",
    "    \n",
    "    '''\n",
    "    if isBalanced:\n",
    "        logger.log('Testing on balanced test set')\n",
    "        test_data = load_data(path, 'test', winLength, numChan, srate, feature,'v2')\n",
    "        subjIDs_file = 'data/test_subjIDs_fewer_subjects.csv'\n",
    "    else:\n",
    "        logger.log('Testing on all male test set')\n",
    "        test_data = load_data(path, 'test', winLength, numChan, srate, feature,'v3')\n",
    "        subjIDs_file = 'data/test_subjIDs_more_test.csv'\n",
    "\n",
    "    sample_acc = []\n",
    "    subject_acc = []\n",
    "    for s in range(num_seed):\n",
    "        model = create_model()\n",
    "        model.load_state_dict(torch.load(f'{partial_model_path}-seed{s}-epoch{epoch}'))\n",
    "        model.to(device=device)\n",
    "        sam_acc, sub_acc = test_model(model, test_data,subjIDs_file)\n",
    "        sample_acc.append(sam_acc)\n",
    "        subject_acc.append(sub_acc)\n",
    "        \n",
    "    sample_acc = np.multiply(sample_acc,100)\n",
    "    subject_acc = np.multiply(subject_acc,100)\n",
    "    return sample_acc, subject_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on balanced test set\n",
      "Testing model accuracy using 1-segment metric\n",
      "Checking accuracy on test set\n",
      "Got 13172 / 15925 correct (82.71)\n",
      "Testing model accuracy using 40-segment per subject metric\n",
      "Got 170 / 197 correct (86.29)\n",
      "Testing model accuracy using 1-segment metric\n",
      "Checking accuracy on test set\n",
      "Got 13102 / 15925 correct (82.27)\n",
      "Testing model accuracy using 40-segment per subject metric\n",
      "Got 169 / 197 correct (85.79)\n",
      "Testing model accuracy using 1-segment metric\n",
      "Checking accuracy on test set\n",
      "Got 12874 / 15925 correct (80.84)\n",
      "Testing model accuracy using 40-segment per subject metric\n",
      "Got 168 / 197 correct (85.28)\n",
      "Testing model accuracy using 1-segment metric\n",
      "Checking accuracy on test set\n",
      "Got 12761 / 15925 correct (80.13)\n",
      "Testing model accuracy using 40-segment per subject metric\n",
      "Got 165 / 197 correct (83.76)\n",
      "Testing model accuracy using 1-segment metric\n",
      "Checking accuracy on test set\n",
      "Got 12477 / 15925 correct (78.35)\n",
      "Testing model accuracy using 40-segment per subject metric\n",
      "Got 163 / 197 correct (82.74)\n",
      "Testing model accuracy using 1-segment metric\n",
      "Checking accuracy on test set\n",
      "Got 12681 / 15925 correct (79.63)\n",
      "Testing model accuracy using 40-segment per subject metric\n",
      "Got 165 / 197 correct (83.76)\n",
      "Testing model accuracy using 1-segment metric\n",
      "Checking accuracy on test set\n",
      "Got 13115 / 15925 correct (82.35)\n",
      "Testing model accuracy using 40-segment per subject metric\n",
      "Got 169 / 197 correct (85.79)\n",
      "Testing model accuracy using 1-segment metric\n",
      "Checking accuracy on test set\n",
      "Got 12831 / 15925 correct (80.57)\n",
      "Testing model accuracy using 40-segment per subject metric\n",
      "Got 170 / 197 correct (86.29)\n",
      "Testing model accuracy using 1-segment metric\n",
      "Checking accuracy on test set\n",
      "Got 12487 / 15925 correct (78.41)\n",
      "Testing model accuracy using 40-segment per subject metric\n",
      "Got 167 / 197 correct (84.77)\n",
      "Testing model accuracy using 1-segment metric\n",
      "Checking accuracy on test set\n",
      "Got 12899 / 15925 correct (81.00)\n",
      "Testing model accuracy using 40-segment per subject metric\n",
      "Got 171 / 197 correct (86.80)\n",
      "Per sample\n",
      "Min: 78.34850863422292, Max: 82.712715855573, Mean: 80.62731554160125, STDEV: 1.4687850472648853\n",
      "Per subject\n",
      "Min: 82.74111675126903, Max: 86.80203045685279, Mean: 85.1269035532995, STDEV: 1.2649681009519929\n",
      "Testing on balanced test set\n",
      "Testing model accuracy using 1-segment metric\n",
      "Checking accuracy on test set\n",
      "Got 12652 / 15925 correct (79.45)\n",
      "Testing model accuracy using 40-segment per subject metric\n",
      "Got 166 / 197 correct (84.26)\n",
      "Testing model accuracy using 1-segment metric\n",
      "Checking accuracy on test set\n",
      "Got 12309 / 15925 correct (77.29)\n",
      "Testing model accuracy using 40-segment per subject metric\n",
      "Got 163 / 197 correct (82.74)\n",
      "Testing model accuracy using 1-segment metric\n",
      "Checking accuracy on test set\n",
      "Got 12656 / 15925 correct (79.47)\n",
      "Testing model accuracy using 40-segment per subject metric\n",
      "Got 169 / 197 correct (85.79)\n",
      "Testing model accuracy using 1-segment metric\n",
      "Checking accuracy on test set\n",
      "Got 13112 / 15925 correct (82.34)\n",
      "Testing model accuracy using 40-segment per subject metric\n",
      "Got 168 / 197 correct (85.28)\n",
      "Testing model accuracy using 1-segment metric\n",
      "Checking accuracy on test set\n",
      "Got 12905 / 15925 correct (81.04)\n",
      "Testing model accuracy using 40-segment per subject metric\n",
      "Got 166 / 197 correct (84.26)\n",
      "Testing model accuracy using 1-segment metric\n",
      "Checking accuracy on test set\n",
      "Got 13040 / 15925 correct (81.88)\n",
      "Testing model accuracy using 40-segment per subject metric\n",
      "Got 172 / 197 correct (87.31)\n",
      "Testing model accuracy using 1-segment metric\n",
      "Checking accuracy on test set\n",
      "Got 13256 / 15925 correct (83.24)\n",
      "Testing model accuracy using 40-segment per subject metric\n",
      "Got 170 / 197 correct (86.29)\n",
      "Testing model accuracy using 1-segment metric\n",
      "Checking accuracy on test set\n",
      "Got 12843 / 15925 correct (80.65)\n",
      "Testing model accuracy using 40-segment per subject metric\n",
      "Got 168 / 197 correct (85.28)\n",
      "Testing model accuracy using 1-segment metric\n",
      "Checking accuracy on test set\n",
      "Got 12972 / 15925 correct (81.46)\n",
      "Testing model accuracy using 40-segment per subject metric\n",
      "Got 171 / 197 correct (86.80)\n",
      "Testing model accuracy using 1-segment metric\n",
      "Checking accuracy on test set\n",
      "Got 13330 / 15925 correct (83.70)\n",
      "Testing model accuracy using 40-segment per subject metric\n",
      "Got 175 / 197 correct (88.83)\n",
      "Per sample\n",
      "Min: 77.29356357927787, Max: 83.70486656200941, Mean: 81.05180533751962, STDEV: 1.8354826738149437\n",
      "Per subject\n",
      "Min: 82.74111675126903, Max: 88.83248730964468, Mean: 85.68527918781726, STDEV: 1.6495509451037509\n",
      "Testing on balanced test set\n",
      "Testing model accuracy using 1-segment metric\n",
      "Checking accuracy on test set\n",
      "Got 12996 / 15925 correct (81.61)\n",
      "Testing model accuracy using 40-segment per subject metric\n",
      "Got 170 / 197 correct (86.29)\n",
      "Testing model accuracy using 1-segment metric\n",
      "Checking accuracy on test set\n",
      "Got 12924 / 15925 correct (81.16)\n",
      "Testing model accuracy using 40-segment per subject metric\n",
      "Got 171 / 197 correct (86.80)\n",
      "Testing model accuracy using 1-segment metric\n",
      "Checking accuracy on test set\n",
      "Got 12807 / 15925 correct (80.42)\n",
      "Testing model accuracy using 40-segment per subject metric\n",
      "Got 166 / 197 correct (84.26)\n",
      "Testing model accuracy using 1-segment metric\n",
      "Checking accuracy on test set\n",
      "Got 13038 / 15925 correct (81.87)\n",
      "Testing model accuracy using 40-segment per subject metric\n",
      "Got 163 / 197 correct (82.74)\n",
      "Testing model accuracy using 1-segment metric\n",
      "Checking accuracy on test set\n",
      "Got 13212 / 15925 correct (82.96)\n",
      "Testing model accuracy using 40-segment per subject metric\n",
      "Got 173 / 197 correct (87.82)\n",
      "Testing model accuracy using 1-segment metric\n",
      "Checking accuracy on test set\n",
      "Got 13123 / 15925 correct (82.41)\n",
      "Testing model accuracy using 40-segment per subject metric\n",
      "Got 171 / 197 correct (86.80)\n",
      "Testing model accuracy using 1-segment metric\n",
      "Checking accuracy on test set\n",
      "Got 13146 / 15925 correct (82.55)\n",
      "Testing model accuracy using 40-segment per subject metric\n",
      "Got 171 / 197 correct (86.80)\n",
      "Testing model accuracy using 1-segment metric\n",
      "Checking accuracy on test set\n",
      "Got 12114 / 15925 correct (76.07)\n",
      "Testing model accuracy using 40-segment per subject metric\n",
      "Got 157 / 197 correct (79.70)\n",
      "Testing model accuracy using 1-segment metric\n",
      "Checking accuracy on test set\n",
      "Got 12988 / 15925 correct (81.56)\n",
      "Testing model accuracy using 40-segment per subject metric\n",
      "Got 167 / 197 correct (84.77)\n",
      "Testing model accuracy using 1-segment metric\n",
      "Checking accuracy on test set\n",
      "Got 13016 / 15925 correct (81.73)\n",
      "Testing model accuracy using 40-segment per subject metric\n",
      "Got 172 / 197 correct (87.31)\n",
      "Per sample\n",
      "Min: 76.0690737833595, Max: 82.96389324960754, Mean: 81.23328100470958, STDEV: 1.8530402645497464\n",
      "Per subject\n",
      "Min: 79.69543147208121, Max: 87.81725888324873, Mean: 85.32994923857868, STDEV: 2.3965627683477937\n",
      "Testing on balanced test set\n",
      "Testing model accuracy using 1-segment metric\n",
      "Checking accuracy on test set\n",
      "Got 13132 / 15925 correct (82.46)\n",
      "Testing model accuracy using 40-segment per subject metric\n",
      "Got 170 / 197 correct (86.29)\n",
      "Testing model accuracy using 1-segment metric\n",
      "Checking accuracy on test set\n",
      "Got 12803 / 15925 correct (80.40)\n",
      "Testing model accuracy using 40-segment per subject metric\n",
      "Got 170 / 197 correct (86.29)\n",
      "Testing model accuracy using 1-segment metric\n",
      "Checking accuracy on test set\n",
      "Got 12988 / 15925 correct (81.56)\n",
      "Testing model accuracy using 40-segment per subject metric\n",
      "Got 173 / 197 correct (87.82)\n",
      "Testing model accuracy using 1-segment metric\n",
      "Checking accuracy on test set\n",
      "Got 13138 / 15925 correct (82.50)\n",
      "Testing model accuracy using 40-segment per subject metric\n",
      "Got 174 / 197 correct (88.32)\n",
      "Testing model accuracy using 1-segment metric\n",
      "Checking accuracy on test set\n",
      "Got 13099 / 15925 correct (82.25)\n",
      "Testing model accuracy using 40-segment per subject metric\n",
      "Got 175 / 197 correct (88.83)\n",
      "Testing model accuracy using 1-segment metric\n",
      "Checking accuracy on test set\n",
      "Got 13004 / 15925 correct (81.66)\n",
      "Testing model accuracy using 40-segment per subject metric\n",
      "Got 169 / 197 correct (85.79)\n",
      "Testing model accuracy using 1-segment metric\n",
      "Checking accuracy on test set\n",
      "Got 12951 / 15925 correct (81.32)\n",
      "Testing model accuracy using 40-segment per subject metric\n",
      "Got 168 / 197 correct (85.28)\n",
      "Testing model accuracy using 1-segment metric\n",
      "Checking accuracy on test set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 12758 / 15925 correct (80.11)\n",
      "Testing model accuracy using 40-segment per subject metric\n",
      "Got 165 / 197 correct (83.76)\n",
      "Testing model accuracy using 1-segment metric\n",
      "Checking accuracy on test set\n",
      "Got 13029 / 15925 correct (81.81)\n",
      "Testing model accuracy using 40-segment per subject metric\n",
      "Got 166 / 197 correct (84.26)\n",
      "Testing model accuracy using 1-segment metric\n",
      "Checking accuracy on test set\n",
      "Got 12702 / 15925 correct (79.76)\n",
      "Testing model accuracy using 40-segment per subject metric\n",
      "Got 166 / 197 correct (84.26)\n",
      "Per sample\n",
      "Min: 79.76138147566719, Max: 82.49921507064364, Mean: 81.3839874411303, STDEV: 0.9317428732667018\n",
      "Per subject\n",
      "Min: 83.75634517766497, Max: 88.83248730964468, Mean: 86.09137055837564, STDEV: 1.686624134602657\n"
     ]
    }
   ],
   "source": [
    "logger = Logger(mode='debug')\n",
    "# Compute test performance statistics for all intermidiary saved-models at each specified epochs\n",
    "# and save result to a csv file\n",
    "epochs = [40, 50, 60, 69]\n",
    "\n",
    "with open(\"original-relu-raw-test-results-balanced.csv\", 'w') as out:\n",
    "    out.write('epoch,min_sam,max_sam,mean_sam,std_sam,min_subj,max_subj,mean_subj,std_subj\\n')\n",
    "    for epoch in epochs:\n",
    "        sample_acc, subject_acc = test_all_seeds(partial_model_path=\"saved-model/original-relu-raw/model-original-relu-raw\", epoch=epoch, num_seed=10, isBalanced=True)\n",
    "\n",
    "        min_sample = np.min(sample_acc)\n",
    "        max_sample = np.max(sample_acc)\n",
    "        mean_sample = np.mean(sample_acc)\n",
    "        std_sample = np.std(sample_acc)\n",
    "\n",
    "        min_subj = np.min(subject_acc)\n",
    "        max_subj = np.max(subject_acc)\n",
    "        mean_subj = np.mean(subject_acc)\n",
    "        std_subj = np.std(subject_acc)\n",
    "\n",
    "        logger.log(\"Per sample\")\n",
    "        logger.log(f\"Min: {min_sample}, Max: {max_sample}, Mean: {mean_sample}, STDEV: {std_sample}\")\n",
    "\n",
    "        logger.log(\"Per subject\")\n",
    "        logger.log(f\"Min: {min_subj}, Max: {max_subj}, Mean: {mean_subj}, STDEV: {std_subj}\")\n",
    "        out.write(f\"{epoch},{min_sample},{max_sample},{mean_sample},{std_sample},{min_subj},{max_subj},{mean_subj},{std_subj}\\n\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "SexPrediction.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
